{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b97726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Parameters loaded from MELCOR (no JSON)\n",
      " - Control functions from 3000 to 3062\n",
      " - Simulation time: 1s to 107288s\n",
      " - Number of control volumes (batches): 7\n",
      " - Volumes (keys 1..N, cm³): {1: 144162662.5198637, 2: 123851651.02197042, 3: 565922975.1899465, 4: 6471758280.302349, 5: 79999998.11147389, 6: 1e+16, 7: 6509367032.222646}\n",
      " - Index->CVH map: {1: 110, 2: 160, 3: 200, 4: 305, 5: 1, 6: 600, 7: 201}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import radioactivedecay as rd\n",
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\macario\\snap4\\python\")\n",
    "from pypost.codes.melcor import MELCOR\n",
    "\n",
    "# =======================\n",
    "# INPUT FROM MELCOR (same variable structure)\n",
    "# =======================\n",
    "\n",
    "# --- Adjust here the file and the CVHs that will be subject of the analysis ---\n",
    "filename = \"MC_Step.ptf\"\n",
    "cv_list = [110, 160, 200, 305, 1, 600, 201]\n",
    "\n",
    "# --- Adjust here the CFVALU range ---\n",
    "#Each CV from cv_list need to have associated 9 CFs with each of the 9 classes that tracks the \n",
    "#The control_function is \"RN1-TOTMASSy.x\"\n",
    "#This is because python cannot directly access the variables from the PTF as they are somtimes too large and get \"cutted\"\n",
    "#THe following are the numbers of the \"EQUALS\" Control functions that point to the RN1-TOTMASS variables, in order, for each CV in cv_list.\n",
    "\n",
    "start_number = 3000     # <-- set your real start\n",
    "# you can do range(cv_list) to obtain the number of CFs, and set end_number to range(cv_list)*9+start_number-1\n",
    "#The same order of cv_list must be maintained\n",
    "end_number   = 3062     # <-- set your real end\n",
    "\n",
    "# Open MELCOR file\n",
    "index = MELCOR.openPlotFile(filename)\n",
    "\n",
    "# Take time values from the first reference variable (as requested)\n",
    "primer_cv = cv_list[0]\n",
    "var_ref = f\"CVH-VOLLIQ_{primer_cv}\"\n",
    "data_ref = np.array(MELCOR.getData(index, var_ref))\n",
    "\n",
    "t_ini_raw = float(data_ref[0, 0])\n",
    "t_fin_raw = float(data_ref[-1, 0])\n",
    "\n",
    "# +1 s and truncated (remove decimals)\n",
    "start_time = int(t_ini_raw + 1)\n",
    "end_time   = int(t_fin_raw + 1)\n",
    "\n",
    "# =======================\n",
    "# Calculation of Volumes in m3 ; V_values (keys 1..N) and index->CVH map\n",
    "# =======================\n",
    "V_values = {}                 # dict[int -> float] in cm³; keys 1..N\n",
    "cv_index_map = {}             # dict[int -> int]  index->CVH (for info only)\n",
    "\n",
    "for idx, cv in enumerate(cv_list, start=1):   # idx = 1..N\n",
    "    cv_index_map[idx] = int(cv)\n",
    "\n",
    "    var_liq = f\"CVH-VOLLIQ_{cv}\"\n",
    "    var_vap = f\"CVH-VOLVAP_{cv}\"\n",
    "\n",
    "    data_liq = np.array(MELCOR.getData(index, var_liq))\n",
    "    data_vap = np.array(MELCOR.getData(index, var_vap))\n",
    "\n",
    "    t_liq = data_liq[:, 0]\n",
    "    v_liq = data_liq[:, 1]\n",
    "    t_vap = data_vap[:, 0]\n",
    "    v_vap = data_vap[:, 1]\n",
    "\n",
    "    # Align time arrays if needed\n",
    "    if (data_liq.shape[0] != data_vap.shape[0]) or (not np.allclose(t_liq, t_vap)):\n",
    "        v_vap = np.interp(t_liq, t_vap, v_vap)\n",
    "\n",
    "    total_m3 = v_liq + v_vap\n",
    "    avg_m3   = float(np.mean(total_m3))\n",
    "    avg_cm3  = avg_m3 * 1_000_000.0  # m³ -> cm³\n",
    "\n",
    "    # Key = sequential index (1..N), not the CVH number\n",
    "    V_values[idx] = avg_cm3\n",
    "\n",
    "# Build CFVALU and batches (identical to your structure)\n",
    "mass_data_lines = [f\"CFVALU_{i}\" for i in range(start_number, end_number + 1)]\n",
    "batches = [mass_data_lines[i:i + 9] for i in range(0, len(mass_data_lines), 9)]\n",
    "num_batches = len(batches)\n",
    "\n",
    "# Messages (same organization and variables; only data source changes)\n",
    "print(f\"\\n[INFO] Parameters loaded from MELCOR (no JSON)\")\n",
    "print(f\" - Control functions from {start_number} to {end_number}\")\n",
    "print(f\" - Simulation time: {start_time}s to {end_time}s\")\n",
    "print(f\" - Number of control volumes (batches): {num_batches}\")\n",
    "print(f\" - Volumes (keys 1..N, cm³): {V_values}\")\n",
    "\n",
    "# (Optional) Show index -> CVH mapping\n",
    "print(f\" - Index->CVH map: {cv_index_map}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf648bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kktuas================================\n",
    "# OUTPUTS Y RADIONUCLIDE CLASSES\n",
    "# ================================\n",
    "output_directory_1 = \"proportions\"\n",
    "recalculate_proportions = False\n",
    "\n",
    "if not os.path.exists(output_directory_1):\n",
    "    os.makedirs(output_directory_1)\n",
    "    recalculate_proportions = True\n",
    "else:\n",
    "    expected_files = [f\"class_{i}_proportions.csv\" for i in range(1, 10)]\n",
    "    existing_files = os.listdir(output_directory_1)\n",
    "    if not all(f in existing_files for f in expected_files):\n",
    "        recalculate_proportions = True\n",
    "\n",
    "#This will need to go to a JSON. \n",
    "#JEFF 3.3 is used for the fission yield of U235 thermal spectrum. 0.08 yield threshold\n",
    "class_inventories = {\n",
    "    1: {\"Kr-84\": 0.018, \"Kr-85m\": 0.023176, \"Kr-85\": 0.0, \"Rb-85\": 0.0, \"Kr-86\": 0.035503, \"Kr-87\": 0.045683, \"Rb-87\": 0.0, \"Sr-87\": 0.0, \"Kr-88\": 0.062069, \"Rb-88\": 0.0, \"Sr-88\": 0.0, \"Kr-89\": 0.078781, \"Rb-89\": 0.0, \"Sr-89\": 0.0, \"Y-89m\": 0.0, \"Y-89\": 0.0, \"Xe-131\": 0.051867, \"Xe-132\": 0.076688, \"Xe-133\": 0.118142, \"Cs-133\": 0.0, \"Xe-134\": 0.138058, \"Ba-134\": 0.0, \"Xe-135\": 0.111981, \"Cs-135\": 0.0, \"Ba-135\": 0.0, \"Xe-135m\": 0.02091, \"Xe-137\": 0.106693, \"Cs-137\": 0.0, \"Ba-137m\": 0.0, \"Ba-137\": 0.0, \"Xe-138\": 0.11245, \"Cs-138\": 0.0, \"Ba-138\": 0.0},\n",
    "    2: {\"Rb-85\": 0.023818, \"Rb-87\": 0.046492, \"Sr-87\": 0.0, \"Rb-88\": 0.063659, \"Sr-88\": 0.0, \"Rb-89\": 0.084946, \"Sr-89\": 0.0, \"Y-89m\": 0.0, \"Y-89\": 0.0, \"Rb-90\": 0.07604, \"Sr-90\": 0.0, \"Y-90\": 0.0, \"Zr-90\": 0.0, \"Rb-90m\": 0.024801, \"Cs-133\": 0.119836, \"Cs-135\": 0.113714, \"Ba-135\": 0.0, \"Cs-137\": 0.109683, \"Ba-137m\": 0.0, \"Ba-137\": 0.0, \"Cs-138\": 0.119443, \"Ba-138\": 0.0, \"Cs-139\": 0.11235, \"Ba-139\": 0.0, \"La-139\": 0.0, \"Cs-140\": 0.105218, \"Ba-140\": 0.0, \"La-140\": 0.0, \"Ce-140\": 0.0},\n",
    "    3: {\"Sr-88\": 0.04358, \"Sr-89\": 0.058285, \"Y-89\": 0.0, \"Sr-90\": 0.069958, \"Y-90\": 0.0, \"Zr-90\": 0.0, \"Sr-91\": 0.072058, \"Y-91m\": 0.0, \"Y-91\": 0.0, \"Zr-91\": 0.0, \"Sr-92\": 0.074303, \"Y-92\": 0.0, \"Zr-92\": 0.0, \"Sr-93\": 0.078257, \"Y-93\": 0.0, \"Zr-93\": 0.0, \"Nb-93m\": 0.0, \"Nb-93\": 0.0, \"Sr-94\": 0.075344, \"Y-94\": 0.0, \"Zr-94\": 0.0, \"Ba-137\": 0.075067, \"Ba-137m\": 0.070861, \"Ba-138\": 0.082371, \"Ba-139\": 0.077936, \"La-139\": 0.0, \"Ba-140\": 0.078198, \"La-140\": 0.0, \"Ce-140\": 0.0, \"Ba-141\": 0.072152, \"La-141\": 0.0, \"Ce-141\": 0.0, \"Pr-141\": 0.0, \"Ba-142\": 0.071631, \"La-142\": 0.0, \"Ce-142\": 0.0, \"Nd-142\": 0.0},\n",
    "    4: {\"Br-84\": 0.032221, \"Kr-84\": 0.0, \"Br-85\": 0.042341, \"Kr-85m\": 0.0, \"Kr-85\": 0.0, \"Rb-85\": 0.0, \"I-129\": 0.026426, \"Xe-129\": 0.0, \"I-131\": 0.09486, \"Xe-131m\": 0.0, \"Xe-131\": 0.0, \"I-132\": 0.140185, \"Xe-132\": 0.0, \"I-133\": 0.217672, \"Xe-133m\": 0.0, \"Xe-133\": 0.0, \"Cs-133\": 0.0, \"I-134\": 0.253421, \"Xe-134\": 0.0, \"I-135\": 0.193875, \"Xe-135\": 0.0, \"Xe-135m\": 0.0, \"Cs-135\": 0.0, \"Ba-135\": 0.0},\n",
    "    5: {\"Se-84\": 0.0724, \"Br-84\": 0.0, \"Kr-84\": 0.0, \"Te-130\": 0.1388, \"Te-131\": 0.1874, \"I-131\": 0.0, \"Xe-131m\": 0.0, \"Xe-131\": 0.0, \"Te-132\": 0.3191, \"I-132\": 0.0, \"Xe-132\": 0.0, \"Te-133\": 0.2823, \"I-133\": 0.0, \"Xe-133m\": 0.0, \"Xe-133\": 0.0, \"Cs-133\": 0.0, \"Te-134\": 0.0, \"I-134\": 0.0, \"Xe-134\": 0.0},\n",
    "    6: {\"Ru-101\": 0.220387, \"Ru-102\": 0.182712, \"Ru-103\": 0.132412, \"Ru-104\": 0.080133, \"Ru-105\": 0.040373, \"Rh-103\": 0.132412, \"Rh-103m\": 0.130825, \"Rh-105\": 0.040373, \"Pd-105\": 0.040373},\n",
    "    7: {\"Nb-95\": 0.0959, \"Nb-97\": 0.088458, \"Nb-99\": 0.058731, \"Nb-99m\": 0.032276, \"Mo-95\": 0.095958, \"Mo-97\": 0.088459, \"Mo-99\": 0.090579, \"Mo-101\": 0.076392, \"Mo-102\": 0.063219, \"Tc-99\": 0.090576, \"Tc-99m\": 0.079764, \"Ru-99\": 0.0, \"Tc-101\": 0.076408, \"Ru-101\": 0.0, \"Tc-102\": 0.063281, \"Ru-102\": 0.0},\n",
    "    8: {\"Ce-140\": 0.189742, \"Ce-141\": 0.175376, \"Pr-141\": 0.0, \"Ce-142\": 0.174772, \"Ce-143\": 0.177996, \"Pr-143\": 0.0, \"Nd-143\": 0.0, \"Ce-144\": 0.163818, \"Pr-144\": 0.0, \"Pr-144m\": 0.0, \"Nd-144\": 0.0, \"Ce-145\": 0.118295, \"Pr-145\": 0.0, \"Nd-145\": 0.0},\n",
    "    9: {\"Y-89\": 0.03602, \"Y-90\": 0.04323, \"Zr-90\": 0.0, \"Y-91\": 0.04454, \"Zr-91\": 0.0, \"Y-91m\": 0.02636, \"Y-92\": 0.04599, \"Zr-92\": 0.0, \"Y-93\": 0.04905, \"Zr-93\": 0.0, \"Nb-93m\": 0.0, \"Nb-93\": 0.0, \"Y-94\": 0.0486, \"Zr-94\": 0.0, \"Y-95\": 0.04867, \"Zr-95\": 0.0, \"Nb-95\": 0.0, \"Nb-95m\": 0.0, \"Mo-95\": 0.0, \"La-139\": 0.04806, \"La-140\": 0.04823, \"Ce-140\": 0.0, \"La-141\": 0.0446, \"Ce-141\": 0.0, \"La-142\": 0.04444, \"Ce-142\": 0.0, \"La-143\": 0.04526, \"Ce-143\": 0.0, \"Pr-141\": 0.0446, \"Pr-143\": 0.04529, \"Pr-144\": 0.04167, \"Pr-145\": 0.0301, \"Pr-146\": 0.02281, \"Pr-147\": 0.0171, \"Pr-148\": 0.01264, \"Nd-143\": 0.04529, \"Nd-144\": 0.04167, \"Nd-145\": 0.0301, \"Nd-146\": 0.02281, \"Nd-147\": 0.0171, \"Nd-148\": 0.0129, \"Pm-147\": 0.0171, \"Sm-147\": 0.0171, \"Sm-149\": 0.00783}\n",
    "}\n",
    "time_steps = np.arange(start_time, end_time, 1)\n",
    "all_class_proportions = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "000fd5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating proportions for class 1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macario\\AppData\\Local\\Temp\\ipykernel_14168\\2943334724.py:46: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(output_directory_1, f\"class_{class_num}_proportions.png\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating proportions for class 2...\n",
      "Calculating proportions for class 3...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     22\u001b[0m last_t \u001b[38;5;241m=\u001b[39m time_steps[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(time_steps):\n\u001b[1;32m---> 24\u001b[0m     inv \u001b[38;5;241m=\u001b[39m inv\u001b[38;5;241m.\u001b[39mdecay(t \u001b[38;5;241m-\u001b[39m last_t, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m inv\n\u001b[0;32m     25\u001b[0m     last_t \u001b[38;5;241m=\u001b[39m t\n\u001b[0;32m     26\u001b[0m     masses \u001b[38;5;241m=\u001b[39m inv\u001b[38;5;241m.\u001b[39mmasses(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\macario\\anaconda3\\Lib\\site-packages\\radioactivedecay\\inventory.py:1343\u001b[0m, in \u001b[0;36mInventory.decay\u001b[1;34m(self, decay_time, units)\u001b[0m\n\u001b[0;32m   1337\u001b[0m vector_n0, indices, matrix_e \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setup_decay_calc()\n\u001b[0;32m   1339\u001b[0m matrix_e\u001b[38;5;241m.\u001b[39mdata[indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(\n\u001b[0;32m   1340\u001b[0m     \u001b[38;5;241m-\u001b[39mdecay_time \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_matrices\u001b[38;5;241m.\u001b[39mdecay_consts[indices]\n\u001b[0;32m   1341\u001b[0m )\n\u001b[1;32m-> 1343\u001b[0m vector_nt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_perform_decay_calc(vector_n0, matrix_e)\n\u001b[0;32m   1344\u001b[0m new_contents \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_data\u001b[38;5;241m.\u001b[39mnuclides[indices], vector_nt[indices]))\n\u001b[0;32m   1346\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m(new_contents, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_data)\n",
      "File \u001b[1;32mc:\\Users\\macario\\anaconda3\\Lib\\site-packages\\radioactivedecay\\inventory.py:693\u001b[0m, in \u001b[0;36mAbstractInventory._perform_decay_calc\u001b[1;34m(self, vector_n0, matrix_e)\u001b[0m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_perform_decay_calc\u001b[39m(\n\u001b[0;32m    684\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    685\u001b[0m     vector_n0: Union[np\u001b[38;5;241m.\u001b[39mndarray, Matrix],\n\u001b[0;32m    686\u001b[0m     matrix_e: Union[sparse\u001b[38;5;241m.\u001b[39mcsr_matrix, Matrix],\n\u001b[0;32m    687\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[np\u001b[38;5;241m.\u001b[39mndarray, Matrix]:\n\u001b[0;32m    688\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    689\u001b[0m \u001b[38;5;124;03m    Perform decay calculation matrix multiplication.\u001b[39;00m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    692\u001b[0m     vector_nt \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m--> 693\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_matrices\u001b[38;5;241m.\u001b[39mmatrix_c\n\u001b[0;32m    694\u001b[0m         \u001b[38;5;241m@\u001b[39m matrix_e\n\u001b[0;32m    695\u001b[0m         \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecay_matrices\u001b[38;5;241m.\u001b[39mmatrix_c_inv\n\u001b[0;32m    696\u001b[0m         \u001b[38;5;241m@\u001b[39m vector_n0\n\u001b[0;32m    697\u001b[0m     )\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vector_nt\n",
      "File \u001b[1;32mc:\\Users\\macario\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:695\u001b[0m, in \u001b[0;36m_spbase.__matmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m isscalarlike(other):\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mScalar operands are not allowed, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    694\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m*\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 695\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_matmul_dispatch(other)\n",
      "File \u001b[1;32mc:\\Users\\macario\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:606\u001b[0m, in \u001b[0;36m_spbase._matmul_dispatch\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    604\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m other\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    605\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCannot yet multiply a 1d sparse array\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 606\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_matmul_sparse(other)\n\u001b[0;32m    608\u001b[0m \u001b[38;5;66;03m# If it's a list or whatever, treat it like an array\u001b[39;00m\n\u001b[0;32m    609\u001b[0m other_a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masanyarray(other)\n",
      "File \u001b[1;32mc:\\Users\\macario\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:520\u001b[0m, in \u001b[0;36m_cs_matrix._matmul_sparse\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    516\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[0;32m    517\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices))\n\u001b[0;32m    519\u001b[0m fn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_sparsetools, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_matmat_maxnnz\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 520\u001b[0m nnz \u001b[38;5;241m=\u001b[39m fn(M, N,\n\u001b[0;32m    521\u001b[0m          np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, dtype\u001b[38;5;241m=\u001b[39midx_dtype),\n\u001b[0;32m    522\u001b[0m          np\u001b[38;5;241m.\u001b[39masarray(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices, dtype\u001b[38;5;241m=\u001b[39midx_dtype),\n\u001b[0;32m    523\u001b[0m          np\u001b[38;5;241m.\u001b[39masarray(other\u001b[38;5;241m.\u001b[39mindptr, dtype\u001b[38;5;241m=\u001b[39midx_dtype),\n\u001b[0;32m    524\u001b[0m          np\u001b[38;5;241m.\u001b[39masarray(other\u001b[38;5;241m.\u001b[39mindices, dtype\u001b[38;5;241m=\u001b[39midx_dtype))\n\u001b[0;32m    526\u001b[0m idx_dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_index_dtype((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindptr, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices,\n\u001b[0;32m    527\u001b[0m                              other\u001b[38;5;241m.\u001b[39mindptr, other\u001b[38;5;241m.\u001b[39mindices),\n\u001b[0;32m    528\u001b[0m                             maxval\u001b[38;5;241m=\u001b[39mnnz)\n\u001b[0;32m    530\u001b[0m indptr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(major_axis \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, dtype\u001b[38;5;241m=\u001b[39midx_dtype)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# CALCULATION OR LOADING OF PROPORTIONS\n",
    "# ==========================================\n",
    "output_directory_1 = \"proportions\"\n",
    "os.makedirs(output_directory_1, exist_ok=True)\n",
    "expected_files = [f\"class_{i}_proportions.csv\" for i in range(1, 10)]\n",
    "recalc = not all(f in os.listdir(output_directory_1) for f in expected_files)\n",
    "\n",
    "all_class_proportions = {}\n",
    "#it creates a csv with the proportion of each isotope in all the different classes for all time steps. \n",
    "#it calculates daughters and so on from the initial proportions given before \n",
    "#It can take up to 60-120 min. \n",
    "#If the user has already performed this step, it will directly import the data and not recalculate again. \n",
    "if recalc:\n",
    "    for class_num, inv_props in class_inventories.items():\n",
    "        print(f\"Calculating proportions for class {class_num}...\")\n",
    "        inv = rd.Inventory({}, \"kg\")\n",
    "        # initialize 1 kg total distributed according to inventory proportions\n",
    "        inv += rd.Inventory({iso: 1.0 * prop for iso, prop in inv_props.items()}, \"kg\")\n",
    "        proportions = {iso: np.zeros(len(time_steps)) for iso in inv_props}\n",
    "        last_t = time_steps[0]\n",
    "        for i, t in enumerate(time_steps):\n",
    "            inv = inv.decay(t - last_t, 's') if i > 0 else inv\n",
    "            last_t = t\n",
    "            masses = inv.masses(\"kg\")\n",
    "            total = sum(masses.values())\n",
    "            for iso in proportions:\n",
    "                proportions[iso][i] = max(masses.get(iso, 0), 0) / total if total > 0 else 0\n",
    "\n",
    "        all_class_proportions[class_num] = proportions\n",
    "\n",
    "        # save CSV\n",
    "        csv_path = os.path.join(output_directory_1, f\"class_{class_num}_proportions.csv\")\n",
    "        with open(csv_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Time (s)\"] + list(proportions.keys()))\n",
    "            for i, t in enumerate(time_steps):\n",
    "                writer.writerow([t] + [proportions[iso][i] for iso in proportions])\n",
    "\n",
    "        # plot results\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        for iso, arr in proportions.items():\n",
    "            plt.plot(time_steps, arr, label=iso)\n",
    "        plt.legend(); plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_directory_1, f\"class_{class_num}_proportions.png\"))\n",
    "        plt.close()\n",
    "\n",
    "else:\n",
    "    for class_num in range(1, 10):\n",
    "        csv_path = os.path.join(output_directory_1, f\"class_{class_num}_proportions.csv\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "        isotopes = df.columns.tolist()[1:]\n",
    "        all_class_proportions[class_num] = {\n",
    "            iso: df[iso].values for iso in isotopes\n",
    "        }\n",
    "    print(\"Proportions successfully loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eff0f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Masas ===\n",
      "[INFO] Cargando masas desde CSV…\n",
      "[Batch 1] Masas recargadas correctamente.\n",
      "  Clase 1 – primer valor masa 'Kr-84' = nan\n",
      "\n",
      "=== Batch 2 — Masas ===\n",
      "[INFO] Cargando masas desde CSV…\n",
      "[Batch 2] Masas recargadas correctamente.\n",
      "  Clase 1 – primer valor masa 'Kr-84' = nan\n",
      "\n",
      "=== Batch 3 — Masas ===\n",
      "[INFO] Cargando masas desde CSV…\n",
      "[Batch 3] Masas recargadas correctamente.\n",
      "  Clase 1 – primer valor masa 'Kr-84' = nan\n",
      "\n",
      "=== Batch 4 — Masas ===\n",
      "[INFO] Cargando masas desde CSV…\n",
      "[Batch 4] Masas recargadas correctamente.\n",
      "  Clase 1 – primer valor masa 'Kr-84' = nan\n",
      "\n",
      "=== Batch 5 — Masas ===\n",
      "[INFO] Cargando masas desde CSV…\n",
      "[Batch 5] Masas recargadas correctamente.\n",
      "  Clase 1 – primer valor masa 'Kr-84' = nan\n",
      "\n",
      "=== Batch 6 — Masas ===\n",
      "[INFO] Cargando masas desde CSV…\n",
      "[Batch 6] Masas recargadas correctamente.\n",
      "  Clase 1 – primer valor masa 'Kr-84' = nan\n",
      "\n",
      "=== Batch 7 — Masas ===\n",
      "[INFO] Cargando masas desde CSV…\n",
      "[Batch 7] Masas recargadas correctamente.\n",
      "  Clase 1 – primer valor masa 'Kr-84' = nan\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from pypost.codes.melcor import MELCOR\n",
    "\n",
    "# ==========================================\n",
    "# MODULE: CALCULATION OR LOADING OF MASSES (all batches)\n",
    "# ==========================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Masses ===\")\n",
    "\n",
    "    # 1) Output directory, create if necessary\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # 2) Do the mass CSV files already exist?\n",
    "    expected = [f\"class_{i}_masses.csv\" for i in range(1, 10)]\n",
    "    recalc = not all(fn in os.listdir(output_directory) for fn in expected)\n",
    "\n",
    "    all_class_masses = {}\n",
    "\n",
    "    if recalc:\n",
    "        print(\"[INFO] Calculating masses from MELCOR…\")\n",
    "        batch = batches[batch_num - 1]               # the 9 variables of this batch\n",
    "\n",
    "        # Loop through each of the 9 classes\n",
    "        for class_num, var in enumerate(batch, start=1):\n",
    "            print(f\"  Class {class_num}: variable '{var}'\")\n",
    "            # 2.1) Read from MELCOR\n",
    "            idx = MELCOR.openPlotFile(\"MC_Step.ptf\")\n",
    "            data = np.array(MELCOR.getData(idx, var))\n",
    "            t, M = data[:, 0], data[:, 1]\n",
    "\n",
    "            # 2.2) Filter and make uniform\n",
    "            mask = (t >= start_time) & (t <= end_time)\n",
    "            uni_t = np.arange(start_time, end_time, 1)\n",
    "            uni_M = interp1d(t[mask], M[mask],\n",
    "                             kind='previous',\n",
    "                             fill_value=\"extrapolate\")(uni_t)\n",
    "\n",
    "            # 2.3) Distribute according to proportions\n",
    "            props = all_class_proportions[class_num]\n",
    "            masses = {iso: props[iso] * uni_M for iso in props}\n",
    "            all_class_masses[class_num] = masses\n",
    "\n",
    "            # 2.4) Save to CSV\n",
    "            csv_path = os.path.join(output_directory,\n",
    "                                    f\"class_{class_num}_masses.csv\")\n",
    "            with open(csv_path, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\"] + list(masses.keys()))\n",
    "                for i, t0 in enumerate(uni_t):\n",
    "                    w.writerow([t0] + [masses[iso][i] for iso in masses])\n",
    "\n",
    "            # 2.5) Plot results\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            for iso, arr in masses.items():\n",
    "                plt.plot(uni_t, arr, label=iso)\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Mass (kg)\")\n",
    "            plt.title(f\"Batch {batch_num} – Class {class_num} Masses\")\n",
    "            plt.legend(); plt.grid(True)\n",
    "            plt.savefig(os.path.join(output_directory,\n",
    "                                     f\"class_{class_num}_masses.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Masses calculated and saved.\")\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] Loading masses from CSV…\")\n",
    "        for class_num in range(1, 10):\n",
    "            csv_path = os.path.join(output_directory,\n",
    "                                    f\"class_{class_num}_masses.csv\")\n",
    "            df = pd.read_csv(csv_path)\n",
    "            isotopes = df.columns.tolist()[1:]\n",
    "            all_class_masses[class_num] = {\n",
    "                iso: df[iso].values for iso in isotopes\n",
    "            }\n",
    "        print(f\"[Batch {batch_num}] Masses successfully reloaded.\")\n",
    "\n",
    "    # Now `all_class_masses` is ready for this batch_num\n",
    "    # Quick check:\n",
    "    print(f\"  Class 1 – first mass value for '{list(all_class_masses[1].keys())[0]}' =\",\n",
    "          all_class_masses[1][list(all_class_masses[1].keys())[0]][0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7de50f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Actividades ===\n",
      "[INFO] Cargando actividades desde CSV…\n",
      "[Batch 1] Actividades recargadas correctamente.\n",
      "\n",
      "=== Batch 2 — Actividades ===\n",
      "[INFO] Cargando actividades desde CSV…\n",
      "[Batch 2] Actividades recargadas correctamente.\n",
      "\n",
      "=== Batch 3 — Actividades ===\n",
      "[INFO] Cargando actividades desde CSV…\n",
      "[Batch 3] Actividades recargadas correctamente.\n",
      "\n",
      "=== Batch 4 — Actividades ===\n",
      "[INFO] Cargando actividades desde CSV…\n",
      "[Batch 4] Actividades recargadas correctamente.\n",
      "\n",
      "=== Batch 5 — Actividades ===\n",
      "[INFO] Cargando actividades desde CSV…\n",
      "[Batch 5] Actividades recargadas correctamente.\n",
      "\n",
      "=== Batch 6 — Actividades ===\n",
      "[INFO] Cargando actividades desde CSV…\n",
      "[Batch 6] Actividades recargadas correctamente.\n",
      "\n",
      "=== Batch 7 — Actividades ===\n",
      "[INFO] Cargando actividades desde CSV…\n",
      "[Batch 7] Actividades recargadas correctamente.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import radioactivedecay as rd\n",
    "\n",
    "# ==========================================\n",
    "# MODULE: CALCULATION OR LOADING OF ACTIVITIES (all batches)\n",
    "# ==========================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Activities ===\")\n",
    "\n",
    "    # 1) Output directory and subfolder for plots\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    dose_plots_dir = os.path.join(output_directory, 'dose_rate_plots')\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    os.makedirs(dose_plots_dir, exist_ok=True)\n",
    "\n",
    "    # 2) Reload MASSES from CSV\n",
    "    all_class_masses = {}\n",
    "    for class_num in range(1, 10):\n",
    "        mass_csv = os.path.join(output_directory, f\"class_{class_num}_masses.csv\")\n",
    "        df_mass = pd.read_csv(mass_csv)\n",
    "        isotopes = df_mass.columns.tolist()[1:]\n",
    "        all_class_masses[class_num] = {iso: df_mass[iso].values for iso in isotopes}\n",
    "\n",
    "    # 3) Check for existing ACTIVITY CSV files\n",
    "    expected = [f\"class_{i}_activities.csv\" for i in range(1, 10)]\n",
    "    recalc_act = not all(fn in os.listdir(output_directory) for fn in expected)\n",
    "\n",
    "    all_class_activities = {}\n",
    "\n",
    "    if recalc_act:\n",
    "        print(\"[INFO] Calculating activities from masses…\")\n",
    "        for class_num, isotope_masses in all_class_masses.items():\n",
    "            print(f\"  Class {class_num}\")\n",
    "            # Prepare the activity dictionary (Ci)\n",
    "            acts = {iso: np.zeros(len(time_steps)) for iso in isotope_masses}\n",
    "\n",
    "            for idx, t in enumerate(time_steps):\n",
    "                inv = rd.Inventory({}, \"kg\")\n",
    "                for iso, mass_arr in isotope_masses.items():\n",
    "                    m = mass_arr[idx]\n",
    "                    if m > 0:\n",
    "                        inv += rd.Inventory({iso: m}, \"kg\")\n",
    "                bq_dict = inv.activities(\"Bq\")\n",
    "                for iso, bq in bq_dict.items():\n",
    "                    acts[iso][idx] = bq / 3.7e10  # Convert Bq → Ci\n",
    "\n",
    "            all_class_activities[class_num] = acts\n",
    "\n",
    "            # Save CSV\n",
    "            csv_path = os.path.join(output_directory, f\"class_{class_num}_activities.csv\")\n",
    "            with open(csv_path, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\"] + list(acts.keys()))\n",
    "                for i, t in enumerate(time_steps):\n",
    "                    w.writerow([t] + [acts[iso][i] for iso in acts])\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            for iso, arr in acts.items():\n",
    "                plt.plot(time_steps, arr, label=iso)\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Activity (Ci)\")\n",
    "            plt.title(f\"Batch {batch_num} – Class {class_num} Activities\")\n",
    "            plt.legend(); plt.grid(True)\n",
    "            plt.savefig(os.path.join(output_directory, f\"class_{class_num}_activities.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Activities calculated and saved.\")\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] Loading activities from CSV…\")\n",
    "        for class_num in range(1, 10):\n",
    "            csv_path = os.path.join(output_directory, f\"class_{class_num}_activities.csv\")\n",
    "            df_act = pd.read_csv(csv_path)\n",
    "            isotopes = df_act.columns.tolist()[1:]\n",
    "            all_class_activities[class_num] = {\n",
    "                iso: df_act[iso].values for iso in isotopes\n",
    "            }\n",
    "        print(f\"[Batch {batch_num}] Activities successfully reloaded.\")\n",
    "\n",
    "    # Now you can use all_class_activities[batch_num]...\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c20103",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the gamma energies in MeV based on your previous information. Taken from JANIS Radioactive Data. \n",
    "#Esto se irá al JSON. \n",
    "gamma_energies = {\n",
    "    \"Ba-134\": 0,\n",
    "    \"Ba-135\": 0,\n",
    "    \"Ba-137\": 0,\n",
    "    \"Ba-137m\": 0.598293,\n",
    "    \"Ba-138\": 0,\n",
    "    \"Ba-139\": 0.044007,\n",
    "    \"Ba-140\": 0.183908,\n",
    "    \"Ba-141\": 0.871229,\n",
    "    \"Ba-142\": 1.045,\n",
    "    \"Br-84\": 1.757,\n",
    "    \"Br-85\": 0.061313,\n",
    "    \"Ce-140\": 0,\n",
    "    \"Ce-141\": 0.076594,\n",
    "    \"Ce-142\": 0,\n",
    "    \"Ce-143\": 0.278651,\n",
    "    \"Ce-144\": 0.018956,\n",
    "    \"Ce-145\": 0.601026,\n",
    "    \"Cs-133\": 0,\n",
    "    \"Cs-135\": 0,\n",
    "    \"Cs-137\": 1.652e-06,\n",
    "    \"Cs-138\": 2.355,\n",
    "    \"Cs-139\": 0.305,\n",
    "    \"Cs-140\": 1.827,\n",
    "    \"Eu-151\": 0,\n",
    "    \"Eu-153\": 0,\n",
    "    \"He-3\": 0,\n",
    "    \"I-129\": 0.024511,\n",
    "    \"I-131\": 0.380618,\n",
    "    \"I-132\": 2.256,\n",
    "    \"I-133\": 0.606453,\n",
    "    \"I-134\": 2.531,\n",
    "    \"I-135\": 1.578,\n",
    "    \"Kr-84\": 0,\n",
    "    \"Kr-85\": 0.002236,\n",
    "    \"Kr-85m\": 0.157403,\n",
    "    \"Kr-86\": 0,\n",
    "    \"Kr-87\": 0.787882,\n",
    "    \"Kr-88\": 1.95,\n",
    "    \"Kr-89\": 1.836,\n",
    "    \"La-139\": 0,\n",
    "    \"La-140\": 2.319,\n",
    "    \"La-141\": 0.02678,\n",
    "    \"La-142\": 2.121,\n",
    "    \"La-143\": 0.4394,\n",
    "    \"Mo-101\": 1.425,\n",
    "    \"Mo-102\": 0.018452,\n",
    "    \"Mo-95\": 0,\n",
    "    \"Mo-97\": 0,\n",
    "    \"Mo-99\": 0.148736,\n",
    "    \"Nb-93\": 0,\n",
    "    \"Nb-93m\": 0.00205,\n",
    "    \"Nb-95\": 0.764492,\n",
    "    \"Nb-95m\": 0.071357,\n",
    "    \"Nb-97\": 0.664232,\n",
    "    \"Nb-99\": 0.298219,\n",
    "    \"Nb-99m\": 0.650406,\n",
    "    \"Nd-142\": 0,\n",
    "    \"Nd-143\": 0,\n",
    "    \"Nd-144\": 0,\n",
    "    \"Nd-145\": 0,\n",
    "    \"Nd-146\": 0,\n",
    "    \"Nd-147\": 0.138133,\n",
    "    \"Nd-148\": 0,\n",
    "    \"Pd-105\": 0,\n",
    "    \"Pd-106\": 0,\n",
    "    \"Pm-147\": 4.264e-06,\n",
    "    \"Pm-149\": 0.011857,\n",
    "    \"Pm-151\": 0.326653,\n",
    "    \"Pr-141\": 0,\n",
    "    \"Pr-143\": 0,\n",
    "    \"Pr-144\": 0.030262,\n",
    "    \"Pr-144m\": 0.013297,\n",
    "    \"Pr-145\": 0.6017,\n",
    "    \"Pr-146\": 0.987414,\n",
    "    \"Pr-147\": 0.9285,\n",
    "    \"Pr-148\": 1.776,\n",
    "    \"Rb-85\": 0,\n",
    "    \"Rb-87\": 0,\n",
    "    \"Rb-88\": 0.667156,\n",
    "    \"Rb-89\": 2.234,\n",
    "    \"Rb-90\": 2.28,\n",
    "    \"Rb-90m\": 3.869,\n",
    "    \"Rh-103\": 0,\n",
    "    \"Rh-103m\": 0.001701,\n",
    "    \"Rh-105\": 0.077271,\n",
    "    \"Rh-106\": 0.205096,\n",
    "    \"Ru-101\": 0,\n",
    "    \"Ru-102\": 0,\n",
    "    \"Ru-103\": 0.496096,\n",
    "    \"Ru-104\": 0,\n",
    "    \"Ru-105\": 0.747755,\n",
    "    \"Ru-106\": 0,\n",
    "    \"Ru-99\": 0,\n",
    "    \"Se-84\": 0.4082,\n",
    "    \"Sm-147\": 0,\n",
    "    \"Sm-149\": 0,\n",
    "    \"Sm-151\": 1.4383e-05,\n",
    "    \"Sm-153\": 0.061397,\n",
    "    \"Sr-87\": 0,\n",
    "    \"Sr-88\": 0,\n",
    "    \"Sr-89\": 0,\n",
    "    \"Sr-90\": 0,\n",
    "    \"Sr-91\": 0.707162,\n",
    "    \"Sr-92\": 1.381,\n",
    "    \"Sr-93\": 2.218,\n",
    "    \"Sr-94\": 1.433,\n",
    "    \"Tc-101\": 0.335927,\n",
    "    \"Tc-102\": 0.080762,\n",
    "    \"Tc-99\": 7.01744e-07,\n",
    "    \"Tc-99m\": 0.126471,\n",
    "    \"Te-130\": 0,\n",
    "    \"Te-131\": 0.445655,\n",
    "    \"Te-132\": 0.23452,\n",
    "    \"Te-133\": 1.182,\n",
    "    \"Te-134\": 0.877281,\n",
    "    \"Xe-129\": 0,\n",
    "    \"Xe-131\": 0,\n",
    "    \"Xe-131m\": 0.020116,\n",
    "    \"Xe-132\": 0,\n",
    "    \"Xe-133\": 0.045685,\n",
    "    \"Xe-133m\": 0.04179,\n",
    "    \"Xe-134\": 0,\n",
    "    \"Xe-135\": 0.248204,\n",
    "    \"Xe-135m\": 0.429934,\n",
    "    \"Xe-137\": 0.189234,\n",
    "    \"Xe-138\": 1.124,\n",
    "    \"Y-89\": 0,\n",
    "    \"Y-89m\": 0.901405,\n",
    "    \"Y-90\": 1.237e-06,\n",
    "    \"Y-91\": 0.003133,\n",
    "    \"Y-91m\": 0.528263,\n",
    "    \"Y-92\": 0.251599,\n",
    "    \"Y-93\": 0.096453,\n",
    "    \"Y-94\": 0.764239,\n",
    "    \"Y-95\": 1.092,\n",
    "    \"Zr-90\": 0,\n",
    "    \"Zr-91\": 0,\n",
    "    \"Zr-92\": 0,\n",
    "    \"Zr-93\": 0,\n",
    "    \"Zr-94\": 0,\n",
    "    \"Zr-95\": 0.732125\n",
    "}\n",
    "\n",
    "    # Define beta emitter average energies for bremsstrahlung calculation (in MeV)\n",
    "beta_emitter_energies = {\n",
    "    \"Ba-134\": 0,\n",
    "    \"Ba-135\": 0,\n",
    "    \"Ba-137\": 0,\n",
    "    \"Ba-137m\": 0.06073,\n",
    "    \"Ba-138\": 0,\n",
    "    \"Ba-139\": 0.892825,\n",
    "    \"Ba-140\": 0.313385,\n",
    "    \"Ba-141\": 0.945734,\n",
    "    \"Ba-142\": 0.399136,\n",
    "    \"Br-84\": 1.229,\n",
    "    \"Br-85\": 1.041,\n",
    "    \"Ce-140\": 0,\n",
    "    \"Ce-141\": 0.160669,\n",
    "    \"Ce-142\": 1.417,\n",
    "    \"Ce-143\": 0.429856,\n",
    "    \"Ce-144\": 0.087466,\n",
    "    \"Ce-145\": 0.762585,\n",
    "    \"Cs-133\": 0,\n",
    "    \"Cs-135\": 0.0757,\n",
    "    \"Cs-137\": 0.17987,\n",
    "    \"Cs-138\": 1.244,\n",
    "    \"Cs-139\": 1.671,\n",
    "    \"Cs-140\": 1.893,\n",
    "    \"Eu-151\": 0,\n",
    "    \"Eu-153\": 0,\n",
    "    \"He-3\": 0,\n",
    "    \"I-129\": 0.059453,\n",
    "    \"I-131\": 0.191476,\n",
    "    \"I-132\": 0.493136,\n",
    "    \"I-133\": 0.408496,\n",
    "    \"I-134\": 0.634527,\n",
    "    \"I-135\": 0.33877,\n",
    "    \"Kr-84\": 0,\n",
    "    \"Kr-85\": 0.250125,\n",
    "    \"Kr-85m\": 0.254231,\n",
    "    \"Kr-86\": 0,\n",
    "    \"Kr-87\": 1.331,\n",
    "    \"Kr-88\": 0.368714,\n",
    "    \"Kr-89\": 1.468,\n",
    "    \"La-139\": 0,\n",
    "    \"La-140\": 0.523249,\n",
    "    \"La-141\": 0.962518,\n",
    "    \"La-142\": 0.9619,\n",
    "    \"La-143\": 1.235,\n",
    "    \"Mo-101\": 0.547612,\n",
    "    \"Mo-102\": 0.349954,\n",
    "    \"Mo-95\": 0,\n",
    "    \"Mo-97\": 0,\n",
    "    \"Mo-99\": 0.39125,\n",
    "    \"Nb-93\": 0,\n",
    "    \"Nb-93m\": 0.02885,\n",
    "    \"Nb-95\": 0.04457,\n",
    "    \"Nb-95m\": 0.170809,\n",
    "    \"Nb-97\": 0.468792,\n",
    "    \"Nb-99\": 1.45,\n",
    "    \"Nb-99m\": 1.416,\n",
    "    \"Nd-142\": 0,\n",
    "    \"Nd-143\": 0,\n",
    "    \"Nd-144\": 0,\n",
    "    \"Nd-145\": 0,\n",
    "    \"Nd-146\": 0,\n",
    "    \"Nd-147\": 0.270598,\n",
    "    \"Nd-148\": 1.928,\n",
    "    \"Pd-105\": 0,\n",
    "    \"Pd-106\": 0,\n",
    "    \"Pm-147\": 0.061761,\n",
    "    \"Pm-149\": 0.366129,\n",
    "    \"Pm-151\": 0.304363,\n",
    "    \"Pr-141\": 0,\n",
    "    \"Pr-143\": 0.314599,\n",
    "    \"Pr-144\": 1.206,\n",
    "    \"Pr-144m\": 0.044817,\n",
    "    \"Pr-145\": 0.6017,\n",
    "    \"Pr-146\": 1.317,\n",
    "    \"Pr-147\": 0.6685,\n",
    "    \"Pr-148\": 1.348,\n",
    "    \"Rb-85\": 0,\n",
    "    \"Rb-87\": 0.0817,\n",
    "    \"Rb-88\": 2.057,\n",
    "    \"Rb-89\": 0.929241,\n",
    "    \"Rb-90\": 1.904,\n",
    "    \"Rb-90m\": 1.118,\n",
    "    \"Rh-103\": 0,\n",
    "    \"Rh-103m\": 0.038209,\n",
    "    \"Rh-105\": 0.153477,\n",
    "    \"Rh-106\": 1.412,\n",
    "    \"Ru-101\": 0,\n",
    "    \"Ru-102\": 0,\n",
    "    \"Ru-103\": 0.066555,\n",
    "    \"Ru-104\": 0,\n",
    "    \"Ru-105\": 0.439836,\n",
    "    \"Ru-106\": 0.01004,\n",
    "    \"Ru-99\": 0,\n",
    "    \"Se-84\": 0.54037,\n",
    "    \"Sm-147\": 0,\n",
    "    \"Sm-149\": 0,\n",
    "    \"Sm-151\": 0.019836,\n",
    "    \"Sm-153\": 0.266624,\n",
    "    \"Sr-87\": 0,\n",
    "    \"Sr-88\": 0,\n",
    "    \"Sr-89\": 0.580864,\n",
    "    \"Sr-90\": 0.1935,\n",
    "    \"Sr-91\": 0.643998,\n",
    "    \"Sr-92\": 0.179903,\n",
    "    \"Sr-93\": 0.794584,\n",
    "    \"Sr-94\": 0.831279,\n",
    "    \"Tc-101\": 0.478598,\n",
    "    \"Tc-102\": 1.945,\n",
    "    \"Tc-99\": 0.095281,\n",
    "    \"Tc-99m\": 0.015645,\n",
    "    \"Te-130\": 2.528,\n",
    "    \"Te-131\": 0.736864,\n",
    "    \"Te-132\": 0.109021,\n",
    "    \"Te-133\": 0.67799,\n",
    "    \"Te-134\": 0.224825,\n",
    "    \"Xe-129\": 0,\n",
    "    \"Xe-131\": 0,\n",
    "    \"Xe-131m\": 0.141932,\n",
    "    \"Xe-132\": 0,\n",
    "    \"Xe-133\": 0.135158,\n",
    "    \"Xe-133m\": 0.190372,\n",
    "    \"Xe-134\": 0.8258,\n",
    "    \"Xe-135\": 0.319687,\n",
    "    \"Xe-135m\": 0.096117,\n",
    "    \"Xe-137\": 1.705,\n",
    "    \"Xe-138\": 0.641877,\n",
    "    \"Y-89\": 0,\n",
    "    \"Y-89m\": 0.007589,\n",
    "    \"Y-90\": 0.933815,\n",
    "    \"Y-91\": 0.605944,\n",
    "    \"Y-91m\": 0.027515,\n",
    "    \"Y-92\": 1.427,\n",
    "    \"Y-93\": 1.173,\n",
    "    \"Y-94\": 1.814,\n",
    "    \"Y-95\": 1.436,\n",
    "    \"Zr-90\": 0,\n",
    "    \"Zr-91\": 0,\n",
    "    \"Zr-92\": 0,\n",
    "    \"Zr-93\": 0.022443,\n",
    "    \"Zr-94\": 1.142,\n",
    "    \"Zr-95\": 0.118404\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c2fe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Energía Gamma Promedio ===\n",
      "[INFO] Cargando energía gamma desde CSV…\n",
      "[Batch 1] Energía gamma recargada correctamente.\n",
      "  Clase 1, primer valor: 0.0\n",
      "\n",
      "=== Batch 2 — Energía Gamma Promedio ===\n",
      "[INFO] Cargando energía gamma desde CSV…\n",
      "[Batch 2] Energía gamma recargada correctamente.\n",
      "  Clase 1, primer valor: 0.0\n",
      "\n",
      "=== Batch 3 — Energía Gamma Promedio ===\n",
      "[INFO] Cargando energía gamma desde CSV…\n",
      "[Batch 3] Energía gamma recargada correctamente.\n",
      "  Clase 1, primer valor: 0.0\n",
      "\n",
      "=== Batch 4 — Energía Gamma Promedio ===\n",
      "[INFO] Cargando energía gamma desde CSV…\n",
      "[Batch 4] Energía gamma recargada correctamente.\n",
      "  Clase 1, primer valor: 0.0\n",
      "\n",
      "=== Batch 5 — Energía Gamma Promedio ===\n",
      "[INFO] Cargando energía gamma desde CSV…\n",
      "[Batch 5] Energía gamma recargada correctamente.\n",
      "  Clase 1, primer valor: 0.0\n",
      "\n",
      "=== Batch 6 — Energía Gamma Promedio ===\n",
      "[INFO] Cargando energía gamma desde CSV…\n",
      "[Batch 6] Energía gamma recargada correctamente.\n",
      "  Clase 1, primer valor: 0.0\n",
      "\n",
      "=== Batch 7 — Energía Gamma Promedio ===\n",
      "[INFO] Cargando energía gamma desde CSV…\n",
      "[Batch 7] Energía gamma recargada correctamente.\n",
      "  Clase 1, primer valor: 0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ==========================================\n",
    "# MODULE: CALCULATION OR LOADING OF AVERAGE GAMMA ENERGY (all batches)\n",
    "# ==========================================\n",
    "# 1) Assumes you have already defined in another cell:\n",
    "#    gamma_energies = {...}\n",
    "#    beta_emitter_energies = {...}\n",
    "\n",
    "# 1) Calculate and add bremsstrahlung **ONCE** before the loop\n",
    "Z_air = 7.3\n",
    "for iso, E_beta in beta_emitter_energies.items():\n",
    "    E_brem = 1.33e-4 * Z_air * E_beta**2\n",
    "    gamma_energies[iso] = gamma_energies.get(iso, 0) + E_brem\n",
    "\n",
    "# ==========================================\n",
    "# MODULE: CALCULATION OR LOADING OF AVERAGE GAMMA ENERGY\n",
    "# ==========================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Average Gamma Energy ===\")\n",
    "\n",
    "    # 2) Output directory\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # 3) Reload MASSES from CSV for this batch\n",
    "    all_class_masses = {}\n",
    "    for class_num in range(1, 10):\n",
    "        mass_csv = os.path.join(output_directory, f\"class_{class_num}_masses.csv\")\n",
    "        df_mass = pd.read_csv(mass_csv)\n",
    "        isotopes = df_mass.columns.tolist()[1:]\n",
    "        all_class_masses[class_num] = {iso: df_mass[iso].values for iso in isotopes}\n",
    "\n",
    "    # 4) Check for existing gamma energy CSVs\n",
    "    expected_files = [f\"class_{i}_average_gamma_energy.csv\" for i in range(1, 10)]\n",
    "    recalc = not all(fn in os.listdir(output_directory) for fn in expected_files)\n",
    "\n",
    "    average_gamma_energies = {}\n",
    "\n",
    "    if recalc:\n",
    "        print(\"[INFO] Calculating average gamma energy…\")\n",
    "\n",
    "        # 5) For each class, calculate the average\n",
    "        for class_num, iso_masses in all_class_masses.items():\n",
    "            print(f\"  Class {class_num}\")\n",
    "            avg = np.zeros(len(time_steps))\n",
    "\n",
    "            for i in range(len(time_steps)):\n",
    "                weighted_sum = 0.0\n",
    "                total_mass = 0.0\n",
    "                for iso, arr in iso_masses.items():\n",
    "                    m = arr[i]\n",
    "                    gE = gamma_energies.get(iso, 0.0)\n",
    "                    if gE > 0:  # only gamma-emitting isotopes\n",
    "                        weighted_sum += m * gE\n",
    "                        total_mass += m\n",
    "                avg[i] = (weighted_sum / total_mass) if total_mass > 0 else 0.0\n",
    "\n",
    "            average_gamma_energies[class_num] = avg\n",
    "\n",
    "            # 6) Save CSV\n",
    "            csv_path = os.path.join(output_directory, f\"class_{class_num}_average_gamma_energy.csv\")\n",
    "            with open(csv_path, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"Time (s)\", \"Average Gamma Energy (MeV)\"])\n",
    "                for t, val in zip(time_steps, avg):\n",
    "                    writer.writerow([t, val])\n",
    "\n",
    "            # 7) Plot\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            plt.plot(time_steps, avg, label=f\"Class {class_num}\")\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Average Gamma Energy (MeV)\")\n",
    "            plt.title(f\"Batch {batch_num} – Class {class_num}\")\n",
    "            plt.grid(True)\n",
    "            plt.legend()\n",
    "            plt.savefig(os.path.join(output_directory, f\"class_{class_num}_average_gamma_energy.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Gamma energy calculated and saved.\")\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] Loading gamma energy from CSV…\")\n",
    "        for class_num in range(1, 10):\n",
    "            csv_path = os.path.join(output_directory, f\"class_{class_num}_average_gamma_energy.csv\")\n",
    "            df = pd.read_csv(csv_path)\n",
    "            if \"Average Gamma Energy (MeV)\" not in df.columns:\n",
    "                raise KeyError(f\"Missing column 'Average Gamma Energy (MeV)' in {csv_path}\")\n",
    "            average_gamma_energies[class_num] = df[\"Average Gamma Energy (MeV)\"].values\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Gamma energy successfully reloaded.\")\n",
    "\n",
    "    # Example check\n",
    "    print(\"  Class 1, first value:\", average_gamma_energies[1][0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fa095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import scipy.special as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# ==================================\n",
    "# CONSTANTS FOR DOSE RATE CALCULATION\n",
    "# ==================================\n",
    "   \n",
    "# Access V based on the current batch number\n",
    "V = V_values[batch_num]\n",
    "R_sphere = ((3 * V) / (4 * math.pi)) ** (1 / 3)  # Equivalent sphere radius, cm\n",
    "density = 0.001  # g/cm³\n",
    "\n",
    "# ==================================\n",
    "# MASS ATTENUATION AND ABSORPTION FUNCTIONS\n",
    "# ==================================\n",
    "\n",
    "def mass_att(E, a1=-0.037274, b1=0.101714, c1=-0.274123):\n",
    "    \"\"\"Mass attenuation coefficient as a function of photon energy E (MeV).\"\"\"\n",
    "    if E <= 0:\n",
    "        print(\"Invalid E values found.\")\n",
    "        return 0\n",
    "    return a1 + b1 * E**c1\n",
    "\n",
    "def mass_ab(E, a2=0, b2=-5.2588e-4, c2=-5.2077e-3, d=2.8172e-2, e=-1.7809e-2):\n",
    "    \"\"\"Mass absorption coefficient as a function of photon energy E (MeV).\"\"\"\n",
    "    if E <= 0:\n",
    "        print(\"Invalid E values found.\")\n",
    "        return 0\n",
    "    return a2 + b2 * E + c2 * (math.log(E))**2 + d * math.sqrt(E) + e * math.log(E)\n",
    "    \n",
    "def calc_mu_m(E):\n",
    "    \"\"\"\n",
    "    Calculate μm depending on photon energy E (in keV):\n",
    "\n",
    "    - For 0 ≤ E ≤ 200 keV: μm = B3*E³ + B2*E² + B1*E + B0\n",
    "      where B0 = 0.29839, B1 = -0.00269, B2 = 1.67948E-5, B3 = -3.75963E-8.\n",
    "    - For E > 200 keV: μm = B2*E² + B1*E + B0\n",
    "      where B0 = 0.13556, B1 = -9.10106E-5, B2 = 2.39846E-8.\n",
    "\n",
    "    Parameters:\n",
    "        E (float): Photon energy in keV.\n",
    "\n",
    "    Returns:\n",
    "        float: Computed μm value.\n",
    "    \"\"\"\n",
    "    if 0 <= E <= 200:\n",
    "        # Coefficients for 0–200 keV\n",
    "        B0 = 0.29839\n",
    "        B1 = -0.00269\n",
    "        B2 = 1.67948E-5\n",
    "        B3 = -3.75963E-8\n",
    "        mu_m = B3 * (E ** 3) + B2 * (E ** 2) + B1 * E + B0\n",
    "    elif E > 200:\n",
    "        # Coefficients for E > 200 keV\n",
    "        B0 = 0.13556\n",
    "        B1 = -9.10106E-5\n",
    "        B2 = 2.39846E-8\n",
    "        mu_m = B2 * (E ** 2) + B1 * E + B0\n",
    "    else:\n",
    "        print(\"Invalid E value.\")\n",
    "        return 0\n",
    "    return mu_m\n",
    "\n",
    "# ==================================\n",
    "# CIRCULAR BASE METHOD FOR GAMMA FLUX\n",
    "# ==================================\n",
    "\n",
    "def gamma_flux_circular_base(activity, R, h, mass_att_func, E):\n",
    "    \"\"\"\n",
    "    Computes gamma flux using the circular base method.\n",
    "\n",
    "    Parameters:\n",
    "        activity (float): Source activity (Ci)\n",
    "        R (float): Base radius (cm)\n",
    "        h (float): Source height (cm)\n",
    "        mass_att_func (function): Function for mass attenuation coefficient\n",
    "        E (float): Photon energy (MeV)\n",
    "\n",
    "    Returns:\n",
    "        float: Calculated gamma flux (photons/cm²·s)\n",
    "    \"\"\"\n",
    "    mu = mass_att_func(E)\n",
    "    r = np.linspace(0, R, 10)  # Discretize radius\n",
    "    theta = np.linspace(0, np.arctan(R / h), 10)  # Discretize angle\n",
    "    R_grid, Theta_grid = np.meshgrid(r, theta)\n",
    "    path_length = np.sqrt(R_grid**2 + h**2)\n",
    "    b1 = mu * path_length\n",
    "    E1_term = sp.exp1(b1)\n",
    "    E1_sec_term = sp.exp1(b1 / np.cos(Theta_grid))  # sec(theta) = 1 / cos(theta)\n",
    "    integrand = (((3.7e10) * activity) / (2 * np.pi * R**2)) * (E1_term - E1_sec_term)\n",
    "    result = np.trapz(np.trapz(integrand * R_grid, r, axis=0), theta)\n",
    "    return result\n",
    "\n",
    "# ==================================\n",
    "# PLOTTING FUNCTIONS FOR DOSE RATES\n",
    "# ==================================\n",
    "\n",
    "def plot_dose_rates(dose_rates, title, filename, out_dir):\n",
    "    \"\"\"Plot dose rate evolution for multiple isotopes.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for iso, dr in dose_rates.items():\n",
    "        plt.plot(time_steps, dr, label=f\"{iso} Dose Rate (rads/h)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Dose Rate (rads/h)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(out_dir, filename))\n",
    "    plt.close()\n",
    "\n",
    "def plot_accumulated_dose(total_dose, title, filename, out_dir):\n",
    "    \"\"\"Plot total accumulated dose as a function of time.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_steps, total_dose, label=\"Total Accumulated Dose (rads)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Accumulated Dose (rads)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(out_dir, filename))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3569061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Dose Rates (Sphere) ===\n",
      "[INFO] CSV por clase ya existen.\n",
      "[INFO] CSV total acumulado ya existe. Recargando valores…\n",
      "\n",
      "=== Batch 2 — Dose Rates (Sphere) ===\n",
      "[INFO] CSV por clase ya existen.\n",
      "[INFO] CSV total acumulado ya existe. Recargando valores…\n",
      "\n",
      "=== Batch 3 — Dose Rates (Sphere) ===\n",
      "[INFO] CSV por clase ya existen.\n",
      "[INFO] CSV total acumulado ya existe. Recargando valores…\n",
      "\n",
      "=== Batch 4 — Dose Rates (Sphere) ===\n",
      "[INFO] CSV por clase ya existen.\n",
      "[INFO] CSV total acumulado ya existe. Recargando valores…\n",
      "\n",
      "=== Batch 5 — Dose Rates (Sphere) ===\n",
      "[INFO] CSV por clase ya existen.\n",
      "[INFO] CSV total acumulado ya existe. Recargando valores…\n",
      "\n",
      "=== Batch 6 — Dose Rates (Sphere) ===\n",
      "[INFO] CSV por clase ya existen.\n",
      "[INFO] CSV total acumulado ya existe. Recargando valores…\n",
      "\n",
      "=== Batch 7 — Dose Rates (Sphere) ===\n",
      "[INFO] CSV por clase ya existen.\n",
      "[INFO] CSV total acumulado ya existe. Recargando valores…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: CALCULATION OR LOADING OF DOSE RATE (Sphere Hypothesis)\n",
    "# ===============================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Dose Rates (Sphere) ===\")\n",
    "\n",
    "    # 1) Output directories and control volume\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    plots_dir = os.path.join(output_directory, 'dose_rate_plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    V = V_values[batch_num]\n",
    "\n",
    "    # 2) Reload ACTIVITIES and GAMMA ENERGIES from CSV\n",
    "    all_class_activities = {}\n",
    "    average_gamma_energies = {}\n",
    "    for class_num in range(1, 10):\n",
    "        # Activities\n",
    "        act_csv = os.path.join(output_directory, f\"class_{class_num}_activities.csv\")\n",
    "        df_act = pd.read_csv(act_csv)\n",
    "        isotopes = df_act.columns.tolist()[1:]\n",
    "        all_class_activities[class_num] = {iso: df_act[iso].values for iso in isotopes}\n",
    "        # Gamma energies\n",
    "        gam_csv = os.path.join(output_directory, f\"class_{class_num}_average_gamma_energy.csv\")\n",
    "        df_g = pd.read_csv(gam_csv)\n",
    "        average_gamma_energies[class_num] = df_g[\"Average Gamma Energy (MeV)\"].values\n",
    "\n",
    "    # 3) Geometric parameters\n",
    "    R_sphere = ((3 * V) / (4 * np.pi)) ** (1 / 3)\n",
    "    density = 0.001  # g/cm³\n",
    "\n",
    "    # 4) Check for per-class CSV files\n",
    "    class_csvs = [f\"dose_rate_sphere_class_{i}.csv\" for i in range(1, 10)]\n",
    "    have_class = all(fn in os.listdir(plots_dir) for fn in class_csvs)\n",
    "\n",
    "    # 5) Check for total accumulated CSV\n",
    "    total_csv = \"total_accumulated_dose_sphere_all_classes.csv\"\n",
    "    have_total = total_csv in os.listdir(plots_dir)\n",
    "\n",
    "    total_accumulated = np.zeros(len(time_steps))\n",
    "\n",
    "    # If any per-class CSVs are missing, recalculate all\n",
    "    if not have_class:\n",
    "        print(\"[INFO] Missing per-class dose rate CSVs → recalculating everything…\")\n",
    "        for class_num, isotopes in class_inventories.items():\n",
    "            acts = all_class_activities[class_num]\n",
    "            energies = average_gamma_energies[class_num]\n",
    "\n",
    "            dose_rates = {iso: np.zeros(len(time_steps)) for iso in isotopes}\n",
    "            total_per_time = np.zeros(len(time_steps))\n",
    "\n",
    "            for i, t in enumerate(time_steps):\n",
    "                E = energies[i]\n",
    "                if E <= 0:\n",
    "                    continue\n",
    "                step_sum = 0.0\n",
    "                for iso in isotopes:\n",
    "                    A = acts.get(iso, np.zeros(len(time_steps)))[i]\n",
    "                    if A <= 0:\n",
    "                        continue\n",
    "                    mu = mass_att(E)\n",
    "                    sigma = max(1e-4, mass_ab(E))\n",
    "                    if mu == 0:\n",
    "                        continue\n",
    "                    flux = (3.7e10) * (A / (V * density * mu)) * (1 - np.exp(-density * R_sphere * mu))\n",
    "                    dr = 5.77e-5 * flux * E * sigma\n",
    "                    dose_rates[iso][i] = dr\n",
    "                    step_sum += dr\n",
    "                total_per_time[i] = step_sum / 3600  # convert to rads/h\n",
    "\n",
    "            # Accumulate into total dose\n",
    "            acc = 0.0\n",
    "            for i in range(len(time_steps)):\n",
    "                acc += total_per_time[i]\n",
    "                total_accumulated[i] += acc\n",
    "\n",
    "            # Save per-class CSV\n",
    "            out_csv = os.path.join(plots_dir, f\"dose_rate_sphere_class_{class_num}.csv\")\n",
    "            with open(out_csv, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"Time (s)\"] + list(dose_rates.keys()))\n",
    "                for j, tt in enumerate(time_steps):\n",
    "                    writer.writerow([tt] + [dose_rates[iso][j] for iso in dose_rates])\n",
    "\n",
    "            # Plot per-class dose rates\n",
    "            plot_dose_rates(\n",
    "                dose_rates,\n",
    "                f\"Dose Rates (Sphere) - Class {class_num}\",\n",
    "                f\"dose_rates_sphere_class_{class_num}.png\",\n",
    "                out_dir=plots_dir\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] Per-class CSVs already exist.\")\n",
    "        # Reload and accumulate\n",
    "        for class_num in range(1, 10):\n",
    "            df_dr = pd.read_csv(os.path.join(plots_dir, f\"dose_rate_sphere_class_{class_num}.csv\"))\n",
    "            isot = df_dr.columns.tolist()[1:]\n",
    "            drs = {iso: df_dr[iso].values for iso in isot}\n",
    "\n",
    "            acc = 0.0\n",
    "            for i in range(len(time_steps)):\n",
    "                step = sum(drs[iso][i] for iso in isot) / 3600\n",
    "                acc += step\n",
    "                total_accumulated[i] += acc\n",
    "\n",
    "    # 6) Save or reload the total accumulated CSV\n",
    "    total_path = os.path.join(plots_dir, total_csv)\n",
    "    if not have_total:\n",
    "        print(\"[INFO] Missing total accumulated CSV → generating now…\")\n",
    "        with open(total_path, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "            for tt, val in zip(time_steps, total_accumulated):\n",
    "                w.writerow([tt, val])\n",
    "    else:\n",
    "        print(\"[INFO] Total accumulated CSV already exists. Reloading values…\")\n",
    "        df_tot = pd.read_csv(total_path)\n",
    "        total_accumulated = df_tot[\"Accumulated_Dose (rads)\"].values\n",
    "\n",
    "    # 7) Plot total accumulated dose\n",
    "    plot_accumulated_dose(\n",
    "        total_accumulated,\n",
    "        f\"Total Accumulated Dose (Sphere) - Batch {batch_num}\",\n",
    "        f\"total_accumulated_dose_sphere_batch_{batch_num}.png\",\n",
    "        out_dir=plots_dir\n",
    "    )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81448689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Circular Base Method ===\n",
      "[INFO] CSV por clase existen → recargando dose rates desde CSV…\n",
      "[Batch 1] Dose rates recargados.\n",
      "[INFO] CSV total acumulado ya existe → recargando…\n",
      "\n",
      "=== Batch 2 — Circular Base Method ===\n",
      "[INFO] CSV por clase existen → recargando dose rates desde CSV…\n",
      "[Batch 2] Dose rates recargados.\n",
      "[INFO] CSV total acumulado ya existe → recargando…\n",
      "\n",
      "=== Batch 3 — Circular Base Method ===\n",
      "[INFO] CSV por clase existen → recargando dose rates desde CSV…\n",
      "[Batch 3] Dose rates recargados.\n",
      "[INFO] CSV total acumulado ya existe → recargando…\n",
      "\n",
      "=== Batch 4 — Circular Base Method ===\n",
      "[INFO] CSV por clase existen → recargando dose rates desde CSV…\n",
      "[Batch 4] Dose rates recargados.\n",
      "[INFO] CSV total acumulado ya existe → recargando…\n",
      "\n",
      "=== Batch 5 — Circular Base Method ===\n",
      "[INFO] CSV por clase existen → recargando dose rates desde CSV…\n",
      "[Batch 5] Dose rates recargados.\n",
      "[INFO] CSV total acumulado ya existe → recargando…\n",
      "\n",
      "=== Batch 6 — Circular Base Method ===\n",
      "[INFO] CSV por clase existen → recargando dose rates desde CSV…\n",
      "[Batch 6] Dose rates recargados.\n",
      "[INFO] CSV total acumulado ya existe → recargando…\n",
      "\n",
      "=== Batch 7 — Circular Base Method ===\n",
      "[INFO] CSV por clase existen → recargando dose rates desde CSV…\n",
      "[Batch 7] Dose rates recargados.\n",
      "[INFO] CSV total acumulado ya existe → recargando…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special as sp\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: CALCULATION OR LOADING OF DOSE RATE (Circular Base Method)\n",
    "# ===============================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Circular Base Method ===\")\n",
    "\n",
    "    # 1) Output directory and control volume\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    plots_dir = os.path.join(output_directory, 'dose_rate_plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    V = V_values[batch_num]\n",
    "\n",
    "    # 2) Reload ACTIVITIES from CSV\n",
    "    all_class_activities = {}\n",
    "    for class_num in range(1, 10):\n",
    "        act_csv = os.path.join(output_directory, f\"class_{class_num}_activities.csv\")\n",
    "        df_act = pd.read_csv(act_csv)\n",
    "        isotopes = df_act.columns.tolist()[1:]\n",
    "        all_class_activities[class_num] = {iso: df_act[iso].values for iso in isotopes}\n",
    "\n",
    "    # 3) Reload AVERAGE GAMMA ENERGIES from CSV\n",
    "    average_gamma_energies = {}\n",
    "    for class_num in range(1, 10):\n",
    "        gam_csv = os.path.join(output_directory, f\"class_{class_num}_average_gamma_energy.csv\")\n",
    "        df_g = pd.read_csv(gam_csv)\n",
    "        average_gamma_energies[class_num] = df_g[\"Average Gamma Energy (MeV)\"].values\n",
    "\n",
    "    # 4) Parameters and total accumulator\n",
    "    total_accumulated_csv = f\"total_accumulated_dose_cb_batch_{batch_num}.csv\"\n",
    "    total_accumulated_path = os.path.join(plots_dir, total_accumulated_csv)\n",
    "\n",
    "    total_accumulated_dose_cb = np.zeros(len(time_steps))\n",
    "    h_base = 25  # cm\n",
    "    R_base = 15  # cm\n",
    "\n",
    "    # 5) Check if per-class recalculation is needed\n",
    "    expected = [f\"dose_rate_circular_base_class_{i}.csv\" for i in range(1, 10)]\n",
    "    need_recalc = not all(fn in os.listdir(plots_dir) for fn in expected)\n",
    "\n",
    "    if need_recalc:\n",
    "        print(\"[INFO] Missing per-class CSV files → calculating dose rates (Circular Base)…\")\n",
    "        for class_num, isotopes in class_inventories.items():\n",
    "            acts = all_class_activities[class_num]\n",
    "            energies = average_gamma_energies[class_num]\n",
    "\n",
    "            # Per-class buffers\n",
    "            dose_rates_cb = {iso: np.zeros(len(time_steps)) for iso in isotopes}\n",
    "            total_per_timestep = np.zeros(len(time_steps))\n",
    "\n",
    "            for i, t in enumerate(time_steps):\n",
    "                E = energies[i]\n",
    "                if E <= 0:\n",
    "                    continue\n",
    "                sum_step = 0.0\n",
    "                for iso in isotopes:\n",
    "                    A = acts.get(iso, np.zeros(len(time_steps)))[i]\n",
    "                    if A <= 0:\n",
    "                        continue\n",
    "                    mu = mass_att(E)\n",
    "                    sigma = max(1e-4, mass_ab(E))\n",
    "                    if mu == 0:\n",
    "                        continue\n",
    "\n",
    "                    flux = gamma_flux_circular_base(A, R_base, h_base, mass_att, E)\n",
    "                    dr = 5.77e-5 * flux * E * sigma\n",
    "                    if np.isnan(dr):\n",
    "                        continue\n",
    "\n",
    "                    dose_rates_cb[iso][i] = dr\n",
    "                    sum_step += dr / 3600  # convert to rads/s\n",
    "\n",
    "                total_per_timestep[i] = sum_step\n",
    "\n",
    "            # Accumulated dose per class\n",
    "            acc = 0.0\n",
    "            for i in range(len(time_steps)):\n",
    "                acc += total_per_timestep[i]\n",
    "                total_accumulated_dose_cb[i] += acc\n",
    "\n",
    "            # Save per-class CSV\n",
    "            out_csv = os.path.join(plots_dir, f\"dose_rate_circular_base_class_{class_num}.csv\")\n",
    "            with open(out_csv, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\"] + list(dose_rates_cb.keys()))\n",
    "                for j, t in enumerate(time_steps):\n",
    "                    w.writerow([t] + [dose_rates_cb[iso][j] for iso in isotopes])\n",
    "\n",
    "            # Plot per-class dose rate\n",
    "            plot_dose_rates(\n",
    "                dose_rates_cb,\n",
    "                f\"Dose Rates (Circular Base) - Class {class_num}\",\n",
    "                f\"dose_rates_circular_base_class_{class_num}.png\",\n",
    "                out_dir=plots_dir\n",
    "            )\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Per-class dose rates calculated.\")\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] Per-class CSV files exist → reloading dose rates from CSV…\")\n",
    "        for class_num in range(1, 10):\n",
    "            df_cb = pd.read_csv(os.path.join(plots_dir, f\"dose_rate_circular_base_class_{class_num}.csv\"))\n",
    "            isot = df_cb.columns.tolist()[1:]\n",
    "            drs = {iso: df_cb[iso].values for iso in isot}\n",
    "\n",
    "            acc = 0.0\n",
    "            for i in range(len(time_steps)):\n",
    "                step = sum(drs[iso][i] for iso in isot) / 3600\n",
    "                acc += step\n",
    "                total_accumulated_dose_cb[i] += acc\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Dose rates successfully reloaded.\")\n",
    "\n",
    "    # 6) Check if total accumulated CSV exists\n",
    "    if not os.path.exists(total_accumulated_path):\n",
    "        print(\"[INFO] Missing total accumulated CSV → generating it now…\")\n",
    "        with open(total_accumulated_path, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "            for tt, val in zip(time_steps, total_accumulated_dose_cb):\n",
    "                w.writerow([tt, val])\n",
    "    else:\n",
    "        print(\"[INFO] Total accumulated CSV already exists → reloading…\")\n",
    "        df_tot = pd.read_csv(total_accumulated_path)\n",
    "        total_accumulated_dose_cb = df_tot[\"Accumulated_Dose (rads)\"].values\n",
    "\n",
    "    # 7) Plot total accumulated dose for this batch\n",
    "    plot_accumulated_dose(\n",
    "        total_accumulated_dose_cb,\n",
    "        f\"Total Accumulated Dose (Circular Base) - Batch {batch_num}\",\n",
    "        f\"total_accumulated_dose_circular_base_batch_{batch_num}.png\",\n",
    "        out_dir=plots_dir\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e69bd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Circular Base + Shielding ===\n",
      "[INFO] CSV por clase existen → recargando Shielding desde CSV…\n",
      "[Batch 1] Shielding recargado.\n",
      "[INFO] CSV total acumulado existe → recargando…\n",
      "\n",
      "=== Batch 2 — Circular Base + Shielding ===\n",
      "[INFO] CSV por clase existen → recargando Shielding desde CSV…\n",
      "[Batch 2] Shielding recargado.\n",
      "[INFO] CSV total acumulado existe → recargando…\n",
      "\n",
      "=== Batch 3 — Circular Base + Shielding ===\n",
      "[INFO] CSV por clase existen → recargando Shielding desde CSV…\n",
      "[Batch 3] Shielding recargado.\n",
      "[INFO] CSV total acumulado existe → recargando…\n",
      "\n",
      "=== Batch 4 — Circular Base + Shielding ===\n",
      "[INFO] CSV por clase existen → recargando Shielding desde CSV…\n",
      "[Batch 4] Shielding recargado.\n",
      "[INFO] CSV total acumulado existe → recargando…\n",
      "\n",
      "=== Batch 5 — Circular Base + Shielding ===\n",
      "[INFO] CSV por clase existen → recargando Shielding desde CSV…\n",
      "[Batch 5] Shielding recargado.\n",
      "[INFO] CSV total acumulado existe → recargando…\n",
      "\n",
      "=== Batch 6 — Circular Base + Shielding ===\n",
      "[INFO] CSV por clase existen → recargando Shielding desde CSV…\n",
      "[Batch 6] Shielding recargado.\n",
      "[INFO] CSV total acumulado existe → recargando…\n",
      "\n",
      "=== Batch 7 — Circular Base + Shielding ===\n",
      "[INFO] CSV por clase existen → recargando Shielding desde CSV…\n",
      "[Batch 7] Shielding recargado.\n",
      "[INFO] CSV total acumulado existe → recargando…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: CALCULATION OR LOADING OF DOSE RATE (Circular Base + Shielding)\n",
    "# ===============================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Circular Base + Shielding ===\")\n",
    "\n",
    "    # 1) Output directory and control volume\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    plots_dir = os.path.join(output_directory, 'dose_rate_plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    V = V_values[batch_num]\n",
    "\n",
    "    # 2) Reload ACTIVITIES from CSV\n",
    "    all_class_activities = {}\n",
    "    for class_num in range(1, 10):\n",
    "        df = pd.read_csv(os.path.join(output_directory, f\"class_{class_num}_activities.csv\"))\n",
    "        isos = df.columns.tolist()[1:]\n",
    "        all_class_activities[class_num] = {iso: df[iso].values for iso in isos}\n",
    "\n",
    "    # 3) Reload GAMMA ENERGIES from CSV\n",
    "    average_gamma_energies = {}\n",
    "    for class_num in range(1, 10):\n",
    "        df = pd.read_csv(os.path.join(output_directory, f\"class_{class_num}_average_gamma_energy.csv\"))\n",
    "        average_gamma_energies[class_num] = df[\"Average Gamma Energy (MeV)\"].values\n",
    "\n",
    "    # 4) Geometrical parameters, material properties, and total accumulator\n",
    "    total_acc_csv = f\"total_accumulated_dose_shield_batch_{batch_num}.csv\"\n",
    "    total_acc_path = os.path.join(plots_dir, total_acc_csv)\n",
    "\n",
    "    total_accumulated_dose_shield = np.zeros(len(time_steps))\n",
    "    cylinder_radius = 15   # cm\n",
    "    cylinder_height = 80   # cm\n",
    "    R_shield = math.sqrt(2 * cylinder_radius * cylinder_height)\n",
    "    density_polymer = 0.92  # g/cm³\n",
    "    shield_thickness = 3    # cm\n",
    "\n",
    "    def linear_att(E_keV, rho):\n",
    "        \"\"\"Linear attenuation coefficient as μ = μm(E) * ρ\"\"\"\n",
    "        return calcular_mu_m(E_keV) * rho\n",
    "\n",
    "    # 5) Check if per-class recalculation is needed\n",
    "    expected = [f\"dose_rate_shield_class_{i}.csv\" for i in range(1, 10)]\n",
    "    need_recalc = not all(fn in os.listdir(plots_dir) for fn in expected)\n",
    "\n",
    "    if need_recalc:\n",
    "        print(\"[INFO] Missing per-class CSVs → calculating Shielding…\")\n",
    "        for class_num, isotopes in class_inventories.items():\n",
    "            acts = all_class_activities[class_num]\n",
    "            energies = average_gamma_energies[class_num]\n",
    "\n",
    "            dose_rates_shield = {iso: np.zeros(len(time_steps)) for iso in isotopes}\n",
    "            timestep_dose = np.zeros(len(time_steps))\n",
    "\n",
    "            for i, t in enumerate(time_steps):\n",
    "                E = energies[i]\n",
    "                if E <= 0:\n",
    "                    continue\n",
    "\n",
    "                for iso in isotopes:\n",
    "                    A = acts.get(iso, np.zeros(len(time_steps)))[i]\n",
    "                    if A <= 0:\n",
    "                        continue\n",
    "\n",
    "                    mu = mass_att(E)\n",
    "                    sigma = max(1e-4, mass_ab(E))\n",
    "                    if mu == 0:\n",
    "                        continue\n",
    "\n",
    "                    flux = gamma_flux_circular_base(A, R_shield, shield_thickness, mass_att, E)\n",
    "                    dr = 5.77e-5 * flux * E * sigma\n",
    "                    dr_sh = dr * np.exp(-linear_att(E * 1000, density_polymer) * shield_thickness)\n",
    "\n",
    "                    if np.isnan(dr_sh):\n",
    "                        continue\n",
    "\n",
    "                    dose_rates_shield[iso][i] = dr_sh\n",
    "                    timestep_dose[i] += dr_sh / 3600  # rads/s\n",
    "\n",
    "            # Accumulate per class\n",
    "            acc = np.cumsum(timestep_dose)\n",
    "            total_accumulated_dose_shield += acc\n",
    "\n",
    "            # Save per-class CSV\n",
    "            out_csv = os.path.join(plots_dir, f\"dose_rate_shield_class_{class_num}.csv\")\n",
    "            with open(out_csv, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                iso_names = list(isotopes.keys())\n",
    "                w.writerow([\"Time (s)\"] + iso_names)\n",
    "                for j, t in enumerate(time_steps):\n",
    "                    w.writerow([t] + [dose_rates_shield[iso][j] for iso in iso_names])\n",
    "\n",
    "            # Plot per-class dose rates\n",
    "            plot_dose_rates(\n",
    "                dose_rates_shield,\n",
    "                f\"Dose Rates (Shielding) - Class {class_num}\",\n",
    "                f\"dose_rate_shield_class_{class_num}.png\",\n",
    "                out_dir=plots_dir\n",
    "            )\n",
    "            print(f\"  Class {class_num} → final accumulated dose: {acc[-1]:.2f} rads\")\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Shielding calculated.\")\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] Per-class CSVs exist → reloading Shielding from CSV…\")\n",
    "        for class_num in range(1, 10):\n",
    "            df = pd.read_csv(os.path.join(plots_dir, f\"dose_rate_shield_class_{class_num}.csv\"))\n",
    "            isos = df.columns.tolist()[1:]\n",
    "            drs = {iso: df[iso].values for iso in isos}\n",
    "\n",
    "            # Accumulate\n",
    "            step = np.array([sum(drs[iso][i] for iso in isos) / 3600 for i in range(len(time_steps))])\n",
    "            total_accumulated_dose_shield += np.cumsum(step)\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Shielding successfully reloaded.\")\n",
    "\n",
    "    # 6) Total accumulated CSV\n",
    "    if not os.path.exists(total_acc_path):\n",
    "        print(\"[INFO] Missing total accumulated CSV → generating it now…\")\n",
    "        with open(total_acc_path, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "            for tt, val in zip(time_steps, total_accumulated_dose_shield):\n",
    "                w.writerow([tt, val])\n",
    "    else:\n",
    "        print(\"[INFO] Total accumulated CSV already exists → reloading…\")\n",
    "        df_tot = pd.read_csv(total_acc_path)\n",
    "        total_accumulated_dose_shield = df_tot[\"Accumulated_Dose (rads)\"].values\n",
    "\n",
    "    # 7) Plot total accumulated dose for this batch\n",
    "    plot_accumulated_dose(\n",
    "        total_accumulated_dose_shield,\n",
    "        f\"Total Accumulated Dose (Shielding) - Batch {batch_num}\",\n",
    "        f\"total_accumulated_dose_shield_batch_{batch_num}.png\",\n",
    "        out_dir=plots_dir\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dff103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Point Source Method ===\n",
      "[INFO] CSV por clase faltantes → calculando Point Source…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macario\\AppData\\Local\\Temp\\ipykernel_17048\\937954156.py:87: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(out_dir, filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 1] Point Source calculado.\n",
      "[INFO] CSV total acumulado faltante → generándolo…\n",
      "\n",
      "=== Batch 2 — Point Source Method ===\n",
      "[INFO] CSV por clase faltantes → calculando Point Source…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macario\\AppData\\Local\\Temp\\ipykernel_17048\\937954156.py:87: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(out_dir, filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 2] Point Source calculado.\n",
      "[INFO] CSV total acumulado faltante → generándolo…\n",
      "\n",
      "=== Batch 3 — Point Source Method ===\n",
      "[INFO] CSV por clase faltantes → calculando Point Source…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macario\\AppData\\Local\\Temp\\ipykernel_17048\\937954156.py:87: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(out_dir, filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 3] Point Source calculado.\n",
      "[INFO] CSV total acumulado faltante → generándolo…\n",
      "\n",
      "=== Batch 4 — Point Source Method ===\n",
      "[INFO] CSV por clase faltantes → calculando Point Source…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macario\\AppData\\Local\\Temp\\ipykernel_17048\\937954156.py:87: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(out_dir, filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 4] Point Source calculado.\n",
      "[INFO] CSV total acumulado faltante → generándolo…\n",
      "\n",
      "=== Batch 5 — Point Source Method ===\n",
      "[INFO] CSV por clase faltantes → calculando Point Source…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macario\\AppData\\Local\\Temp\\ipykernel_17048\\937954156.py:87: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(out_dir, filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 5] Point Source calculado.\n",
      "[INFO] CSV total acumulado faltante → generándolo…\n",
      "\n",
      "=== Batch 6 — Point Source Method ===\n",
      "[INFO] CSV por clase faltantes → calculando Point Source…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macario\\AppData\\Local\\Temp\\ipykernel_17048\\937954156.py:87: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(out_dir, filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 6] Point Source calculado.\n",
      "[INFO] CSV total acumulado faltante → generándolo…\n",
      "\n",
      "=== Batch 7 — Point Source Method ===\n",
      "[INFO] CSV por clase faltantes → calculando Point Source…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\macario\\AppData\\Local\\Temp\\ipykernel_17048\\937954156.py:87: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  plt.savefig(os.path.join(out_dir, filename))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Batch 7] Point Source calculado.\n",
      "[INFO] CSV total acumulado faltante → generándolo…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: CALCULATION OR LOADING OF DOSE RATE (Point Source Method)\n",
    "# ===============================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Point Source Method ===\")\n",
    "\n",
    "    # 1) Output directory and plots\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    plots_dir = os.path.join(output_directory, 'dose_rate_plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "    # 2) Reload ACTIVITIES\n",
    "    all_class_activities = {}\n",
    "    for class_num in range(1, 10):\n",
    "        df_act = pd.read_csv(os.path.join(output_directory, f\"class_{class_num}_activities.csv\"))\n",
    "        isos = df_act.columns.tolist()[1:]  # skip the time column\n",
    "        all_class_activities[class_num] = {iso: df_act[iso].values for iso in isos}\n",
    "\n",
    "    # 3) Reload AVERAGE GAMMA ENERGIES\n",
    "    average_gamma_energies = {}\n",
    "    for class_num in range(1, 10):\n",
    "        df_g = pd.read_csv(os.path.join(output_directory, f\"class_{class_num}_average_gamma_energy.csv\"))\n",
    "        average_gamma_energies[class_num] = df_g[\"Average Gamma Energy (MeV)\"].values\n",
    "\n",
    "    # 4) Parameters and total accumulator\n",
    "    total_acc_csv = f\"total_accumulated_dose_point_batch_{batch_num}.csv\"\n",
    "    total_acc_path = os.path.join(plots_dir, total_acc_csv)\n",
    "    accumulated_dose_point = np.zeros(len(time_steps))\n",
    "    h_point = 25  # cm\n",
    "\n",
    "    def gamma_flux_point_source(activity, h, mass_att_func, E):\n",
    "        \"\"\"Gamma flux for a point source with attenuation (μ * ρ * h).\"\"\"\n",
    "        mu = mass_att_func(E)\n",
    "        if mu <= 0:\n",
    "            return 0.0\n",
    "        # 3.7e10 converts Ci → disintegrations/s if the activity is given in Ci.\n",
    "        # Adjust this factor if A is already in Bq.\n",
    "        return ((3.7e10) * activity) / (4 * math.pi * h**2) * math.exp(-mu * density * h)\n",
    "\n",
    "    # 5) Check for per-class CSV files\n",
    "    expected = [f\"dose_rate_point_source_class_{i}.csv\" for i in range(1, 10)]\n",
    "    need_recalc = not all(fn in os.listdir(plots_dir) for fn in expected)\n",
    "\n",
    "    if need_recalc:\n",
    "        print(\"[INFO] Missing per-class CSVs → calculating Point Source…\")\n",
    "        for class_num, isotopes in class_inventories.items():\n",
    "            # isotopes can be a dict or list; extract the isotope names\n",
    "            if isinstance(isotopes, dict):\n",
    "                iso_names = list(isotopes.keys())\n",
    "            else:\n",
    "                iso_names = list(isotopes)\n",
    "\n",
    "            acts = all_class_activities[class_num]   # dict: iso -> activity array\n",
    "            energies = average_gamma_energies[class_num]  # array of gamma energies (MeV)\n",
    "\n",
    "            dose_rates_point = {iso: np.zeros(len(time_steps)) for iso in iso_names}\n",
    "            timestep_dose = np.zeros(len(time_steps))  # total dose rate sum at each time step\n",
    "\n",
    "            for i, t in enumerate(time_steps):\n",
    "                E = energies[i]\n",
    "                if E <= 0:\n",
    "                    continue\n",
    "                for iso in iso_names:\n",
    "                    A = acts.get(iso, np.zeros(len(time_steps)))[i]\n",
    "                    if A <= 0:\n",
    "                        continue\n",
    "                    # coefficients\n",
    "                    sigma = max(1e-4, mass_ab(E))  # effective absorption coefficient\n",
    "                    flux = gamma_flux_point_source(A, h_point, mass_att, E)\n",
    "                    dr = 5.77e-5 * flux * E * sigma  # conversion factor to dose rate\n",
    "                    if np.isnan(dr):\n",
    "                        continue\n",
    "                    dose_rates_point[iso][i] = dr\n",
    "                    timestep_dose[i] += dr / 3600.0  # rads/s → rads (1 s timestep)\n",
    "\n",
    "            # Accumulate and add to total\n",
    "            acc = np.cumsum(timestep_dose)\n",
    "            accumulated_dose_point += acc\n",
    "\n",
    "            # Save per-class CSV\n",
    "            out_csv = os.path.join(plots_dir, f\"dose_rate_point_source_class_{class_num}.csv\")\n",
    "            with open(out_csv, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\"] + iso_names)\n",
    "                for j, t in enumerate(time_steps):\n",
    "                    w.writerow([t] + [dose_rates_point[iso][j] for iso in iso_names])\n",
    "\n",
    "            # Plot per-class dose rates\n",
    "            plot_dose_rates(\n",
    "                dose_rates_point,\n",
    "                f\"Dose Rates (Point Source) - Class {class_num}\",\n",
    "                f\"dose_rate_point_source_class_{class_num}.png\",\n",
    "                out_dir=plots_dir\n",
    "            )\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Point Source dose rates calculated.\")\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] Per-class CSVs already exist → reloading Point Source from CSV…\")\n",
    "        for class_num in range(1, 10):\n",
    "            df_ps = pd.read_csv(os.path.join(plots_dir, f\"dose_rate_point_source_class_{class_num}.csv\"))\n",
    "            isos = df_ps.columns.tolist()[1:]\n",
    "            drs = {iso: df_ps[iso].values for iso in isos}\n",
    "\n",
    "            # Sum dose rates per time step and convert to rads\n",
    "            steps = np.array([sum(drs[iso][i] for iso in isos) / 3600.0 for i in range(len(time_steps))])\n",
    "            accumulated_dose_point += np.cumsum(steps)\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Point Source successfully reloaded.\")\n",
    "\n",
    "    # 6) Save or reload total accumulated CSV\n",
    "    if not os.path.exists(total_acc_path):\n",
    "        print(\"[INFO] Missing total accumulated CSV → generating it now…\")\n",
    "        with open(total_acc_path, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "            for tt, val in zip(time_steps, accumulated_dose_point):\n",
    "                w.writerow([tt, val])\n",
    "    else:\n",
    "        print(\"[INFO] Total accumulated CSV already exists → reloading…\")\n",
    "        df_tot = pd.read_csv(total_acc_path)\n",
    "        accumulated_dose_point = df_tot[\"Accumulated_Dose (rads)\"].values\n",
    "\n",
    "    # 7) Plot total accumulated dose for this batch\n",
    "    plot_accumulated_dose(\n",
    "        accumulated_dose_point,\n",
    "        f\"Total Accumulated Dose (Point Source) - Batch {batch_num}\",\n",
    "        f\"total_accumulated_dose_point_source_batch_{batch_num}.png\",\n",
    "        out_dir=plots_dir\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da5905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Damage Levels (autonomous) ===\n",
      "[Point Source] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Point Source] t=43200s | EQ=2.00e+07 | AccDose=1.11e+10 | ratio=556.56 | raw_lvl=5 | final_lvl=5\n",
      "[Point Source] t=86400s | EQ=2.40e+07 | AccDose=1.12e+10 | ratio=465.00 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[With Shield] t=43200s | EQ=2.00e+07 | AccDose=8.87e+10 | ratio=4436.59 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=86400s | EQ=2.40e+07 | AccDose=8.90e+10 | ratio=3709.69 | raw_lvl=5 | final_lvl=5\n",
      "[Sphere] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Sphere] t=43200s | EQ=2.00e+07 | AccDose=1.94e+08 | ratio=9.69 | raw_lvl=4 | final_lvl=4\n",
      "[Sphere] t=86400s | EQ=2.40e+07 | AccDose=1.94e+08 | ratio=8.09 | raw_lvl=4 | final_lvl=4\n",
      "[Circular Base] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Circular Base] t=43200s | EQ=2.00e+07 | AccDose=6.68e+09 | ratio=334.19 | raw_lvl=5 | final_lvl=5\n",
      "[Circular Base] t=86400s | EQ=2.40e+07 | AccDose=6.71e+09 | ratio=279.48 | raw_lvl=5 | final_lvl=5\n",
      "[Batch 1] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 2 — Damage Levels (autonomous) ===\n",
      "[Point Source] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Point Source] t=43200s | EQ=2.00e+07 | AccDose=5.11e+09 | ratio=255.60 | raw_lvl=5 | final_lvl=5\n",
      "[Point Source] t=86400s | EQ=2.40e+07 | AccDose=5.13e+09 | ratio=213.88 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[With Shield] t=43200s | EQ=2.00e+07 | AccDose=2.09e+10 | ratio=1046.87 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=86400s | EQ=2.40e+07 | AccDose=2.12e+10 | ratio=881.74 | raw_lvl=5 | final_lvl=5\n",
      "[Sphere] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Sphere] t=43200s | EQ=2.00e+07 | AccDose=9.82e+07 | ratio=4.91 | raw_lvl=3 | final_lvl=3\n",
      "[Sphere] t=86400s | EQ=2.40e+07 | AccDose=9.86e+07 | ratio=4.11 | raw_lvl=3 | final_lvl=3\n",
      "[Circular Base] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Circular Base] t=43200s | EQ=2.00e+07 | AccDose=1.21e+09 | ratio=60.67 | raw_lvl=5 | final_lvl=5\n",
      "[Circular Base] t=86400s | EQ=2.40e+07 | AccDose=1.23e+09 | ratio=51.30 | raw_lvl=5 | final_lvl=5\n",
      "[Batch 2] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 3 — Damage Levels (autonomous) ===\n",
      "[Point Source] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Point Source] t=43200s | EQ=2.00e+07 | AccDose=7.15e+09 | ratio=357.74 | raw_lvl=5 | final_lvl=5\n",
      "[Point Source] t=86400s | EQ=2.40e+07 | AccDose=2.87e+10 | ratio=1194.87 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[With Shield] t=43200s | EQ=2.00e+07 | AccDose=7.97e+10 | ratio=3985.36 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=86400s | EQ=2.40e+07 | AccDose=3.09e+11 | ratio=12887.29 | raw_lvl=5 | final_lvl=5\n",
      "[Sphere] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Sphere] t=43200s | EQ=2.00e+07 | AccDose=4.97e+07 | ratio=2.49 | raw_lvl=2 | final_lvl=2\n",
      "[Sphere] t=86400s | EQ=2.40e+07 | AccDose=1.99e+08 | ratio=8.30 | raw_lvl=4 | final_lvl=4\n",
      "[Circular Base] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Circular Base] t=43200s | EQ=2.00e+07 | AccDose=6.41e+09 | ratio=320.72 | raw_lvl=5 | final_lvl=5\n",
      "[Circular Base] t=86400s | EQ=2.40e+07 | AccDose=2.46e+10 | ratio=1023.96 | raw_lvl=5 | final_lvl=5\n",
      "[Batch 3] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 4 — Damage Levels (autonomous) ===\n",
      "[Point Source] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Point Source] t=43200s | EQ=2.00e+07 | AccDose=8.59e+10 | ratio=4294.29 | raw_lvl=5 | final_lvl=5\n",
      "[Point Source] t=86400s | EQ=2.40e+07 | AccDose=1.81e+11 | ratio=7525.69 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[With Shield] t=43200s | EQ=2.00e+07 | AccDose=5.76e+11 | ratio=28821.43 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=86400s | EQ=2.40e+07 | AccDose=1.59e+12 | ratio=66211.77 | raw_lvl=5 | final_lvl=5\n",
      "[Sphere] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Sphere] t=43200s | EQ=2.00e+07 | AccDose=1.11e+08 | ratio=5.57 | raw_lvl=3 | final_lvl=3\n",
      "[Sphere] t=86400s | EQ=2.40e+07 | AccDose=2.37e+08 | ratio=9.86 | raw_lvl=4 | final_lvl=4\n",
      "[Circular Base] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Circular Base] t=43200s | EQ=2.00e+07 | AccDose=4.17e+10 | ratio=2086.61 | raw_lvl=5 | final_lvl=5\n",
      "[Circular Base] t=86400s | EQ=2.40e+07 | AccDose=1.22e+11 | ratio=5079.51 | raw_lvl=5 | final_lvl=5\n",
      "[Batch 4] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 5 — Damage Levels (autonomous) ===\n",
      "[Point Source] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Point Source] t=43200s | EQ=2.00e+07 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Point Source] t=86400s | EQ=2.40e+07 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[With Shield] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[With Shield] t=43200s | EQ=2.00e+07 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[With Shield] t=86400s | EQ=2.40e+07 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Sphere] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Sphere] t=43200s | EQ=2.00e+07 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Sphere] t=86400s | EQ=2.40e+07 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Circular Base] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Circular Base] t=43200s | EQ=2.00e+07 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Circular Base] t=86400s | EQ=2.40e+07 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Batch 5] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 6 — Damage Levels (autonomous) ===\n",
      "[Point Source] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Point Source] t=43200s | EQ=2.00e+07 | AccDose=1.01e+11 | ratio=5061.05 | raw_lvl=5 | final_lvl=5\n",
      "[Point Source] t=86400s | EQ=2.40e+07 | AccDose=1.25e+11 | ratio=5196.70 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[With Shield] t=43200s | EQ=2.00e+07 | AccDose=2.45e+11 | ratio=12256.49 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=86400s | EQ=2.40e+07 | AccDose=3.02e+11 | ratio=12576.29 | raw_lvl=5 | final_lvl=5\n",
      "[Sphere] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Sphere] t=43200s | EQ=2.00e+07 | AccDose=4.31e+02 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Sphere] t=86400s | EQ=2.40e+07 | AccDose=5.26e+02 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Circular Base] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Circular Base] t=43200s | EQ=2.00e+07 | AccDose=9.95e+09 | ratio=497.33 | raw_lvl=5 | final_lvl=5\n",
      "[Circular Base] t=86400s | EQ=2.40e+07 | AccDose=1.28e+10 | ratio=532.66 | raw_lvl=5 | final_lvl=5\n",
      "[Batch 6] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 7 — Damage Levels (autonomous) ===\n",
      "[Point Source] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Point Source] t=43200s | EQ=2.00e+07 | AccDose=7.70e+10 | ratio=3850.95 | raw_lvl=5 | final_lvl=5\n",
      "[Point Source] t=86400s | EQ=2.40e+07 | AccDose=2.24e+11 | ratio=9327.76 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[With Shield] t=43200s | EQ=2.00e+07 | AccDose=7.92e+11 | ratio=39603.48 | raw_lvl=5 | final_lvl=5\n",
      "[With Shield] t=86400s | EQ=2.40e+07 | AccDose=2.37e+12 | ratio=98550.20 | raw_lvl=5 | final_lvl=5\n",
      "[Sphere] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Sphere] t=43200s | EQ=2.00e+07 | AccDose=1.01e+08 | ratio=5.06 | raw_lvl=3 | final_lvl=3\n",
      "[Sphere] t=86400s | EQ=2.40e+07 | AccDose=2.95e+08 | ratio=12.28 | raw_lvl=5 | final_lvl=5\n",
      "[Circular Base] t=3600s | EQ=4.00e+06 | AccDose=0.00e+00 | ratio=0.00 | raw_lvl=1 | final_lvl=1\n",
      "[Circular Base] t=43200s | EQ=2.00e+07 | AccDose=6.29e+10 | ratio=3146.68 | raw_lvl=5 | final_lvl=5\n",
      "[Circular Base] t=86400s | EQ=2.40e+07 | AccDose=1.88e+11 | ratio=7813.48 | raw_lvl=5 | final_lvl=5\n",
      "[Batch 7] Damage Levels generated! ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: DAMAGE LEVELS (autonomous calculation/load)\n",
    "# ===============================================\n",
    "eq_data = [\n",
    "    (3600,    4e6),    # 1 hour\n",
    "    (43200,   2e7),    # 12 hours\n",
    "    (86400,   2.4e7),  # 1 day\n",
    "    (864000,  4e7),    # 10 days\n",
    "    (2592000, 5.5e7),  # 1 month\n",
    "    (15552000,1.1e8),  # 6 months\n",
    "    (31536000,1.5e8)   # 1 year\n",
    "]\n",
    "\n",
    "def level_from_ratio(r):\n",
    "    if r < 1:\n",
    "        return 1\n",
    "    elif r < 4:\n",
    "        return 2\n",
    "    elif r < 7:\n",
    "        return 3\n",
    "    elif r < 10:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "def calculate_damage_level(acc_dose, EQ, current_level):\n",
    "    ratio = acc_dose / EQ if EQ > 0 else float('inf')\n",
    "    lvl = level_from_ratio(ratio)\n",
    "    return lvl, ratio, lvl   \n",
    "\n",
    "\n",
    "# ===============================================\n",
    "# MAIN LOOP\n",
    "# ===============================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Damage Levels (autonomous) ===\")\n",
    "\n",
    "    out_levels_dir = f\"damage_levels_{batch_num}\"\n",
    "    csv_levels_dir = os.path.join(out_levels_dir, \"csv_data\")\n",
    "    os.makedirs(csv_levels_dir, exist_ok=True)\n",
    "\n",
    "    max_t = time_steps.max()\n",
    "    segments = [(t, EQ) for t, EQ in eq_data if t <= max_t]\n",
    "\n",
    "    dose_methods = {\n",
    "        \"Point Source\":      \"dose_rate_point_source_class_\",\n",
    "        \"With Shield\":       \"dose_rate_shield_class_\",\n",
    "        \"Sphere\":            \"dose_rate_sphere_class_\",\n",
    "        \"Circular Base\":     \"dose_rate_circular_base_class_\",\n",
    "    }\n",
    "    accumulated = {}\n",
    "\n",
    "    for label, prefix in dose_methods.items():\n",
    "        plots_dir = os.path.join(f\"output_batch_{batch_num}\", \"dose_rate_plots\")\n",
    "        total_csv = os.path.join(plots_dir, f\"total_accumulated_{label.replace(' ', '_')}.csv\")\n",
    "\n",
    "        if os.path.exists(total_csv):\n",
    "            data = np.loadtxt(total_csv, delimiter=',', skiprows=1, usecols=1)\n",
    "            accumulated[label] = data\n",
    "        else:\n",
    "            cum_sum = np.zeros(len(time_steps))\n",
    "            for class_num in range(1, 10):\n",
    "                file_i = os.path.join(plots_dir, f\"{prefix}{class_num}.csv\")\n",
    "                if not os.path.exists(file_i):\n",
    "                    raise FileNotFoundError(f\"Missing {file_i}\")\n",
    "                arr = np.loadtxt(file_i, delimiter=',', skiprows=1)[:, 1:]\n",
    "                step = arr.sum(axis=1) / 3600.0\n",
    "                cum = np.cumsum(step)\n",
    "                cum_sum += cum\n",
    "            with open(total_csv, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "                for t, val in zip(time_steps, cum_sum):\n",
    "                    w.writerow([t, val])\n",
    "            accumulated[label] = cum_sum\n",
    "\n",
    "    # ===============================================\n",
    "    # CSV + PLOTTING + DEBUG PRINTS\n",
    "    # ===============================================\n",
    "    for label, dose_arr in accumulated.items():\n",
    "        key = label.replace(' ', '_').lower()\n",
    "        csv_out = os.path.join(csv_levels_dir, f\"{key}_dose_data.csv\")\n",
    "        png_out = os.path.join(out_levels_dir, f\"damage_level_{key}.png\")\n",
    "        damage_csv_out = os.path.join(csv_levels_dir, f\"{key}_damage_levels.csv\")\n",
    "\n",
    "        if not os.path.exists(csv_out):\n",
    "            with open(csv_out, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time Step (s)\", \"Accumulated Dose (rads)\"])\n",
    "                for t, val in zip(time_steps, dose_arr):\n",
    "                    w.writerow([t, val])\n",
    "\n",
    "        levels = []\n",
    "        segment_labels = []\n",
    "        current = 1\n",
    "        prev = 0\n",
    "        for seg_t, EQ in segments:\n",
    "            idx = np.searchsorted(time_steps, seg_t)\n",
    "            acc_val = dose_arr[idx-1 if idx > 0 else 0]\n",
    "\n",
    "            # calculate level + debug info\n",
    "            new_level, ratio, raw_lvl = calculate_damage_level(acc_val, EQ, current)\n",
    "\n",
    "            # DEBUG PRINT\n",
    "            print(f\"[{label}] t={seg_t}s | EQ={EQ:.2e} | AccDose={acc_val:.2e} \"\n",
    "                  f\"| ratio={ratio:.2f} | raw_lvl={raw_lvl} | final_lvl={new_level}\")\n",
    "\n",
    "            current = new_level\n",
    "            levels.append(current)\n",
    "\n",
    "            if seg_t < 86400:\n",
    "                segment_labels.append(f\"{int(prev/3600)}-{int(seg_t/3600)}h\")\n",
    "            else:\n",
    "                segment_labels.append(f\"{int(prev/86400)}-{int(seg_t/86400)}d\")\n",
    "            prev = seg_t\n",
    "\n",
    "        with open(damage_csv_out, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Segment\", \"Time (s)\", \"Interval\", \"Damage Level\"])\n",
    "            for i, ((seg_t, _), label_str, level) in enumerate(zip(segments, segment_labels, levels)):\n",
    "                w.writerow([i + 1, seg_t, label_str, level])\n",
    "\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        x = list(range(len(levels)))\n",
    "        plt.plot(x, levels, drawstyle='steps-post', linewidth=2.5, marker='o', markersize=4)\n",
    "        plt.title(f\"Damage Levels — {label} (Batch {batch_num})\")\n",
    "        plt.xlabel(\"Segment\")\n",
    "        plt.ylabel(\"Damage Level (1–5)\")\n",
    "        plt.ylim(1, 6)             # always 1–5 + headroom\n",
    "        plt.yticks([1, 2, 3, 4, 5])\n",
    "        plt.xticks(range(len(segment_labels)), segment_labels, rotation=45, ha='right')\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(png_out)\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"[Batch {batch_num}] Damage Levels generated! ✅\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7adf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import os            \n",
    "import matplotlib.pyplot as plt  \n",
    "import numpy as np   \n",
    "\n",
    "# ============================\n",
    "# 1) Import the level CSV files\n",
    "# ============================\n",
    "df1 = pd.read_csv(\"sphere_damage_levels_1.csv\")\n",
    "df4 = pd.read_csv(\"sphere_damage_levels_4.csv\")\n",
    "df5 = pd.read_csv(\"sphere_damage_levels_5.csv\")\n",
    "df7 = pd.read_csv(\"sphere_damage_levels_7.csv\")\n",
    "\n",
    "# ===================================\n",
    "# 2) Instrumentation to location definition\n",
    "# ===================================\n",
    "instrumentation_by_location = {\n",
    "    \"WETWELL\": [\"Suppression Pool Thermocouples\"],\n",
    "    \"DRYWELL\": [\n",
    "        \"SRV Position Indicators\",\n",
    "        \"Radiation Detectors in Containment\",\n",
    "        \"Boron Injection Pressure Transmitters\",\n",
    "        \"Boron Tank Level Transmitter\",\n",
    "        \"Drywell Pressure Transmitters\",\n",
    "        \"Containment Pressure Transmitters\",\n",
    "        \"Containment Thermocouples\",\n",
    "        \"Vessel Level (Wide Range)\",\n",
    "        \"Vessel Level (Fuel Range)\",\n",
    "        \"Vessel Pressure Transmitters\",\n",
    "        \"Feedwater Flow Transmitters\",\n",
    "        \"Drywell Thermocouples\",\n",
    "        \"Radiation Detectors in Drywell\",\n",
    "        \"Control Rods Position\",\n",
    "    ],\n",
    "    \"LOWER_HEAD\": [\"Vessel Thermocouples (Lower Head)\", \"FW Thermocouples\"],\n",
    "    \"DOME\": [\"Vessel Thermocouples (Upper Head)\"],\n",
    "    \"RECIRCULATION_PUMPS\": [\n",
    "        \"Suction Pipes Thermocouples\",\n",
    "        \"Recirculation Flow Transmitters\",\n",
    "        \"Recirculation Pressure Transmitters\",\n",
    "    ],\n",
    "    \"ANNULUS\": [\"Average Reactor Power Monitors\"],\n",
    "    \"AUXILIARY_BUILDING\": [\n",
    "        \"Containment Hydrogen Concentration Analyzer\",\n",
    "        \"Drywell Hydrogen Concentration Analyzer\",\n",
    "        \"Feedwater Pressure Transmitters\",\n",
    "        \"HPCS Flow Transmitter\",\n",
    "        \"Suppression Pool Level Transmitters\",\n",
    "    ],\n",
    "    \"FUEL_BUILDING\": [],\n",
    "}\n",
    "\n",
    "# =================================\n",
    "# 3) Link the location to level CSV files\n",
    "# =================================\n",
    "level_map = {\n",
    "    \"WETWELL\": 4,\n",
    "    \"DRYWELL\": 7,\n",
    "    \"LOWER_HEAD\": 1,\n",
    "    \"DOME\": 1,\n",
    "    \"RECIRCULATION_PUMPS\": 1,\n",
    "    \"ANNULUS\": 1,\n",
    "    \"AUXILIARY_BUILDING\": 5,\n",
    "    \"FUEL_BUILDING\": 5,\n",
    "}\n",
    "\n",
    "# ==============================\n",
    "# 4) CSV to dict conversion\n",
    "# ==============================\n",
    "level_df_map = {\n",
    "    1: df1.to_dict(orient=\"records\"),\n",
    "    4: df4.to_dict(orient=\"records\"),\n",
    "    5: df5.to_dict(orient=\"records\"),\n",
    "    7: df7.to_dict(orient=\"records\"),\n",
    "}\n",
    "\n",
    "# ===================================================\n",
    "# 5) Link instrument with damage level\n",
    "# ===================================================\n",
    "damage_by_instrument = {}\n",
    "for location, instruments in instrumentation_by_location.items():\n",
    "    level = level_map[location]\n",
    "    damage_data = level_df_map[level]\n",
    "    for instr in instruments:\n",
    "        damage_by_instrument[instr] = damage_data\n",
    "\n",
    "# =========================================================\n",
    "# 6) Actions and Guides\n",
    "# =========================================================\n",
    "actions_library = {\n",
    "    \"G1_BREACH_IN_VESSEL\": {\n",
    "        \"TEMPERATURE DRYWELL\": [\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"PRESSURE DRYWELL\": [\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitters\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\",\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G2_BORON_INJECTION\": {\n",
    "        \"LEVEL BORON TANK\": [\n",
    "            \"Boron Tank Level Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"G3_SPRAY\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G4_VENTING\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "    },\n",
    "    \"G5_INJECTION_RPV\": {\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"G6_INJECTION_RPV\": {\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"G7_INJECTION_PC_UP_TO_TAF\": {\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"PRESSURE SP\": [\n",
    "            \"Suppression Pool Thermocouples\",\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitters\"\n",
    "        ]\n",
    "    },\n",
    "    \"G9_SUPPORT_VENTING_VESSEL\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G10_EVIDENCES_LOCA\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE DRYWELL\": [\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitters\"\n",
    "        ],\n",
    "        \"SUPPRESSION POOL TEMPERATURE\": [\n",
    "            \"Suppression Pool Thermocouples\",\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G12_FLOOD_RPV_UP_TO_TAF\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"SRV POSITION\": [\"SRV Position Indicators\"],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ]\n",
    "    },\n",
    "    \"G13_SUPPORT_VENTING_RPV\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"SRV POSITION\": [\"SRV Position Indicators\"],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G14_DETERMINE_INVESSEL_RETENTION\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GP\": {\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"SRV POSITION\": [\"SRV Position Indicators\"],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"PRESSURE DRYWELL\": [\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitters\"\n",
    "        ]\n",
    "    },\n",
    "    \"GQ\": {\n",
    "        \"REACTOR POWER\": [\n",
    "            \"Average Reactor Power Monitors\",\n",
    "            \"Control Rods Position\"\n",
    "        ]\n",
    "    },\n",
    "    \"GT/D\": {\n",
    "        \"TEMPERATURE DRYWELL\": [\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GT/PC\": {\n",
    "        \"TEMPERATURE CONTAINMENT\": [\n",
    "            \"Containment Thermocouples\",\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GT/SP\": {\n",
    "        \"TEMPERATURE SUPPRESSION POOL\": [\n",
    "            \"Suppression Pool Thermocouples\",\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GH/PC\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitter (Auxiliary Building)\",\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitter (Auxiliary Building)\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"GR/PC\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitter (Auxiliary Building)\",\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitter (Auxiliary Building)\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ]\n",
    "    },\n",
    "    \"GL/SP\": {\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "actions_short = { k.split(\"_\")[0]: v for k,v in actions_library.items() }\n",
    "\n",
    "\n",
    "# SAMG1 and SAMG2\n",
    "SAMG1 = {\n",
    "    \"RC_F1\": [\"G1\", \"G3\", \"G4\", \"G5\", \"G6\", \"G7\"],\n",
    "    \"RC_F2\": [\"G12\", \"G3\", \"G4\", \"G7\", \"G9\", \"G13\"],\n",
    "    \"RC_F3\": [\"G3\", \"G4\", \"G12\"],\n",
    "    \"RC_F4\": [\"G14\", \"G3\", \"G4\", \"G6\"],\n",
    "    \"RC_F5\": [\"G3\", \"G4\", \"G5\", \"G7\", \"G14\"],\n",
    "    \"RC_Q\": [\"G1\", \"G2\", \"GQ\"],\n",
    "    \"RC_P\": [\"GP\"],\n",
    "}\n",
    "\n",
    "SAMG2 = {\n",
    "    \"DW_T\": [\"GT/D\"],\n",
    "    \"CN_T\": [\"GT/PC\"],\n",
    "    \"SP_T\": [\"GT/SP\"],\n",
    "    \"PC_P\": [\"G4\"],\n",
    "    \"PC_H\": [\"GH/PC\"],\n",
    "    \"PC_R\": [\"GR/PC\"],\n",
    "    \"SP_L\": [\"GL/SP\"],\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 7) Utilities functions\n",
    "# =========================================================\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def _detect_interval_key(sample_records):\n",
    "    if not sample_records:\n",
    "        return \"Interval\"\n",
    "    keys = list(sample_records[0].keys())\n",
    "    lowmap = {k.lower(): k for k in keys}\n",
    "    for cand in [\"intervalo\", \"interval\"]:\n",
    "        if cand in lowmap:\n",
    "            return lowmap[cand]\n",
    "    for k in keys:\n",
    "        if \"interval\" in k.lower():\n",
    "            return k\n",
    "    return keys[0]\n",
    "\n",
    "def _detect_level_key(sample_records):\n",
    "    if not sample_records:\n",
    "        return \"Damage Level\"\n",
    "    keys = list(sample_records[0].keys())\n",
    "    lowmap = {k.lower(): k for k in keys}\n",
    "    for cand in [\"nivel de daño\", \"nivel_de_daño\", \"damage level\", \"damage_level\", \"damage\"]:\n",
    "        if cand in lowmap:\n",
    "            return lowmap[cand]\n",
    "    for k in keys:\n",
    "        kl = k.lower()\n",
    "        if \"damage\" in kl or \"daño\" in kl:\n",
    "            return k\n",
    "    return keys[-1]\n",
    "\n",
    "# =========================================================\n",
    "# 8) Functions to build dataframes and states\n",
    "# =========================================================\n",
    "def _levels_dataframe_for_measure(instrs, damage_by_instrument, fallback_df_records):\n",
    "    sample = next((damage_by_instrument[i] for i in instrs if i in damage_by_instrument), fallback_df_records)\n",
    "    interval_key = _detect_interval_key(sample)\n",
    "    level_key = _detect_level_key(sample)\n",
    "    intervals = [r[interval_key] for r in sample]\n",
    "    data = {interval_key: intervals}\n",
    "    for instr in instrs:\n",
    "        recs = damage_by_instrument.get(instr)\n",
    "        if not recs:\n",
    "            data[instr] = [1] * len(intervals)\n",
    "            continue\n",
    "        vals_raw = [rec.get(level_key, None) for rec in recs]\n",
    "        vals = [int(v) if v is not None and str(v).strip() != \"\" else 1 for v in vals_raw]\n",
    "        if len(vals) < len(intervals):\n",
    "            vals += [vals[-1] if vals else 1] * (len(intervals) - len(vals))\n",
    "        elif len(vals) > len(intervals):\n",
    "            vals = vals[:len(intervals)]\n",
    "        data[instr] = vals\n",
    "    df = pd.DataFrame(data)\n",
    "    return interval_key, level_key, intervals, df\n",
    "\n",
    "def _availability_dataframe_for_measure(instrs, damage_by_instrument, fallback_df_records):\n",
    "    sample = next((damage_by_instrument[i] for i in instrs if i in damage_by_instrument), fallback_df_records)\n",
    "    interval_key = _detect_interval_key(sample)\n",
    "    level_key = _detect_level_key(sample)\n",
    "    intervals = [r[interval_key] for r in sample]\n",
    "    all_levels = []\n",
    "    for instr in instrs:\n",
    "        recs = damage_by_instrument.get(instr)\n",
    "        if not recs:\n",
    "            all_levels.append([1] * len(intervals))\n",
    "        else:\n",
    "            vals_raw = [rec.get(level_key, None) for rec in recs]\n",
    "            vals = [int(v) if v is not None and str(v).strip() != \"\" else 1 for v in vals_raw]\n",
    "            if len(vals) < len(intervals):\n",
    "                vals += [vals[-1] if vals else 1] * (len(intervals) - len(vals))\n",
    "            elif len(vals) > len(intervals):\n",
    "                vals = vals[:len(intervals)]\n",
    "            all_levels.append(vals)\n",
    "    states, codes = [], []\n",
    "    for i in range(len(intervals)):\n",
    "        lvls_t = [levels[i] for levels in all_levels] if all_levels else []\n",
    "        st = _classify_state_from_levels(lvls_t)\n",
    "        states.append(st)\n",
    "        codes.append(state_map[st])\n",
    "    df = pd.DataFrame({interval_key: intervals, \"state\": states, \"state_code\": codes})\n",
    "    return interval_key, intervals, df\n",
    "\n",
    "# =========================================================\n",
    "# 9) Plotting functions\n",
    "# =========================================================\n",
    "def plot_damage(instruments, damage_by_instrument, save_path, title):\n",
    "    sample = next((damage_by_instrument[i] for i in instruments if i in damage_by_instrument), None)\n",
    "    if not sample:\n",
    "        return\n",
    "    interval_key = _detect_interval_key(sample)\n",
    "    level_key = _detect_level_key(sample)\n",
    "    intervals = [r[interval_key] for r in sample]\n",
    "    n = len(intervals)\n",
    "    b = np.arange(n + 1)\n",
    "    centers = b[:-1] + 0.5\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), dpi=100)\n",
    "    fig.patch.set_facecolor(\"#001F3F\")\n",
    "    ax.set_facecolor(\"#001F3F\")\n",
    "    markers = [\"o\", \"s\", \"D\", \"^\", \"v\", \"P\", \"X\", \"*\", \"<\", \">\"]\n",
    "    for idx, instr in enumerate(instruments):\n",
    "        data = damage_by_instrument.get(instr)\n",
    "        if not data:\n",
    "            continue\n",
    "        y_raw = [r.get(level_key, None) for r in data]\n",
    "        y = [int(v) if v is not None and str(v).strip() != \"\" else 1 for v in y_raw]\n",
    "        jitter = (idx - len(instruments) / 2) * 0.05\n",
    "        x_d, y_d = [], []\n",
    "        for i, yi in enumerate(y):\n",
    "            xs = np.linspace(b[i], b[i + 1], 50)\n",
    "            x_d.extend(xs)\n",
    "            y_d.extend([yi + jitter] * len(xs))\n",
    "        ax.plot(\n",
    "            x_d,\n",
    "            y_d,\n",
    "            marker=markers[idx % len(markers)],\n",
    "            markersize=8,\n",
    "            linewidth=2,\n",
    "            label=instr,\n",
    "            markevery=10,\n",
    "        )\n",
    "    ax.set_xticks(centers)\n",
    "    ax.set_xticklabels(intervals, rotation=45, ha=\"right\", color=\"white\", fontsize=22)\n",
    "    ax.set_ylabel(\"Damage Level\", color=\"white\", fontsize=24)\n",
    "    ax.set_yticks([1, 2, 3, 4, 5])\n",
    "    ax.set_yticklabels([1, 2, 3, 4, 5], color=\"white\", fontsize=22)\n",
    "    ax.set_title(title, color=\"white\", fontsize=36, pad=36)\n",
    "    ax.tick_params(colors=\"white\", labelsize=22)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"white\")\n",
    "    ax.grid(color=\"white\", linestyle=\"--\", alpha=0.2, linewidth=1)\n",
    "    fig.subplots_adjust(bottom=0.25)\n",
    "    ncol = len(instruments) if len(instruments) <= 2 else (len(instruments) + 1) // 2\n",
    "    leg = ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.12), ncol=ncol, frameon=False, fontsize=18)\n",
    "    for txt in leg.get_texts():\n",
    "        txt.set_color(\"white\")\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "# =========================================================\n",
    "# 10) Availability functions\n",
    "# =========================================================\n",
    "state_map = {\"Good\": 0, \"Careful\": 1, \"Warning\": 2, \"Blind\": 3}\n",
    "zone_colors = {0: \"#006400\", 1: \"#CCCC00\", 2: \"#FF8C00\", 3: \"#8B0000\"}\n",
    "\n",
    "def plot_availability(measure, intervals, states, save_path):\n",
    "    values = [state_map[s] for s in states] or [0] * len(intervals)\n",
    "    n = len(intervals)\n",
    "    fig, ax = plt.subplots(figsize=(16, 9), dpi=100)\n",
    "    fig.patch.set_facecolor(\"#001F3F\")\n",
    "    ax.set_facecolor(\"#001F3F\")\n",
    "    for lvl, col in zone_colors.items():\n",
    "        ax.axhspan(lvl, lvl + 1, color=col, alpha=0.3)\n",
    "    x_d, y_d = [], []\n",
    "    for i, v in enumerate(values):\n",
    "        xs = np.linspace(i, i + 1, 50, endpoint=False)\n",
    "        x_d.extend(xs)\n",
    "        y_d.extend([v] * len(xs))\n",
    "    x_d.append(n)\n",
    "    y_d.append(values[-1])\n",
    "    ax.plot(x_d, y_d, drawstyle=\"steps-post\", marker=\"o\", markersize=8, linewidth=2, color=\"#00CED1\")\n",
    "    centers = np.arange(n) + 0.5\n",
    "    ax.set_xticks(centers)\n",
    "    ax.set_xticklabels(intervals, rotation=45, ha=\"right\", color=\"white\", fontsize=18)\n",
    "    ax.set_yticks(list(state_map.values()))\n",
    "    ax.set_yticklabels(list(state_map.keys()), color=\"white\", fontsize=18)\n",
    "    ax.set_title(f\"{measure} Availability\", color=\"white\", fontsize=26, pad=50)\n",
    "    ax.tick_params(colors=\"white\", labelsize=18)\n",
    "    ax.grid(color=\"white\", linestyle=\"--\", alpha=0.2, linewidth=1)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"white\")\n",
    "    fig.subplots_adjust(top=0.88, bottom=0.12)\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "def _classify_state_from_levels(levels):\n",
    "    if not levels:\n",
    "        return \"Blind\"\n",
    "    lvls = [int(x) for x in levels if x is not None]\n",
    "    if all(l == 1 for l in lvls):\n",
    "        return \"Good\"\n",
    "    if all(l == 5 for l in lvls):\n",
    "        return \"Blind\"\n",
    "    if any(l in (3, 4) for l in lvls):\n",
    "        return \"Warning\"\n",
    "    if any(l == 2 for l in lvls) and all(l <= 2 for l in lvls):\n",
    "        return \"Careful\"\n",
    "    return \"Warning\"\n",
    "\n",
    "# =========================================================\n",
    "# 11) CSV and graphs generators\n",
    "# =========================================================\n",
    "def generate_graphs(samg_name, samg_dict, actions_map, damage_by_instrument):\n",
    "    create_directory(samg_name)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(samg_name, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                base = measure.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                interval_key, level_key, intervals, df_levels = _levels_dataframe_for_measure(\n",
    "                    instrs, damage_by_instrument, df1.to_dict(orient=\"records\")\n",
    "                )\n",
    "                df_levels.to_csv(os.path.join(path_code, base + \".csv\"), index=False, encoding=\"utf-8\")\n",
    "                plot_damage(instrs, damage_by_instrument, os.path.join(path_code, base + \".png\"), measure)\n",
    "\n",
    "def generate_availability(samg_name, samg_dict, actions_map, damage_by_instrument):\n",
    "    base = f\"Availability_{samg_name}\"\n",
    "    create_directory(base)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(base, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                safe = measure.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                interval_key, intervals, df_av = _availability_dataframe_for_measure(\n",
    "                    instrs, damage_by_instrument, df1.to_dict(orient=\"records\")\n",
    "                )\n",
    "                df_av.to_csv(os.path.join(path_code, safe + \"_availability.csv\"), index=False, encoding=\"utf-8\")\n",
    "                plot_availability(measure, intervals, df_av[\"state\"].tolist(), os.path.join(path_code, safe + \"_availability.png\"))\n",
    "\n",
    "# =========================================================\n",
    "# 12) Execution\n",
    "# =========================================================\n",
    "generate_graphs(\"SAMG1\", SAMG1, actions_short, damage_by_instrument)\n",
    "generate_graphs(\"SAMG2\", SAMG2, actions_short, damage_by_instrument)\n",
    "generate_availability(\"SAMG1\", SAMG1, actions_short, damage_by_instrument)\n",
    "generate_availability(\"SAMG2\", SAMG2, actions_short, damage_by_instrument)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb1eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pypost.codes.melcor import MELCOR\n",
    "\n",
    "file_path_melcor = \"MC_Step.ptf\"   \n",
    "file_index_melcor = MELCOR.openPlotFile(file_path_melcor)\n",
    "\n",
    "def cargar(var_code: str):\n",
    "    data = np.array(MELCOR.getData(file_index_melcor, var_code))\n",
    "    if data.ndim != 2 or data.shape[1] < 2:\n",
    "        raise RuntimeError(f\"Unexpected format for {var_code}: shape={data.shape}\")\n",
    "    return data[:, 0], data[:, 1]\n",
    "\n",
    "# =========================\n",
    "# Import of MELCOR variables\n",
    "# =========================\n",
    "tiempo_s, TempVapor_Wetwell = cargar(\"CVH-TVAP_305\")\n",
    "\n",
    "def cargar_misma_malla(var_code: str):\n",
    "    t, v = cargar(var_code)\n",
    "    if not np.array_equal(tiempo_s, t):\n",
    "        if np.allclose(tiempo_s, t, rtol=0, atol=1e-12):\n",
    "            return v\n",
    "        raise ValueError(f\"La malla de tiempo en {var_code} no coincide con la referencia.\")\n",
    "    return v\n",
    "\n",
    "Presion_Wetwell          = cargar_misma_malla(\"CVH-P_305\")\n",
    "TempVapor_Drywell        = cargar_misma_malla(\"CVH-TVAP_201\")\n",
    "Presion_Drywell          = cargar_misma_malla(\"CVH-P_201\")\n",
    "TempVapor_CabezaSuperior = cargar_misma_malla(\"CVH-TVAP_160\")\n",
    "Presion_CabezaSuperior   = cargar_misma_malla(\"CVH-P_160\")\n",
    "TempVapor_CabezaInferior = cargar_misma_malla(\"CVH-TVAP_120\")\n",
    "Presion_CabezaInferior   = cargar_misma_malla(\"CVH-P_120\")\n",
    "TempVapor_BombaRecir     = cargar_misma_malla(\"CVH-TVAP_106\")\n",
    "Presion_BombaRecir       = cargar_misma_malla(\"CVH-P_106\")\n",
    "\n",
    "# =========================\n",
    "# VARIABLES CONSTANTES\n",
    "# =========================\n",
    "EQ_PRESSURE = 410000   # Pa\n",
    "EQ_TEMP = 422          # K\n",
    "\n",
    "# =========================\n",
    "# CRITERIO DE FALLO DE VASIJA\n",
    "# =========================\n",
    "VESSEL_FAILURE = Presion_BombaRecir < 6_000_000  # Boolean array\n",
    "\n",
    "# =========================\n",
    "# DICCIONARIO PARA USO POSTERIOR\n",
    "# =========================\n",
    "variables_melcor = {\n",
    "    \"tiempo_s\": tiempo_s,\n",
    "    \"TempVapor_Wetwell\":        TempVapor_Wetwell,\n",
    "    \"Presion_Wetwell\":          Presion_Wetwell,\n",
    "    \"TempVapor_Drywell\":        TempVapor_Drywell,\n",
    "    \"Presion_Drywell\":          Presion_Drywell,\n",
    "    \"TempVapor_CabezaSuperior\": TempVapor_CabezaSuperior,\n",
    "    \"Presion_CabezaSuperior\":   Presion_CabezaSuperior,\n",
    "    \"TempVapor_CabezaInferior\": TempVapor_CabezaInferior,\n",
    "    \"Presion_CabezaInferior\":   Presion_CabezaInferior,\n",
    "    \"TempVapor_BombaRecir\":     TempVapor_BombaRecir,\n",
    "    \"Presion_BombaRecir\":       Presion_BombaRecir,\n",
    "    \"EQ_PRESSURE\":              EQ_PRESSURE,\n",
    "    \"EQ_TEMP\":                  EQ_TEMP,\n",
    "    \"VESSEL_FAILURE\":           VESSEL_FAILURE\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# CONTENEDOR: niveles por instrumento\n",
    "# =========================\n",
    "niveles_instrumentos = {}  # { nombre_instrumento: ndarray[int] (niveles 1..5 en cada t) }\n",
    "\n",
    "def guardar_nivel_instrumento(nombre: str, level_array: np.ndarray):\n",
    "    \"\"\"\n",
    "    Guarda la serie de niveles (1..5) a lo largo del tiempo para un instrumento.\n",
    "    \"\"\"\n",
    "    if level_array.shape != tiempo_s.shape:\n",
    "        raise ValueError(f\"Longitud de niveles de '{nombre}' no coincide con tiempo.\")\n",
    "    niveles_instrumentos[nombre] = level_array.astype(int, copy=False)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Suppression Pool Thermocouples (niveles 1–5)\n",
    "# Reglas interpretadas:\n",
    "# 1: 273–422 K (nominal)  [Estado base; no fuerza 1 si hay niveles superiores]\n",
    "# 2: CEC>EQ => T_wet > EQ_TEMP  OR  P_wet > EQ_PRESSURE\n",
    "# 3: T_wet > 673 K\n",
    "# 5: T_wet > 1530 K\n",
    "# (Nivel 4 aún sin criterio)\n",
    "# =========================\n",
    "# HISTÉRESIS TEMPORAL (30 min para bajar de nivel)\n",
    "# =========================\n",
    "def aplicar_histeresis(tiempo, niveles_condiciones, retardo_bajada_s):\n",
    "    \"\"\"\n",
    "    Aplica histéresis temporal a una serie de niveles (1..5).\n",
    "    - Subida inmediata al nivel mayor si se detecta.\n",
    "    - Bajada solo si han pasado retardo_bajada_s desde que se cumplen condiciones de nivel menor.\n",
    "    \"\"\"\n",
    "    niveles_final = np.zeros_like(niveles_condiciones)\n",
    "    niveles_final[0] = niveles_condiciones[0]\n",
    "    tiempo_ultimo_cambio = tiempo[0]\n",
    "\n",
    "    for i in range(1, len(tiempo)):\n",
    "        nivel_actual = niveles_final[i-1]\n",
    "        nivel_cond = niveles_condiciones[i]\n",
    "\n",
    "        if nivel_cond > nivel_actual:\n",
    "            # Subida inmediata\n",
    "            niveles_final[i] = nivel_cond\n",
    "            tiempo_ultimo_cambio = tiempo[i]\n",
    "        elif nivel_cond < nivel_actual:\n",
    "            # Baja solo si ha pasado el retardo\n",
    "            if tiempo[i] - tiempo_ultimo_cambio >= retardo_bajada_s:\n",
    "                niveles_final[i] = nivel_cond\n",
    "                tiempo_ultimo_cambio = tiempo[i]\n",
    "            else:\n",
    "                niveles_final[i] = nivel_actual\n",
    "        else:\n",
    "            # Mismo nivel\n",
    "            niveles_final[i] = nivel_actual\n",
    "\n",
    "    return niveles_final\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Suppression Pool Thermocouples con histéresis\n",
    "# =========================\n",
    "T_wet = TempVapor_Wetwell\n",
    "P_wet = Presion_Wetwell\n",
    "\n",
    "# Niveles por condiciones instantáneas\n",
    "niveles_cond = np.ones_like(tiempo_s, dtype=int)\n",
    "niveles_cond[(T_wet > EQ_TEMP) | (P_wet > EQ_PRESSURE)] = 2\n",
    "niveles_cond[T_wet > 673.0] = 3\n",
    "niveles_cond[T_wet > 1530.0] = 5\n",
    "\n",
    "# Aplicar histéresis de 1800 s para bajar\n",
    "SuppressionPool_TC_Level = aplicar_histeresis(tiempo_s, niveles_cond, 1800.0)\n",
    "\n",
    "# Guardar\n",
    "guardar_nivel_instrumento(\"SuppressionPoolThermocouples\", SuppressionPool_TC_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: SRV Position Indicators (con T y P del DRYWELL)\n",
    "# =========================\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_srv = np.ones_like(tiempo_s, dtype=int)\n",
    "\n",
    "# Nivel 2: CEC>EQ usando Drywell\n",
    "niveles_cond_srv[(TempVapor_Drywell > EQ_TEMP) | (Presion_Drywell > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 5: Vessel Failure (ya definido con Presion_BombaRecir < 6 MPa)\n",
    "niveles_cond_srv[VESSEL_FAILURE] = 5\n",
    "\n",
    "# Aplicar histéresis de 1800 s para bajar\n",
    "SRV_PositionIndicators_Level = aplicar_histeresis(tiempo_s, niveles_cond_srv, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles en el contenedor general\n",
    "guardar_nivel_instrumento(\"SRVPositionIndicators\", SRV_PositionIndicators_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Radiation Detectors in Containment (Drywell)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_rad = np.ones_like(tiempo_s, dtype=int)\n",
    "\n",
    "# Aplicar de menor a mayor gravedad; los superiores sobreescriben a los inferiores\n",
    "# Nivel 2: CEC>EQ (OR en T o P)\n",
    "niveles_cond_rad[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: 1.5*CEC>EQ\n",
    "niveles_cond_rad[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "\n",
    "# Nivel 5: 2*CEC>EQ\n",
    "niveles_cond_rad[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "RadiationDetectorsContainment_Level = aplicar_histeresis(tiempo_s, niveles_cond_rad, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"RadiationDetectorsContainment\", RadiationDetectorsContainment_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Boron Injection Pressure Transmitters (como presión en contención)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_bipt = np.ones_like(tiempo_s, dtype=int)\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P)\n",
    "niveles_cond_bipt[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: 1.5*CEC>EQ\n",
    "niveles_cond_bipt[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "\n",
    "# Nivel 5: 2*CEC>EQ\n",
    "niveles_cond_bipt[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "BoronInjectionPressureTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_bipt, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"BoronInjectionPressureTransmitters\", BoronInjectionPressureTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Boron Tank Level Transmitter (Drywell)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "# Helper: duración continua de una condición booleana (segundos)\n",
    "def duracion_continua(tiempo, mask_bool):\n",
    "    dur = np.zeros_like(tiempo, dtype=float)\n",
    "    for i in range(1, len(tiempo)):\n",
    "        if mask_bool[i]:\n",
    "            dur[i] = (dur[i-1] + (tiempo[i] - tiempo[i-1])) if mask_bool[i-1] else 0.0\n",
    "        else:\n",
    "            dur[i] = 0.0\n",
    "    return dur\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_btl = np.ones_like(tiempo_s, dtype=int)\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P del Drywell)\n",
    "niveles_cond_btl[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: 30 min después de Tcont>422 K (condición mantenida de forma continua)\n",
    "mask_T422 = T_dw > 422.0\n",
    "dur_T422 = duracion_continua(tiempo_s, mask_T422)\n",
    "niveles_cond_btl[dur_T422 >= 1800.0] = 3\n",
    "\n",
    "# Nivel 5: Tcont > 1530 K\n",
    "niveles_cond_btl[T_dw > 1530.0] = 5\n",
    "\n",
    "# Aplicar histéresis de 1800 s para bajar de nivel\n",
    "BoronTankLevelTransmitter_Level = aplicar_histeresis(tiempo_s, niveles_cond_btl, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"BoronTankLevelTransmitter\", BoronTankLevelTransmitter_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Drywell Pressure Transmitters\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "niveles_cond_dpt = np.ones_like(tiempo_s, dtype=int)\n",
    "# Nivel 2: CEC>EQ (OR)\n",
    "niveles_cond_dpt[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "# Nivel 3: 1.5*CEC>EQ\n",
    "niveles_cond_dpt[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "# Nivel 5: 2*CEC>EQ\n",
    "niveles_cond_dpt[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "\n",
    "DrywellPressureTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_dpt, 1800.0)\n",
    "guardar_nivel_instrumento(\"DrywellPressureTransmitters\", DrywellPressureTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Containment Pressure Transmitters\n",
    "# =========================\n",
    "niveles_cond_cpt = np.ones_like(tiempo_s, dtype=int)\n",
    "# Nivel 2: CEC>EQ (OR)\n",
    "niveles_cond_cpt[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "# Nivel 3: 1.5*CEC>EQ\n",
    "niveles_cond_cpt[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "# Nivel 5: 2*CEC>EQ\n",
    "niveles_cond_cpt[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "\n",
    "ContainmentPressureTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_cpt, 1800.0)\n",
    "guardar_nivel_instrumento(\"ContainmentPressureTransmitters\", ContainmentPressureTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Containment Thermocouples (Drywell)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_ctc = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto (base)\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P)\n",
    "niveles_cond_ctc[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: Tcont > 673 K\n",
    "niveles_cond_ctc[T_dw > 673.0] = 3\n",
    "\n",
    "# Nivel 5: Tcont > 1530 K\n",
    "niveles_cond_ctc[T_dw > 1530.0] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "ContainmentThermocouples_Level = aplicar_histeresis(tiempo_s, niveles_cond_ctc, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"ContainmentThermocouples\", ContainmentThermocouples_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Vessel Level (Wide Range)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "niveles_cond_vlwr = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P)\n",
    "niveles_cond_vlwr[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: 30 min continuos tras Tcont>422 K\n",
    "mask_T422_dw = T_dw > 422.0\n",
    "dur_T422_dw  = duracion_continua(tiempo_s, mask_T422_dw)\n",
    "niveles_cond_vlwr[dur_T422_dw >= 1800.0] = 3\n",
    "\n",
    "# Nivel 5: Vessel Failure (omite nivel 4)\n",
    "niveles_cond_vlwr[VESSEL_FAILURE] = 5\n",
    "\n",
    "VesselLevelWideRange_Level = aplicar_histeresis(tiempo_s, niveles_cond_vlwr, 1800.0)\n",
    "guardar_nivel_instrumento(\"VesselLevelWideRange\", VesselLevelWideRange_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Vessel Level (Fuel Range)\n",
    "# =========================\n",
    "niveles_cond_vlfr = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P)\n",
    "niveles_cond_vlfr[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: 30 min continuos tras Tcont>422 K\n",
    "niveles_cond_vlfr[dur_T422_dw >= 1800.0] = 3  # reutilizamos dur_T422_dw calculado arriba\n",
    "\n",
    "# Nivel 5: Vessel Failure (omite nivel 4)\n",
    "niveles_cond_vlfr[VESSEL_FAILURE] = 5\n",
    "\n",
    "VesselLevelFuelRange_Level = aplicar_histeresis(tiempo_s, niveles_cond_vlfr, 1800.0)\n",
    "guardar_nivel_instrumento(\"VesselLevelFuelRange\", VesselLevelFuelRange_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Vessel Pressure Transmitters\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "PRCS = Presion_BombaRecir  # presión de bomba de recirculación\n",
    "\n",
    "# Duración continua de T_dw > 422 K (para el nivel 3)\n",
    "mask_T422_dw = T_dw > 422.0\n",
    "dur_T422_dw  = duracion_continua(tiempo_s, mask_T422_dw)\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_vpt = np.ones_like(tiempo_s, dtype=int)\n",
    "\n",
    "# --- Nivel 2 ---\n",
    "# Condición A: PRCS < 0.25 MPa (250000 Pa) AND Pcont > 0.2 MPa (200000 Pa)\n",
    "cond_A = (PRCS < 250_000.0) & (P_dw > 200_000.0)\n",
    "\n",
    "# Condición B: CEC > EQ en Drywell (T o P)\n",
    "cond_B = (T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)\n",
    "\n",
    "niveles_cond_vpt[cond_A | cond_B] = 2\n",
    "\n",
    "# --- Nivel 3 ---\n",
    "niveles_cond_vpt[dur_T422_dw >= 1800.0] = 3  # 30 min (1800 s) continuos tras T_dw > 422 K\n",
    "\n",
    "# --- Nivel 5 ---\n",
    "niveles_cond_vpt[T_dw > 1530.0] = 5  # nivel 4 omitido\n",
    "\n",
    "# Aplicar histéresis de 1800 s para bajar\n",
    "VesselPressureTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_vpt, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"VesselPressureTransmitters\", VesselPressureTransmitters_Level)\n",
    "\n",
    "# Referencias Drywell\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "# =========================\n",
    "# Feedwater Flow Transmitters\n",
    "# Niveles: 1(base), 2: CEC>EQ, 3: 1.5*EQ, 5: 2*EQ (4 omitido)\n",
    "# =========================\n",
    "niveles_cond_fwft = np.ones_like(tiempo_s, dtype=int)\n",
    "niveles_cond_fwft[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "niveles_cond_fwft[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "niveles_cond_fwft[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "FeedwaterFlowTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_fwft, 1800.0)\n",
    "guardar_nivel_instrumento(\"FeedwaterFlowTransmitters\", FeedwaterFlowTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# Drywell Thermocouples\n",
    "# Niveles: 1 (273–422 K base), 2: CEC>EQ, 3: T>673 K, 5: T>1530 K (4 omitido)\n",
    "# =========================\n",
    "niveles_cond_dwtc = np.ones_like(tiempo_s, dtype=int)\n",
    "# (si quieres forzar estrictamente 273–422K para nivel 1, dilo y lo ajusto)\n",
    "niveles_cond_dwtc[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "niveles_cond_dwtc[T_dw > 673.0] = 3\n",
    "niveles_cond_dwtc[T_dw > 1530.0] = 5\n",
    "DrywellThermocouples_Level = aplicar_histeresis(tiempo_s, niveles_cond_dwtc, 1800.0)\n",
    "guardar_nivel_instrumento(\"DrywellThermocouples\", DrywellThermocouples_Level)\n",
    "\n",
    "# =========================\n",
    "# Radiation Detectors in Drywell\n",
    "# Niveles: 1(base), 2: CEC>EQ, 3: 1.5*EQ, 5: 2*EQ (4 omitido)\n",
    "# =========================\n",
    "niveles_cond_rddw = np.ones_like(tiempo_s, dtype=int)\n",
    "niveles_cond_rddw[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "niveles_cond_rddw[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "niveles_cond_rddw[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "RadiationDetectorsDrywell_Level = aplicar_histeresis(tiempo_s, niveles_cond_rddw, 1800.0)\n",
    "guardar_nivel_instrumento(\"RadiationDetectorsDrywell\", RadiationDetectorsDrywell_Level)\n",
    "\n",
    "# =========================\n",
    "# Control Rods Position\n",
    "# Niveles: 1(base), 2: CEC>EQ, 5: Vessel Failure (3 y 4 omitidos)\n",
    "# =========================\n",
    "niveles_cond_crp = np.ones_like(tiempo_s, dtype=int)\n",
    "niveles_cond_crp[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "niveles_cond_crp[VESSEL_FAILURE] = 5\n",
    "ControlRodsPosition_Level = aplicar_histeresis(tiempo_s, niveles_cond_crp, 1800.0)\n",
    "guardar_nivel_instrumento(\"ControlRodsPosition\", ControlRodsPosition_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Recirculation Pressure Transmitters (P106 / T106)\n",
    "# =========================\n",
    "P106 = Presion_BombaRecir        # Pa\n",
    "T106 = TempVapor_BombaRecir      # K\n",
    "\n",
    "# Umbrales en Pa/K (conversión MPa -> Pa incluida)\n",
    "P2_thr = 8_000_000.0     # 8 MPa\n",
    "T2_thr = 573.0           # 573 K\n",
    "P3_thr = 12_000_000.0    # 12 MPa\n",
    "T3_thr = 1100.0          # 1100 K\n",
    "P4_thr = 17_200_000.0    # 17.2 MPa\n",
    "T4_thr = 1530.0          # 1530 K\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_rpt = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto (base)\n",
    "\n",
    "# Nivel 2\n",
    "niveles_cond_rpt[(P106 > P2_thr) | (T106 > T2_thr)] = 2\n",
    "\n",
    "# Nivel 3\n",
    "niveles_cond_rpt[(P106 > P3_thr) | (T106 > T3_thr)] = 3\n",
    "\n",
    "# Nivel 4\n",
    "niveles_cond_rpt[(P106 > P4_thr) | (T106 > T4_thr)] = 4\n",
    "\n",
    "# Nivel 5 (Vessel Failure)\n",
    "niveles_cond_rpt[VESSEL_FAILURE] = 5\n",
    "\n",
    "# Aplicar histéresis de 1800 s para bajar\n",
    "RecirculationPressureTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_rpt, 10000.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"RecirculationPressureTransmitters\", RecirculationPressureTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Recirculation Flow Transmitters (P106 / T106)\n",
    "# =========================\n",
    "P106 = Presion_BombaRecir   # Pa\n",
    "T106 = TempVapor_BombaRecir # K\n",
    "\n",
    "# Umbrales (MPa -> Pa)\n",
    "P2_thr = 8_000_000.0     # 8 MPa\n",
    "T2_thr = 573.0           # 573 K\n",
    "P3_thr = 12_000_000.0    # 12 MPa\n",
    "T3_thr = 1100.0          # 1100 K\n",
    "P4_thr = 17_200_000.0    # 17.2 MPa\n",
    "T4_thr = 1530.0          # 1530 K\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_rft = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2\n",
    "niveles_cond_rft[(P106 > P2_thr) | (T106 > T2_thr)] = 2\n",
    "\n",
    "# Nivel 3\n",
    "niveles_cond_rft[(P106 > P3_thr) | (T106 > T3_thr)] = 3\n",
    "\n",
    "# Nivel 4\n",
    "niveles_cond_rft[(P106 > P4_thr) | (T106 > T4_thr)] = 4\n",
    "\n",
    "# Nivel 5 (Vessel Failure)\n",
    "niveles_cond_rft[VESSEL_FAILURE] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "RecirculationFlowTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_rft, 10000.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"RecirculationFlowTransmitters\", RecirculationFlowTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Average Reactor Power Monitors (Drywell)\n",
    "# Niveles: 1(base), 2: CEC>EQ, 5: Vessel Failure (3 y 4 omitidos)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "niveles_cond_arpm = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P del Drywell)\n",
    "niveles_cond_arpm[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 5: Vessel Failure\n",
    "niveles_cond_arpm[VESSEL_FAILURE] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "AverageReactorPowerMonitors_Level = aplicar_histeresis(tiempo_s, niveles_cond_arpm, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"AverageReactorPowerMonitors\", AverageReactorPowerMonitors_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Vessel Thermocouples (Upper Head)\n",
    "# Niveles (1–5):\n",
    "# 1: 273–645 K (base)\n",
    "# 2: 645 K < T < 873 K\n",
    "# 3: 923 K < T < 1173 K\n",
    "# 4: 1173 K < T < 1530 K\n",
    "# 5: T > 1570 K\n",
    "# (Quedan huecos 873–923 K y 1530–1570 K tal como indican los rangos)\n",
    "# =========================\n",
    "T_uh = TempVapor_CabezaSuperior\n",
    "P_uh = Presion_CabezaSuperior  # No interviene en estos criterios, pero lo dejamos referenciado\n",
    "\n",
    "niveles_cond_vtuh = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2: 645 K < T < 873 K\n",
    "niveles_cond_vtuh[(T_uh > 645.0) & (T_uh < 873.0)] = 2\n",
    "\n",
    "# Nivel 3: 923 K < T < 1173 K\n",
    "niveles_cond_vtuh[(T_uh > 923.0) & (T_uh < 1173.0)] = 3\n",
    "\n",
    "# Nivel 4: 1173 K < T < 1530 K\n",
    "niveles_cond_vtuh[(T_uh > 1173.0) & (T_uh < 1530.0)] = 4\n",
    "\n",
    "# Nivel 5: T > 1570 K\n",
    "niveles_cond_vtuh[T_uh > 1570.0] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "VesselThermocouplesUpperHead_Level = aplicar_histeresis(tiempo_s, niveles_cond_vtuh, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"VesselThermocouplesUpperHead\", VesselThermocouplesUpperHead_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Vessel Thermocouples (Lower Head)\n",
    "# Niveles (1–5):\n",
    "# 1: 273–645 K (base)\n",
    "# 2: 645 K < T < 873 K\n",
    "# 3: 923 K < T < 1173 K\n",
    "# 4: 1173 K < T < 1530 K\n",
    "# 5: T > 1570 K\n",
    "# (Quedan huecos 873–923 K y 1530–1570 K, igual que el de Upper Head)\n",
    "# =========================\n",
    "T_lh = TempVapor_CabezaInferior\n",
    "P_lh = Presion_CabezaInferior  # no usado en estos criterios\n",
    "\n",
    "niveles_cond_vtlh = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2: 645 K < T < 873 K\n",
    "niveles_cond_vtlh[(T_lh > 645.0) & (T_lh < 873.0)] = 2\n",
    "\n",
    "# Nivel 3: 923 K < T < 1173 K\n",
    "niveles_cond_vtlh[(T_lh > 923.0) & (T_lh < 1173.0)] = 3\n",
    "\n",
    "# Nivel 4: 1173 K < T < 1530 K\n",
    "niveles_cond_vtlh[(T_lh > 1173.0) & (T_lh < 1530.0)] = 4\n",
    "\n",
    "# Nivel 5: Vessel Failure\n",
    "niveles_cond_vtlh[VESSEL_FAILURE] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "VesselThermocouplesLowerHead_Level = aplicar_histeresis(tiempo_s, niveles_cond_vtlh, 20000.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"VesselThermocouplesLowerHead\", VesselThermocouplesLowerHead_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: FW Thermocouples (usando Cabeza Inferior como proxy de Tcore)\n",
    "# Niveles (1–5):\n",
    "# 1: 273–645 K (base)\n",
    "# 2: 645 K < Tcore < 873 K\n",
    "# 3: — (omitido)\n",
    "# 4: 873 K < Tcore < 1530 K\n",
    "# 5: Tcore > 1570 K\n",
    "# =========================\n",
    "Tcore = TempVapor_CabezaInferior  # proxy Tcore con Cabeza Inferior\n",
    "\n",
    "niveles_cond_fwtc = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2\n",
    "niveles_cond_fwtc[(Tcore > 645.0) & (Tcore < 873.0)] = 2\n",
    "\n",
    "# Nivel 4\n",
    "niveles_cond_fwtc[(Tcore > 873.0) & (Tcore < 1530.0)] = 4\n",
    "\n",
    "# Nivel 5\n",
    "niveles_cond_fwtc[Tcore > 1570.0] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "FWThermocouples_Level = aplicar_histeresis(tiempo_s, niveles_cond_fwtc, 25000.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"FWThermocouples\", FWThermocouples_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Suction Pipes Thermocouples (T106)\n",
    "# Niveles (1–5):\n",
    "# 1: 273–645 K (base)\n",
    "# 2: 645 K < T < 873 K\n",
    "# 3: 923 K < T < 1173 K\n",
    "# 4: 1173 K < T < 1530 K\n",
    "# 5: T > 1570 K\n",
    "# (Quedan huecos 873–923 K y 1530–1570 K, según tu tabla)\n",
    "# =========================\n",
    "T106 = TempVapor_BombaRecir  # K\n",
    "\n",
    "niveles_cond_sptc = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2\n",
    "niveles_cond_sptc[(T106 > 645.0) & (T106 < 873.0)] = 2\n",
    "# Nivel 3\n",
    "niveles_cond_sptc[(T106 > 923.0) & (T106 < 1173.0)] = 3\n",
    "# Nivel 4\n",
    "niveles_cond_sptc[(T106 > 1173.0) & (T106 < 1530.0)] = 4\n",
    "# Nivel 5\n",
    "niveles_cond_sptc[T106 > 1570.0] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "SuctionPipesThermocouples_Level = aplicar_histeresis(tiempo_s, niveles_cond_sptc, 100000.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"SuctionPipesThermocouples\", SuctionPipesThermocouples_Level)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def exportar_niveles_y_graficas(niveles_instrumentos: dict, tiempo_s: np.ndarray,\n",
    "                                carpeta_csv: str = \"csv_niveles\",\n",
    "                                carpeta_figs: str = \"graficas_niveles\"):\n",
    "    \"\"\"\n",
    "    Para cada instrumento en `niveles_instrumentos`:\n",
    "      - Guarda CSV con columnas: tiempo_s, nivel\n",
    "      - Genera PNG con step-plot del nivel (1–5) vs tiempo\n",
    "    \"\"\"\n",
    "    os.makedirs(carpeta_csv, exist_ok=True)\n",
    "    os.makedirs(carpeta_figs, exist_ok=True)\n",
    "\n",
    "    for nombre, niveles in niveles_instrumentos.items():\n",
    "        if niveles.shape != tiempo_s.shape:\n",
    "            print(f\"[ADVERTENCIA] Longitud diferente en '{nombre}': \"\n",
    "                  f\"tiempo={tiempo_s.shape}, niveles={niveles.shape}. Se omite.\")\n",
    "            continue\n",
    "\n",
    "        # Nombre de archivo seguro\n",
    "        safe = \"\".join(c if c.isalnum() or c in (\"_\", \"-\") else \"_\" for c in nombre)\n",
    "\n",
    "        # ----- CSV -----\n",
    "        df = pd.DataFrame({\"tiempo_s\": tiempo_s, \"nivel\": niveles.astype(int)})\n",
    "        ruta_csv = os.path.join(carpeta_csv, f\"{safe}_niveles.csv\")\n",
    "        df.to_csv(ruta_csv, index=False)\n",
    "\n",
    "        # ----- Gráfica -----\n",
    "        plt.figure()\n",
    "        plt.step(tiempo_s, niveles, where=\"post\")\n",
    "        plt.xlabel(\"Tiempo [s]\")\n",
    "        plt.ylabel(\"Nivel de daño (1–5)\")\n",
    "        plt.title(f\"{nombre} – Nivel (1–5)\")\n",
    "        plt.yticks([1, 2, 3, 4, 5])\n",
    "        plt.ylim(0.8, 5.2)  # para ver bien los extremos\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        ruta_png = os.path.join(carpeta_figs, f\"{safe}_niveles.png\")\n",
    "        plt.savefig(ruta_png, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Guardado CSV: {ruta_csv}\")\n",
    "        print(f\"Guardada gráfica: {ruta_png}\")\n",
    "\n",
    "# Ejecuta la exportación\n",
    "exportar_niveles_y_graficas(niveles_instrumentos, tiempo_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c400637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN\n",
    "# ============================================================\n",
    "carpeta = Path(\".\")\n",
    "\n",
    "state_order = {'Good':0, 'Careful':1, 'Warning':2, 'Blind':3}\n",
    "\n",
    "# ============================================================\n",
    "# MAPEO CSV POR INSTRUMENTO\n",
    "# ============================================================\n",
    "instrument_to_csv = {\n",
    "    \"Average Reactor Power Monitors\": \"AverageReactorPowerMonitors\",\n",
    "    \"Boron Injection Pressure Transmitters\": \"BoronInjectionPressureTransmitters\",\n",
    "    \"Boron Tank Level Transmitter\": \"BoronTankLevelTransmitter\",\n",
    "    \"Containment Pressure Transmitters\": \"ContainmentPressureTransmitters\",\n",
    "    \"Containment Thermocouples\": \"ContainmentThermocouples\",\n",
    "    \"Control Rods Position\": \"ControlRodsPosition\",\n",
    "    \"Drywell Pressure Transmitters\": \"DrywellPressureTransmitters\",\n",
    "    \"Drywell Thermocouples\": \"DrywellThermocouples\",\n",
    "    \"Feedwater Flow Transmitters\": \"FeedwaterFlowTransmitters\",\n",
    "    \"Feedwater Pressure Transmitters\": \"FeedwaterPressureTransmitters\",\n",
    "    \"FW Thermocouples\": \"FWThermocouples\",\n",
    "    \"Radiation Detectors in Containment\": \"RadiationDetectorsContainment\",\n",
    "    \"Radiation Detectors in Drywell\": \"RadiationDetectorsDrywell\",\n",
    "    \"Recirculation Flow Transmitters\": \"RecirculationFlowTransmitters\",\n",
    "    \"Recirculation Pressure Transmitters\": \"RecirculationPressureTransmitters\",\n",
    "    \"SRV Position Indicators\": \"SRVPositionIndicators\",\n",
    "    \"Suction Pipes Thermocouples\": \"SuctionPipesThermocouples\",\n",
    "    \"Supression Pool Thermocouples\": \"SuppressionPoolThermocouples\",  # base 'pp'\n",
    "    \"Suppresion Pool Level Transmitters\": \"SuppressionPoolLevelTransmitters\",\n",
    "    \"Vessel Level (Fuel Range)\": \"VesselLevelFuelRange\",\n",
    "    \"Vessel Level (Wide Range)\": \"VesselLevelWideRange\",\n",
    "    \"Vessel Pressure Transmitters\": \"VesselPressureTransmitters\",\n",
    "    \"Vessel Thermocouples (Lower Head)\": \"VesselThermocouplesLowerHead\",\n",
    "    \"Vessel Thermocouples (Upper Head)\": \"VesselThermocouplesUpperHead\",\n",
    "    \"HPCS Flow Transmitter\": \"HPCSFlowTransmitter\",\n",
    "    \"Containment Hydrogen Concentration Analyzer\": \"ContainmentHydrogenAnalyzer\",\n",
    "    \"Drywell Hydrogen Concentration Analyzer\": \"DrywellHydrogenAnalyzer\",\n",
    "    # Opcionales si existen CSV:\n",
    "    \"Containment Pressure Transmitter (Auxiliary Building)\": \"ContainmentPressureTransmitterAux\",\n",
    "    \"Drywell Pressure Transmitter (Auxiliary Building)\": \"DrywellPressureTransmitterAux\",\n",
    "}\n",
    "\n",
    "# Alias (por si aparecen variantes de escritura)\n",
    "name_aliases = {\n",
    "    \"Suppression Pool Thermocouples\": \"Supression Pool Thermocouples\",\n",
    "    \"Suppression Pool Level Transmitters\": \"Suppresion Pool Level Transmitters\",\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# UTILIDADES\n",
    "# ============================================================\n",
    "def _canon(s: str) -> str:\n",
    "    return \"\".join(ch.lower() for ch in s if ch.isalnum())\n",
    "\n",
    "def resolve_instrument_name(name: str, available: dict) -> str | None:\n",
    "    name = name_aliases.get(name, name)\n",
    "    if name in available:\n",
    "        return name\n",
    "    idx = { _canon(k): k for k in available.keys() }\n",
    "    return idx.get(_canon(name))\n",
    "\n",
    "def leer_csv_flexible(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Lee CSV con separador auto (, ; \\t) y devuelve DF con columnas 'tiempo_s','nivel'.\"\"\"\n",
    "    seps = [\",\",\";\",\"\\t\",\"|\"]\n",
    "    last_err = None\n",
    "    for sep in seps:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=sep)\n",
    "            if df.shape[1] < 1:\n",
    "                continue\n",
    "            # limpiar columnas unnamed\n",
    "            df = df.loc[:, ~df.columns.astype(str).str.startswith(\"Unnamed\")]\n",
    "            cols = [c.lower().strip() for c in df.columns.astype(str)]\n",
    "\n",
    "            # Caso NUEVO (ancho): columnas tiempo_s, nivel\n",
    "            if \"tiempo_s\" in cols and \"nivel\" in cols:\n",
    "                tcol = df.columns[cols.index(\"tiempo_s\")]\n",
    "                ncol = df.columns[cols.index(\"nivel\")]\n",
    "                out = df[[tcol,ncol]].rename(columns={tcol:\"tiempo_s\", ncol:\"nivel\"}).copy()\n",
    "                out[\"tiempo_s\"] = pd.to_numeric(out[\"tiempo_s\"], errors=\"coerce\")\n",
    "                out[\"nivel\"]    = pd.to_numeric(out[\"nivel\"], errors=\"coerce\")\n",
    "                out = out.dropna(subset=[\"tiempo_s\",\"nivel\"])\n",
    "                out[\"nivel\"] = out[\"nivel\"].round().clip(1,5).astype(int)\n",
    "                out = out.sort_values(\"tiempo_s\").reset_index(drop=True)\n",
    "                return out\n",
    "\n",
    "            # Caso ANTIGUO (largo): Intervalo / Nivel de Daño\n",
    "            if \"intervalo\" in cols and \"nivel de daño\" in cols:\n",
    "                icol = df.columns[cols.index(\"intervalo\")]\n",
    "                lcol = df.columns[cols.index(\"nivel de daño\")]\n",
    "                tmp = df[[icol,lcol]].rename(columns={icol:\"Intervalo\", lcol:\"Nivel de Daño\"}).copy()\n",
    "                tmp[\"Intervalo\"] = tmp[\"Intervalo\"].astype(str)\n",
    "                tmp[\"Nivel de Daño\"] = pd.to_numeric(tmp[\"Nivel de Daño\"], errors=\"coerce\").fillna(1).astype(int).clip(1,5)\n",
    "                # inventamos tiempo_s como 0,1,2,... (pasos)\n",
    "                out = pd.DataFrame({\n",
    "                    \"tiempo_s\": np.arange(len(tmp), dtype=float),\n",
    "                    \"nivel\": tmp[\"Nivel de Daño\"].to_numpy(int)\n",
    "                })\n",
    "                return out\n",
    "\n",
    "            # Si tiene dos columnas cualesquiera, intentamos mapear a tiempo,nivel por posición\n",
    "            if df.shape[1] >= 2:\n",
    "                out = df.iloc[:, :2].copy()\n",
    "                out.columns = [\"tiempo_s\",\"nivel\"]\n",
    "                out[\"tiempo_s\"] = pd.to_numeric(out[\"tiempo_s\"], errors=\"coerce\")\n",
    "                out[\"nivel\"]    = pd.to_numeric(out[\"nivel\"], errors=\"coerce\")\n",
    "                out = out.dropna(subset=[\"tiempo_s\",\"nivel\"])\n",
    "                out[\"nivel\"] = out[\"nivel\"].round().clip(1,5).astype(int)\n",
    "                out = out.sort_values(\"tiempo_s\").reset_index(drop=True)\n",
    "                return out\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    # Si no pudimos leer, relanza último error\n",
    "    raise last_err if last_err else RuntimeError(f\"No se pudo leer {path}\")\n",
    "\n",
    "# ====== NUEVO: utilidades para construir y guardar CSV ======\n",
    "def _levels_dataframe(instrs):\n",
    "    \"\"\"\n",
    "    Devuelve (t_ref, df) donde df contiene 'tiempo_s' y,\n",
    "    por cada instrumento, una columna con su nivel remuestreado (1..5).\n",
    "    \"\"\"\n",
    "    t_ref = _reference_time(instrs)\n",
    "    data = {\"tiempo_s\": t_ref}\n",
    "    for i_name in instrs:\n",
    "        resolved = resolve_instrument_name(i_name, damage_by_instrument) or i_name\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        y = _resample_to_reference(df, t_ref)\n",
    "        data[resolved] = y.astype(int)\n",
    "    out = pd.DataFrame(data)\n",
    "    return t_ref, out\n",
    "\n",
    "def _availability_dataframe(instrs):\n",
    "    \"\"\"\n",
    "    Calcula availability y devuelve (t_ref, df) con columnas:\n",
    "    'tiempo_s', 'state', 'state_code' (0..3).\n",
    "    \"\"\"\n",
    "    t_ref = _reference_time(instrs)\n",
    "    levels = []\n",
    "    for i_name in instrs:\n",
    "        resolved = resolve_instrument_name(i_name, damage_by_instrument) or i_name\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        y = _resample_to_reference(df, t_ref)\n",
    "        levels.append(y.astype(int))\n",
    "\n",
    "    states, codes = [], []\n",
    "    for i in range(len(t_ref)):\n",
    "        lvls_t = [int(arr[i]) for arr in levels]\n",
    "        st = determine_state_from_levels(lvls_t)\n",
    "        states.append(st)\n",
    "        codes.append(state_order[st])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"tiempo_s\": t_ref,\n",
    "        \"state\": states,\n",
    "        \"state_code\": np.array(codes, dtype=int)\n",
    "    })\n",
    "    return t_ref, df\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CARGA TODOS LOS INSTRUMENTOS + TIEMPO DE REFERENCIA\n",
    "# ============================================================\n",
    "raw_data = {}\n",
    "ref_time = None\n",
    "\n",
    "for visible_name, base in instrument_to_csv.items():\n",
    "    ruta = carpeta / f\"{base}_niveles.csv\"\n",
    "    if ruta.exists():\n",
    "        df = leer_csv_flexible(ruta)\n",
    "        raw_data[visible_name] = df\n",
    "        if ref_time is None and not df.empty:\n",
    "            ref_time = df[\"tiempo_s\"].to_numpy()\n",
    "    else:\n",
    "        # se rellena luego con fallback\n",
    "        pass\n",
    "\n",
    "# Si no hay ningún CSV real, inventamos ref_time\n",
    "if ref_time is None:\n",
    "    ref_time = np.arange(100, dtype=float)  # 100 puntos por defecto\n",
    "\n",
    "# Completar faltantes con nivel=1 y mismo eje temporal\n",
    "for visible_name, base in instrument_to_csv.items():\n",
    "    if visible_name not in raw_data:\n",
    "        print(f\"⚠ No encontrado: {base}_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\")\n",
    "        raw_data[visible_name] = pd.DataFrame({\n",
    "            \"tiempo_s\": ref_time,\n",
    "            \"nivel\": np.ones_like(ref_time, dtype=int)\n",
    "        })\n",
    "\n",
    "# ============================================================\n",
    "# PREPARACIÓN DE ESTRUCTURAS\n",
    "# ============================================================\n",
    "damage_by_instrument = {name: df for name, df in raw_data.items()}\n",
    "\n",
    "# ============================================================\n",
    "# LÓGICA AVAILABILITY (tu regla)\n",
    "# ============================================================\n",
    "def determine_state_from_levels(lvls: list[int]) -> str:\n",
    "    if all(l == 1 for l in lvls):\n",
    "        return 'Good'\n",
    "    if any(l == 2 for l in lvls) and all(l <= 2 for l in lvls):\n",
    "        return 'Careful'\n",
    "    if all(l == 5 for l in lvls):\n",
    "        return 'Blind'\n",
    "    if any(l in (3,4) for l in lvls):\n",
    "        return 'Warning'\n",
    "    return 'Warning'\n",
    "\n",
    "# ============================================================\n",
    "# PLOTS\n",
    "# ============================================================\n",
    "def create_directory(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def _reference_time(instruments):\n",
    "    \"\"\"Devuelve el vector tiempo_s de referencia (el del primer instrumento con datos).\"\"\"\n",
    "    for instr in instruments:\n",
    "        resolved = resolve_instrument_name(instr, damage_by_instrument) or instr\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        if df is not None and not df.empty:\n",
    "            return df[\"tiempo_s\"].to_numpy()\n",
    "    return ref_time\n",
    "\n",
    "def _resample_to_reference(df: pd.DataFrame, t_ref: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ajusta la serie (tiempo_s, nivel) al eje temporal t_ref:\n",
    "    - si longitudes coinciden y tiempos iguales ≈: devuelve niveles tal cual\n",
    "    - si difiere, interpola 'nearest' por escalón (usamos pandas merge_asof).\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return np.ones_like(t_ref, dtype=int)\n",
    "    src_t = df[\"tiempo_s\"].to_numpy()\n",
    "    src_y = df[\"nivel\"].to_numpy(int)\n",
    "\n",
    "    if len(src_t) == len(t_ref) and np.allclose(src_t, t_ref, rtol=0, atol=1e-9):\n",
    "        return src_y\n",
    "\n",
    "    # merge_asof para asignar al tiempo de referencia el nivel más cercano (look-up tipo nearest)\n",
    "    a = pd.DataFrame({\"t\": t_ref})\n",
    "    b = pd.DataFrame({\"t\": src_t, \"y\": src_y}).sort_values(\"t\")\n",
    "    out = pd.merge_asof(a.sort_values(\"t\"), b, on=\"t\", direction=\"nearest\")\n",
    "    y = out[\"y\"].fillna(1).round().clip(1,5).astype(int).to_numpy()\n",
    "    return y\n",
    "\n",
    "def plot_damage(instruments, save_path, title):\n",
    "    t_ref = _reference_time(instruments)\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), dpi=100)\n",
    "    fig.patch.set_facecolor('#001F3F')\n",
    "    ax.set_facecolor('#001F3F')\n",
    "\n",
    "    markers = ['o','s','D','^','v','P','X','*','<','>']\n",
    "    for idx, instr in enumerate(instruments):\n",
    "        resolved = resolve_instrument_name(instr, damage_by_instrument) or instr\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        y = _resample_to_reference(df, t_ref)\n",
    "        jitter = (idx - len(instruments)/2) * 0.05\n",
    "        ax.plot(\n",
    "            t_ref, y + jitter,\n",
    "            marker=markers[idx % len(markers)],\n",
    "            markersize=6,\n",
    "            linewidth=1.8,\n",
    "            label=resolved,\n",
    "            markevery=max(1, len(t_ref)//20)\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Time (s)\", color='white', fontsize=20)\n",
    "    ax.set_ylabel(\"Damage Level\", color='white', fontsize=20)\n",
    "    ax.set_yticks([1,2,3,4,5])\n",
    "    ax.set_yticklabels([1,2,3,4,5], color='white', fontsize=18)\n",
    "    ax.tick_params(colors='white', labelsize=16)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('white')\n",
    "    ax.grid(color='white', linestyle='--', alpha=0.2, linewidth=1)\n",
    "    ax.set_title(title, color='white', fontsize=28, pad=24)\n",
    "\n",
    "    # leyenda abajo\n",
    "    leg_cols = len(instruments) if len(instruments) <= 2 else (len(instruments)+1)//2\n",
    "    leg = ax.legend(\n",
    "        loc='upper center', bbox_to_anchor=(0.5, -0.12),\n",
    "        ncol=max(1, leg_cols), frameon=False, fontsize=14\n",
    "    )\n",
    "    for txt in leg.get_texts():\n",
    "        txt.set_color('white')\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.25)\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_availability(measure, t_ref, states, save_path):\n",
    "    import numpy as np\n",
    "    values = np.array([state_order[s] for s in states], dtype=int)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), dpi=100)\n",
    "    fig.patch.set_facecolor('#001F3F')\n",
    "    ax.set_facecolor('#001F3F')\n",
    "\n",
    "    # bandas por estado (Good/Careful/Warning/Blind)\n",
    "    bands = {0:'#2E7D32', 1:'#F9A825', 2:'#EF6C00', 3:'#B71C1C'}\n",
    "    for lvl, col in bands.items():\n",
    "        ax.axhspan(lvl, lvl+1, color=col, alpha=0.25)\n",
    "\n",
    "    # línea escalonada (mismo estilo que daño)\n",
    "    ax.plot(t_ref, values, drawstyle='steps-post', marker='o',\n",
    "            markersize=6, linewidth=1.8)\n",
    "\n",
    "    # === Igualamos estilo de ejes al de \"daño\" ===\n",
    "    ax.set_xlabel(\"Time (s)\", color='white', fontsize=20)\n",
    "    ax.set_ylabel(\"\", color='white', fontsize=20)  # sin etiqueta textual\n",
    "    ax.set_yticks([0,1,2,3])\n",
    "    ax.set_yticklabels(list(state_order.keys()), color='white', fontsize=18)\n",
    "\n",
    "    # ¡NO fijamos los xticks! (dejamos el auto-locator como en daño)\n",
    "    ax.tick_params(colors='white', labelsize=16)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('white')\n",
    "    ax.grid(color='white', linestyle='--', alpha=0.2, linewidth=1)\n",
    "    ax.set_title(f\"{measure} Availability\", color='white', fontsize=28, pad=24)\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.25)\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GENERACIÓN DE SALIDAS\n",
    "# ============================================================\n",
    "def create_directory(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def generate_graphs(samg_name, samg_dict, actions_map):\n",
    "    create_directory(samg_name)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(samg_name, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                base = measure.replace(' ', '_').replace('/', '_')\n",
    "                # --- nuevo: CSV de niveles por instrumento (remuestreados) ---\n",
    "                _, df_levels = _levels_dataframe(instrs)\n",
    "                df_levels.to_csv(os.path.join(path_code, base + \".csv\"),\n",
    "                                 index=False, encoding=\"utf-8\")\n",
    "                # --- gráfico como antes ---\n",
    "                plot_damage(instrs, os.path.join(path_code, base + \".png\"), measure)\n",
    "\n",
    "\n",
    "def generate_availability(samg_name, samg_dict, actions_map):\n",
    "    base_dir = f\"Availability_{samg_name}\"\n",
    "    create_directory(base_dir)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(base_dir, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                safe = measure.replace(' ', '_').replace('/', '_')\n",
    "                # --- nuevo: CSV de availability ---\n",
    "                t_ref, df_av = _availability_dataframe(instrs)\n",
    "                df_av.to_csv(os.path.join(path_code, safe + \"_availability.csv\"),\n",
    "                             index=False, encoding=\"utf-8\")\n",
    "                # --- gráfico como antes ---\n",
    "                states = df_av[\"state\"].tolist()\n",
    "                plot_availability(measure, t_ref, states,\n",
    "                                  os.path.join(path_code, safe + \"_availability.png\"))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EJECUCIÓN\n",
    "# ============================================================\n",
    "generate_graphs(\"SAMG1\", SAMG1, actions_short)\n",
    "generate_graphs(\"SAMG2\", SAMG2, actions_short)\n",
    "generate_availability(\"SAMG1\", SAMG1, actions_short)\n",
    "generate_availability(\"SAMG2\", SAMG2, actions_short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9105b29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===========================\n",
    "# CONFIGURATION\n",
    "# ===========================\n",
    "\n",
    "VARIABLES = [\n",
    "    \"TEMPERATURE_DRYWELL\",\n",
    "    \"PRESSURE_DRYWELL\",\n",
    "    \"RADIATION_CONTAINMENT\",\n",
    "    \"HYDROGEN_CONTAINMENT\",\n",
    "    \"LEVEL_BORON_TANK\",\n",
    "    \"INJECTED_FLOW_RPV\",\n",
    "    \"LEVEL_RPV\",\n",
    "    \"PRESSURE_RPV\",\n",
    "    \"TEMPERATURE_RPV\",\n",
    "    \"PRESSURE_CONTAINMENT\",\n",
    "    \"LEVEL_CONTAINMENT\",\n",
    "    \"PRESSURE_SP\",\n",
    "    \"TEMPERATURE_SP\",\n",
    "    \"SRV_POSITION\",\n",
    "    \"REACTOR_POWER\",\n",
    "    \"TEMPERATURE_CONTAINMENT\"\n",
    "]\n",
    "\n",
    "OUT_DIR = \"plots_out\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "T_MAX = 86400\n",
    "\n",
    "MARKERS = [\"o\", \"s\", \"^\", \"D\", \"v\", \"P\", \"X\", \"<\", \">\", \"h\"]\n",
    "\n",
    "STATE_MAP = {\"Good\": 0, \"Careful\": 1, \"Warning\": 2, \"Blind\": 3}\n",
    "ZONE_COLORS = {0: \"#006400\", 1: \"#CCCC00\", 2: \"#FF8C00\", 3: \"#8B0000\"}\n",
    "\n",
    "# ===========================\n",
    "# UTILITIES\n",
    "# ===========================\n",
    "\n",
    "def interval_to_seconds(interval_str: str):\n",
    "    norm = str(interval_str).strip().lower().replace(\" \", \"\")\n",
    "    if norm in (\"12h-1d\", \"12h-1dia\", \"12h-1día\", \"12h_a_1d\"):\n",
    "        return (12*3600, 24*3600)\n",
    "    if norm in (\"0-1d\", \"0-1dia\", \"0-1día\"):\n",
    "        return (12*3600, 24*3600)\n",
    "    if norm in (\"0-1h\", \"0h-1h\"):\n",
    "        return (0, 1*3600)\n",
    "    if norm in (\"1-12h\", \"1h-12h\"):\n",
    "        return (1*3600, 12*3600)\n",
    "    if \"-\" in norm:\n",
    "        a, b = norm.split(\"-\")\n",
    "        def to_s(x):\n",
    "            if x.endswith(\"h\"):\n",
    "                return int(float(x[:-1]) * 3600)\n",
    "            if x.endswith(\"d\"):\n",
    "                return int(float(x[:-1]) * 86400)\n",
    "            return int(float(x))\n",
    "        return (to_s(a), to_s(b))\n",
    "    raise ValueError(f\"No puedo interpretar el intervalo: {interval_str!r}\")\n",
    "\n",
    "def load_interval_table(csv1_path: str) -> pd.DataFrame:\n",
    "    df1 = pd.read_csv(csv1_path)\n",
    "    col_interval = None\n",
    "    for c in df1.columns:\n",
    "        if str(c).strip().lower() == \"interval\":\n",
    "            col_interval = c\n",
    "            break\n",
    "    if col_interval is None:\n",
    "        raise ValueError(f\"{csv1_path}: no encuentro columna 'Interval'.\")\n",
    "    inst_cols = [c for c in df1.columns if c != col_interval]\n",
    "    rows = []\n",
    "    for _, r in df1.iterrows():\n",
    "        start, end = interval_to_seconds(r[col_interval])\n",
    "        for col in inst_cols:\n",
    "            val = int(r[col])\n",
    "            rows.append({\"start\": start, \"end\": end, \"Instrument\": col, \"Damage\": val})\n",
    "    return pd.DataFrame(rows).sort_values([\"Instrument\", \"start\"]).reset_index(drop=True)\n",
    "\n",
    "def load_timeseries_table(csv2_path: str) -> pd.DataFrame:\n",
    "    df2 = pd.read_csv(csv2_path)\n",
    "    time_col = None\n",
    "    for c in df2.columns:\n",
    "        if str(c).strip().lower() in (\"tiempo_s\", \"time_s\", \"t\", \"tiempo\"):\n",
    "            time_col = c\n",
    "            break\n",
    "    if time_col is None:\n",
    "        raise ValueError(f\"{csv2_path}: no encuentro columna de tiempo en segundos.\")\n",
    "    if time_col != \"tiempo_s\":\n",
    "        df2 = df2.rename(columns={time_col: \"tiempo_s\"})\n",
    "    return df2\n",
    "\n",
    "def df1_value_at(df1_intervals: pd.DataFrame, instrument: str, t: float) -> int:\n",
    "    sub = df1_intervals[(df1_intervals[\"Instrument\"] == instrument) &\n",
    "                        (df1_intervals[\"start\"] <= t) &\n",
    "                        (t < df1_intervals[\"end\"])]\n",
    "    if not sub.empty:\n",
    "        return int(sub.iloc[0][\"Damage\"])\n",
    "    if math.isclose(t, T_MAX, rel_tol=0, abs_tol=1e-9):\n",
    "        last = df1_intervals[df1_intervals[\"Instrument\"] == instrument].sort_values(\"end\").iloc[-1]\n",
    "        return int(last[\"Damage\"])\n",
    "    return np.nan\n",
    "\n",
    "def df2_value_at(df2: pd.DataFrame, instrument: str, t: float) -> int:\n",
    "    sub = df2[df2[\"tiempo_s\"] <= t]\n",
    "    if sub.empty:\n",
    "        return int(df2.iloc[0][instrument])\n",
    "    return int(sub.iloc[-1][instrument])\n",
    "\n",
    "def build_series_max(csv1_path: str, csv2_path: str):\n",
    "    df1_intervals = load_interval_table(csv1_path)\n",
    "    df2 = load_timeseries_table(csv2_path)\n",
    "    insts = sorted(set(df1_intervals[\"Instrument\"].unique()).union(\n",
    "                   set([c for c in df2.columns if c != \"tiempo_s\"])))\n",
    "    T = set([0, T_MAX])\n",
    "    for _, r in df1_intervals.iterrows():\n",
    "        T.add(int(r[\"start\"]))\n",
    "        T.add(int(r[\"end\"]))\n",
    "    for t in df2[\"tiempo_s\"].values:\n",
    "        if 0 <= t <= T_MAX:\n",
    "            T.add(float(t))\n",
    "    T = sorted(T)\n",
    "    series = {}\n",
    "    for inst in insts:\n",
    "        y_vals = []\n",
    "        for tt in T:\n",
    "            v1 = df1_value_at(df1_intervals, inst, tt)\n",
    "            v2 = df2_value_at(df2, inst, tt) if inst in df2.columns else np.nan\n",
    "            y_vals.append(int(max(v1, v2)))\n",
    "        x_comp, y_comp = [T[0]], [y_vals[0]]\n",
    "        for i in range(1, len(T)):\n",
    "            if y_vals[i] != y_comp[-1]:\n",
    "                x_comp.append(T[i])\n",
    "                y_comp.append(y_vals[i])\n",
    "        if x_comp[-1] != T_MAX:\n",
    "            x_comp.append(T_MAX)\n",
    "            y_comp.append(y_comp[-1])\n",
    "        series[inst] = (np.array(x_comp), np.array(y_comp))\n",
    "    return series, insts\n",
    "\n",
    "def auto_offsets(n: int, base=0.06):  # más separación que antes\n",
    "    if n == 1:\n",
    "        return [0.0]\n",
    "    idx = np.arange(n) - (n-1)/2.0\n",
    "    return (idx / max(1, (n-1)/2.0)) * base\n",
    "\n",
    "def plot_variable(name: str, series: dict, insts: list, out_dir=OUT_DIR):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    fig.patch.set_facecolor(\"#06243A\")\n",
    "    ax.set_facecolor(\"#06243A\")\n",
    "    offs = auto_offsets(len(insts), base=0.06)\n",
    "    markers = {insts[i]: MARKERS[i % len(MARKERS)] for i in range(len(insts))}\n",
    "    line_kwargs = dict(\n",
    "        where=\"post\",\n",
    "        linewidth=2.0,\n",
    "        markersize=7,\n",
    "        markeredgewidth=1.8,\n",
    "        solid_capstyle=\"butt\",\n",
    "        mfc=\"none\",\n",
    "        markevery=None\n",
    "    )\n",
    "    y_all = []\n",
    "    for i, inst in enumerate(insts):\n",
    "        x, y = series[inst]\n",
    "        y_shift = y + offs[i]\n",
    "        y_all.extend(list(y_shift))\n",
    "        ln = ax.step(x, y_shift, marker=markers[inst], label=inst, **line_kwargs)[0]\n",
    "        ln.set_zorder(3)\n",
    "    ax.set_title(name.replace(\"_\", \" \"), fontsize=34, fontweight=\"bold\", color=\"white\", pad=20)\n",
    "    ax.set_xlabel(\"Time (s)\", fontsize=20, color=\"white\", labelpad=15)\n",
    "    ax.set_ylabel(\"Damage Level\", fontsize=24, color=\"white\", labelpad=15)\n",
    "    ax.set_xlim(0, T_MAX)\n",
    "    ymin = max(0.9, np.nanmin(y_all) - 0.1)\n",
    "    ymax = min(5.1, np.nanmax(y_all) + 0.1)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.tick_params(axis=\"both\", colors=\"white\", labelsize=14)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color(\"white\")\n",
    "        spine.set_alpha(0.6)\n",
    "    plt.subplots_adjust(bottom=0.24)\n",
    "    leg_cols = min(4, max(2, int(math.ceil(len(insts)/2))))\n",
    "    legend = ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.18),\n",
    "        ncol=leg_cols,\n",
    "        frameon=False,\n",
    "        fontsize=14,\n",
    "        handlelength=2.6,\n",
    "        handletextpad=0.8,\n",
    "        columnspacing=1.8,\n",
    "    )\n",
    "    for text in legend.get_texts():\n",
    "        text.set_color(\"white\")\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(out_dir, f\"{name}_COMBINED.png\")\n",
    "    plt.savefig(out_path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"✓ Guardado: {out_path}\")\n",
    "\n",
    "# ===========================\n",
    "# AVAILABILITY\n",
    "# ===========================\n",
    "\n",
    "def classify_state_from_levels(levels):\n",
    "    if not levels:\n",
    "        return \"Blind\"\n",
    "    lvls = [int(x) for x in levels if x is not None]\n",
    "    if all(l == 1 for l in lvls):\n",
    "        return \"Good\"\n",
    "    if all(l == 5 for l in lvls):\n",
    "        return \"Blind\"\n",
    "    if any(l in (3, 4) for l in lvls):\n",
    "        return \"Warning\"\n",
    "    if any(l == 2 for l in lvls) and all(l <= 2 for l in lvls):\n",
    "        return \"Careful\"\n",
    "    return \"Warning\"\n",
    "\n",
    "def build_availability_from_series(series: dict, insts: list):\n",
    "    all_times = set()\n",
    "    for inst in insts:\n",
    "        x, _ = series[inst]\n",
    "        all_times.update(x.tolist())\n",
    "    times = sorted(all_times)\n",
    "    states, codes = [], []\n",
    "    for t in times:\n",
    "        lvls = []\n",
    "        for inst in insts:\n",
    "            x, y = series[inst]\n",
    "            idx = np.searchsorted(x, t, side=\"right\") - 1\n",
    "            idx = max(0, min(idx, len(y) - 1))\n",
    "            lvls.append(int(y[idx]))\n",
    "        st = classify_state_from_levels(lvls)\n",
    "        states.append(st)\n",
    "        codes.append(STATE_MAP[st])\n",
    "    return pd.DataFrame({\"time_s\": times, \"state\": states, \"state_code\": codes})\n",
    "\n",
    "def plot_availability_timeseries(var_name: str, df_av: pd.DataFrame, save_path: str):\n",
    "    times = df_av[\"time_s\"].tolist()\n",
    "    values = df_av[\"state_code\"].tolist()\n",
    "    fig, ax = plt.subplots(figsize=(16, 9), dpi=120)\n",
    "    fig.patch.set_facecolor(\"#06243A\")\n",
    "    ax.set_facecolor(\"#06243A\")\n",
    "    for lvl, col in ZONE_COLORS.items():\n",
    "        ax.axhspan(lvl, lvl + 1, color=col, alpha=0.28)\n",
    "    ax.step(times, values, where=\"post\", marker=\"o\", mfc=\"none\",\n",
    "            markersize=6, linewidth=1.8, color=\"#00CED1\")\n",
    "    ax.set_xlim(0, T_MAX)\n",
    "    ax.set_xlabel(\"Time (s)\", fontsize=20, color=\"white\", labelpad=15)\n",
    "    ax.set_ylabel(\"Availability State\", fontsize=20, color=\"white\", labelpad=15)\n",
    "    ax.set_yticks(list(STATE_MAP.values()))\n",
    "    ax.set_yticklabels(list(STATE_MAP.keys()), color=\"white\", fontsize=16)\n",
    "    ax.set_title(f\"{var_name.replace('_',' ')} Availability\", color=\"white\", fontsize=28, pad=40)\n",
    "    ax.tick_params(colors=\"white\", labelsize=14)\n",
    "    ax.grid(color=\"white\", linestyle=\"--\", alpha=0.25, linewidth=1)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"white\")\n",
    "    fig.subplots_adjust(top=0.88, bottom=0.18)\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=220)\n",
    "    plt.close(fig)\n",
    "    print(f\"✓ Guardado: {save_path}\")\n",
    "\n",
    "# ===========================\n",
    "# EJECUCIÓN\n",
    "# ===========================\n",
    "\n",
    "for var in VARIABLES:\n",
    "    csv1 = f\"{var}_1.csv\"\n",
    "    csv2 = f\"{var}_2.csv\"\n",
    "    if not (os.path.exists(csv1) and os.path.exists(csv2)):\n",
    "        print(f\"⚠️  Omito {var}: faltan {csv1} o {csv2}\")\n",
    "        continue\n",
    "    series, insts = build_series_max(csv1, csv2)\n",
    "    # Plot damage curves\n",
    "    plot_variable(var, series, insts, out_dir=OUT_DIR)\n",
    "    # Availability\n",
    "    df_av = build_availability_from_series(series, insts)\n",
    "    csv_out = os.path.join(OUT_DIR, f\"{var}_availability.csv\")\n",
    "    df_av.to_csv(csv_out, index=False)\n",
    "    plot_availability_timeseries(var, df_av, os.path.join(OUT_DIR, f\"{var}_availability.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
