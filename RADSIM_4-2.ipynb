{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b97726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Parameters loaded from MELCOR (no JSON)\n",
      " - Control functions from 3000 to 3062\n",
      " - Simulation time: 1s to 107288s\n",
      " - Number of control volumes (batches): 7\n",
      " - Volumes (keys 1..N, cm³): {1: 144162662.5198637, 2: 123851651.02197042, 3: 565922975.1899465, 4: 6471758280.302349, 5: 79999998.11147389, 6: 1e+16, 7: 6509367032.222646}\n",
      " - Index->CVH map: {1: 110, 2: 160, 3: 200, 4: 305, 5: 1, 6: 600, 7: 201}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import interp1d\n",
    "import radioactivedecay as rd\n",
    "from pypost.codes.melcor import MELCOR\n",
    "\n",
    "# =======================\n",
    "# INPUT FROM MELCOR (same variable structure)\n",
    "# =======================\n",
    "\n",
    "# --- Adjust here the file and the CVHs you want to use ---\n",
    "filename = \"MC_Step.ptf\"\n",
    "cv_list = [110, 160, 200, 305, 1, 600, 201]\n",
    "\n",
    "# --- Adjust here the CFVALU range that previously came from JSON ---\n",
    "start_number = 3000     # <-- set your real start\n",
    "end_number   = 3062     # <-- set your real end\n",
    "\n",
    "# Open MELCOR file\n",
    "index = MELCOR.openPlotFile(filename)\n",
    "\n",
    "# Take time values from the first reference variable (as requested)\n",
    "primer_cv = cv_list[0]\n",
    "var_ref = f\"CVH-VOLLIQ_{primer_cv}\"\n",
    "data_ref = np.array(MELCOR.getData(index, var_ref))\n",
    "\n",
    "t_ini_raw = float(data_ref[0, 0])\n",
    "t_fin_raw = float(data_ref[-1, 0])\n",
    "\n",
    "# +1 s and truncated (remove decimals)\n",
    "start_time = int(t_ini_raw + 1)\n",
    "end_time   = int(t_fin_raw + 1)\n",
    "\n",
    "# =======================\n",
    "# Calculation of V_values (keys 1..N) and index->CVH map\n",
    "# =======================\n",
    "V_values = {}                 # dict[int -> float] in cm³; keys 1..N\n",
    "cv_index_map = {}             # dict[int -> int]  index->CVH (for info only)\n",
    "\n",
    "for idx, cv in enumerate(cv_list, start=1):   # idx = 1..N\n",
    "    cv_index_map[idx] = int(cv)\n",
    "\n",
    "    var_liq = f\"CVH-VOLLIQ_{cv}\"\n",
    "    var_vap = f\"CVH-VOLVAP_{cv}\"\n",
    "\n",
    "    data_liq = np.array(MELCOR.getData(index, var_liq))\n",
    "    data_vap = np.array(MELCOR.getData(index, var_vap))\n",
    "\n",
    "    t_liq = data_liq[:, 0]\n",
    "    v_liq = data_liq[:, 1]\n",
    "    t_vap = data_vap[:, 0]\n",
    "    v_vap = data_vap[:, 1]\n",
    "\n",
    "    # Align time arrays if needed\n",
    "    if (data_liq.shape[0] != data_vap.shape[0]) or (not np.allclose(t_liq, t_vap)):\n",
    "        v_vap = np.interp(t_liq, t_vap, v_vap)\n",
    "\n",
    "    total_m3 = v_liq + v_vap\n",
    "    avg_m3   = float(np.mean(total_m3))\n",
    "    avg_cm3  = avg_m3 * 1_000_000.0  # m³ -> cm³\n",
    "\n",
    "    # Key = sequential index (1..N), not the CVH number\n",
    "    V_values[idx] = avg_cm3\n",
    "\n",
    "# Build CFVALU and batches (identical to your structure)\n",
    "mass_data_lines = [f\"CFVALU_{i}\" for i in range(start_number, end_number + 1)]\n",
    "batches = [mass_data_lines[i:i + 9] for i in range(0, len(mass_data_lines), 9)]\n",
    "num_batches = len(batches)\n",
    "\n",
    "# Messages (same organization and variables; only data source changes)\n",
    "print(f\"\\n[INFO] Parameters loaded from MELCOR (no JSON)\")\n",
    "print(f\" - Control functions from {start_number} to {end_number}\")\n",
    "print(f\" - Simulation time: {start_time}s to {end_time}s\")\n",
    "print(f\" - Number of control volumes (batches): {num_batches}\")\n",
    "print(f\" - Volumes (keys 1..N, cm³): {V_values}\")\n",
    "\n",
    "# (Optional) Show index -> CVH mapping\n",
    "print(f\" - Index->CVH map: {cv_index_map}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1cf648bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# OUTPUTS Y RADIONUCLIDE CLASSES\n",
    "# ================================\n",
    "output_directory_1 = \"proportions\"\n",
    "recalculate_proportions = False\n",
    "\n",
    "if not os.path.exists(output_directory_1):\n",
    "    os.makedirs(output_directory_1)\n",
    "    recalculate_proportions = True\n",
    "else:\n",
    "    expected_files = [f\"class_{i}_proportions.csv\" for i in range(1, 10)]\n",
    "    existing_files = os.listdir(output_directory_1)\n",
    "    if not all(f in existing_files for f in expected_files):\n",
    "        recalculate_proportions = True\n",
    "\n",
    "with open(\"class_inventories.json\", \"r\") as f:\n",
    "    class_inventories = json.load(f)\n",
    "\n",
    "# Convertir claves a enteros (opcional pero recomendable)\n",
    "class_inventories = {int(k): v for k, v in class_inventories.items()}        \n",
    "\n",
    "time_steps = np.arange(start_time, end_time, 1)\n",
    "all_class_proportions = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "000fd5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proportions successfully loaded.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# ==========================================\n",
    "# CALCULATION OR LOADING OF PROPORTIONS\n",
    "# ==========================================\n",
    "output_directory_1 = \"proportions\"\n",
    "os.makedirs(output_directory_1, exist_ok=True)\n",
    "expected_files = [f\"class_{i}_proportions.csv\" for i in range(1, 10)]\n",
    "recalc = not all(f in os.listdir(output_directory_1) for f in expected_files)\n",
    "\n",
    "all_class_proportions = {}\n",
    "\n",
    "if recalc:\n",
    "    for class_num, inv_props in class_inventories.items():\n",
    "        print(f\"Calculating proportions for class {class_num}...\")\n",
    "        inv = rd.Inventory({}, \"kg\")\n",
    "        # initialize 1 kg total distributed according to inventory proportions\n",
    "        inv += rd.Inventory({iso: 1.0 * prop for iso, prop in inv_props.items()}, \"kg\")\n",
    "        proportions = {iso: np.zeros(len(time_steps)) for iso in inv_props}\n",
    "        last_t = time_steps[0]\n",
    "        for i, t in enumerate(time_steps):\n",
    "            inv = inv.decay(t - last_t, 's') if i > 0 else inv\n",
    "            last_t = t\n",
    "            masses = inv.masses(\"kg\")\n",
    "            total = sum(masses.values())\n",
    "            for iso in proportions:\n",
    "                proportions[iso][i] = max(masses.get(iso, 0), 0) / total if total > 0 else 0\n",
    "\n",
    "        all_class_proportions[class_num] = proportions\n",
    "\n",
    "        # save CSV\n",
    "        csv_path = os.path.join(output_directory_1, f\"class_{class_num}_proportions.csv\")\n",
    "        with open(csv_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Time (s)\"] + list(proportions.keys()))\n",
    "            for i, t in enumerate(time_steps):\n",
    "                writer.writerow([t] + [proportions[iso][i] for iso in proportions])\n",
    "\n",
    "        # plot results\n",
    "        plt.figure(figsize=(8, 5))\n",
    "        for iso, arr in proportions.items():\n",
    "            plt.plot(time_steps, arr, label=iso)\n",
    "        plt.legend(); plt.grid(True)\n",
    "        plt.savefig(os.path.join(output_directory_1, f\"class_{class_num}_proportions.png\"))\n",
    "        plt.close()\n",
    "\n",
    "else:\n",
    "    for class_num in range(1, 10):\n",
    "        csv_path = os.path.join(output_directory_1, f\"class_{class_num}_proportions.csv\")\n",
    "        df = pd.read_csv(csv_path)\n",
    "        isotopes = df.columns.tolist()[1:]\n",
    "        all_class_proportions[class_num] = {\n",
    "            iso: df[iso].values for iso in isotopes\n",
    "        }\n",
    "    print(\"Proportions successfully loaded.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7eff0f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Masses ===\n",
      "[INFO] Loading masses from CSV…\n",
      "[Batch 1] Masses successfully reloaded.\n",
      "  Class 1 – first mass value for 'Kr-84' = nan\n",
      "\n",
      "=== Batch 2 — Masses ===\n",
      "[INFO] Loading masses from CSV…\n",
      "[Batch 2] Masses successfully reloaded.\n",
      "  Class 1 – first mass value for 'Kr-84' = nan\n",
      "\n",
      "=== Batch 3 — Masses ===\n",
      "[INFO] Loading masses from CSV…\n",
      "[Batch 3] Masses successfully reloaded.\n",
      "  Class 1 – first mass value for 'Kr-84' = nan\n",
      "\n",
      "=== Batch 4 — Masses ===\n",
      "[INFO] Loading masses from CSV…\n",
      "[Batch 4] Masses successfully reloaded.\n",
      "  Class 1 – first mass value for 'Kr-84' = nan\n",
      "\n",
      "=== Batch 5 — Masses ===\n",
      "[INFO] Loading masses from CSV…\n",
      "[Batch 5] Masses successfully reloaded.\n",
      "  Class 1 – first mass value for 'Kr-84' = nan\n",
      "\n",
      "=== Batch 6 — Masses ===\n",
      "[INFO] Loading masses from CSV…\n",
      "[Batch 6] Masses successfully reloaded.\n",
      "  Class 1 – first mass value for 'Kr-84' = nan\n",
      "\n",
      "=== Batch 7 — Masses ===\n",
      "[INFO] Loading masses from CSV…\n",
      "[Batch 7] Masses successfully reloaded.\n",
      "  Class 1 – first mass value for 'Kr-84' = nan\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt\n",
    "from pypost.codes.melcor import MELCOR\n",
    "\n",
    "# ==========================================\n",
    "# MODULE: CALCULATION OR LOADING OF MASSES (all batches)\n",
    "# ==========================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Masses ===\")\n",
    "\n",
    "    # 1) Output directory, create if necessary\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    # 2) Do the mass CSV files already exist?\n",
    "    expected = [f\"class_{i}_masses.csv\" for i in range(1, 10)]\n",
    "    recalc = not all(fn in os.listdir(output_directory) for fn in expected)\n",
    "\n",
    "    all_class_masses = {}\n",
    "\n",
    "    if recalc:\n",
    "        print(\"[INFO] Calculating masses from MELCOR…\")\n",
    "        batch = batches[batch_num - 1]               # the 9 variables of this batch\n",
    "\n",
    "        # Loop through each of the 9 classes\n",
    "        for class_num, var in enumerate(batch, start=1):\n",
    "            print(f\"  Class {class_num}: variable '{var}'\")\n",
    "            # 2.1) Read from MELCOR\n",
    "            idx = MELCOR.openPlotFile(\"MC_Step.ptf\")\n",
    "            data = np.array(MELCOR.getData(idx, var))\n",
    "            t, M = data[:, 0], data[:, 1]\n",
    "\n",
    "            # 2.2) Filter and make uniform\n",
    "            mask = (t >= start_time) & (t <= end_time)\n",
    "            uni_t = np.arange(start_time, end_time, 1)\n",
    "            uni_M = interp1d(t[mask], M[mask],\n",
    "                             kind='previous',\n",
    "                             fill_value=\"extrapolate\")(uni_t)\n",
    "\n",
    "            # 2.3) Distribute according to proportions\n",
    "            props = all_class_proportions[class_num]\n",
    "            masses = {iso: props[iso] * uni_M for iso in props}\n",
    "            all_class_masses[class_num] = masses\n",
    "\n",
    "            # 2.4) Save to CSV\n",
    "            csv_path = os.path.join(output_directory,\n",
    "                                    f\"class_{class_num}_masses.csv\")\n",
    "            with open(csv_path, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\"] + list(masses.keys()))\n",
    "                for i, t0 in enumerate(uni_t):\n",
    "                    w.writerow([t0] + [masses[iso][i] for iso in masses])\n",
    "\n",
    "            # 2.5) Plot results\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            for iso, arr in masses.items():\n",
    "                plt.plot(uni_t, arr, label=iso)\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Mass (kg)\")\n",
    "            plt.title(f\"Batch {batch_num} – Class {class_num} Masses\")\n",
    "            plt.legend(); plt.grid(True)\n",
    "            plt.savefig(os.path.join(output_directory,\n",
    "                                     f\"class_{class_num}_masses.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Masses calculated and saved.\")\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] Loading masses from CSV…\")\n",
    "        for class_num in range(1, 10):\n",
    "            csv_path = os.path.join(output_directory,\n",
    "                                    f\"class_{class_num}_masses.csv\")\n",
    "            df = pd.read_csv(csv_path)\n",
    "            isotopes = df.columns.tolist()[1:]\n",
    "            all_class_masses[class_num] = {\n",
    "                iso: df[iso].values for iso in isotopes\n",
    "            }\n",
    "        print(f\"[Batch {batch_num}] Masses successfully reloaded.\")\n",
    "\n",
    "    # Now `all_class_masses` is ready for this batch_num\n",
    "    # Quick check:\n",
    "    print(f\"  Class 1 – first mass value for '{list(all_class_masses[1].keys())[0]}' =\",\n",
    "          all_class_masses[1][list(all_class_masses[1].keys())[0]][0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7de50f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Activities ===\n",
      "[INFO] Loading activities from CSV…\n",
      "[Batch 1] Activities successfully reloaded.\n",
      "\n",
      "=== Batch 2 — Activities ===\n",
      "[INFO] Loading activities from CSV…\n",
      "[Batch 2] Activities successfully reloaded.\n",
      "\n",
      "=== Batch 3 — Activities ===\n",
      "[INFO] Loading activities from CSV…\n",
      "[Batch 3] Activities successfully reloaded.\n",
      "\n",
      "=== Batch 4 — Activities ===\n",
      "[INFO] Loading activities from CSV…\n",
      "[Batch 4] Activities successfully reloaded.\n",
      "\n",
      "=== Batch 5 — Activities ===\n",
      "[INFO] Loading activities from CSV…\n",
      "[Batch 5] Activities successfully reloaded.\n",
      "\n",
      "=== Batch 6 — Activities ===\n",
      "[INFO] Loading activities from CSV…\n",
      "[Batch 6] Activities successfully reloaded.\n",
      "\n",
      "=== Batch 7 — Activities ===\n",
      "[INFO] Loading activities from CSV…\n",
      "[Batch 7] Activities successfully reloaded.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import radioactivedecay as rd\n",
    "\n",
    "# ==========================================\n",
    "# MODULE: CALCULATION OR LOADING OF ACTIVITIES (all batches)\n",
    "# ==========================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Activities ===\")\n",
    "\n",
    "    # 1) Output directory and subfolder for plots\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    dose_plots_dir = os.path.join(output_directory, 'dose_rate_plots')\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "    os.makedirs(dose_plots_dir, exist_ok=True)\n",
    "\n",
    "    # 2) Reload MASSES from CSV\n",
    "    all_class_masses = {}\n",
    "    for class_num in range(1, 10):\n",
    "        mass_csv = os.path.join(output_directory, f\"class_{class_num}_masses.csv\")\n",
    "        df_mass = pd.read_csv(mass_csv)\n",
    "        isotopes = df_mass.columns.tolist()[1:]\n",
    "        all_class_masses[class_num] = {iso: df_mass[iso].values for iso in isotopes}\n",
    "\n",
    "    # 3) Check for existing ACTIVITY CSV files\n",
    "    expected = [f\"class_{i}_activities.csv\" for i in range(1, 10)]\n",
    "    recalc_act = not all(fn in os.listdir(output_directory) for fn in expected)\n",
    "\n",
    "    all_class_activities = {}\n",
    "\n",
    "    if recalc_act:\n",
    "        print(\"[INFO] Calculating activities from masses…\")\n",
    "        for class_num, isotope_masses in all_class_masses.items():\n",
    "            print(f\"  Class {class_num}\")\n",
    "            # Prepare the activity dictionary (Ci)\n",
    "            acts = {iso: np.zeros(len(time_steps)) for iso in isotope_masses}\n",
    "\n",
    "            for idx, t in enumerate(time_steps):\n",
    "                inv = rd.Inventory({}, \"kg\")\n",
    "                for iso, mass_arr in isotope_masses.items():\n",
    "                    m = mass_arr[idx]\n",
    "                    if m > 0:\n",
    "                        inv += rd.Inventory({iso: m}, \"kg\")\n",
    "                bq_dict = inv.activities(\"Bq\")\n",
    "                for iso, bq in bq_dict.items():\n",
    "                    acts[iso][idx] = bq / 3.7e10  # Convert Bq → Ci\n",
    "\n",
    "            all_class_activities[class_num] = acts\n",
    "\n",
    "            # Save CSV\n",
    "            csv_path = os.path.join(output_directory, f\"class_{class_num}_activities.csv\")\n",
    "            with open(csv_path, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\"] + list(acts.keys()))\n",
    "                for i, t in enumerate(time_steps):\n",
    "                    w.writerow([t] + [acts[iso][i] for iso in acts])\n",
    "\n",
    "            # Plot\n",
    "            plt.figure(figsize=(8, 5))\n",
    "            for iso, arr in acts.items():\n",
    "                plt.plot(time_steps, arr, label=iso)\n",
    "            plt.xlabel(\"Time (s)\")\n",
    "            plt.ylabel(\"Activity (Ci)\")\n",
    "            plt.title(f\"Batch {batch_num} – Class {class_num} Activities\")\n",
    "            plt.legend(); plt.grid(True)\n",
    "            plt.savefig(os.path.join(output_directory, f\"class_{class_num}_activities.png\"))\n",
    "            plt.close()\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Activities calculated and saved.\")\n",
    "\n",
    "    else:\n",
    "        print(\"[INFO] Loading activities from CSV…\")\n",
    "        for class_num in range(1, 10):\n",
    "            csv_path = os.path.join(output_directory, f\"class_{class_num}_activities.csv\")\n",
    "            df_act = pd.read_csv(csv_path)\n",
    "            isotopes = df_act.columns.tolist()[1:]\n",
    "            all_class_activities[class_num] = {\n",
    "                iso: df_act[iso].values for iso in isotopes\n",
    "            }\n",
    "        print(f\"[Batch {batch_num}] Activities successfully reloaded.\")\n",
    "\n",
    "    # Now you can use all_class_activities[batch_num]...\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c20103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"energies_data.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "gamma_energies = data[\"gamma_energies\"]\n",
    "beta_emitter_energies = data[\"beta_emitter_energies\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5c2fe37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Bremsstrahlung energy added to gamma_energies for all isotopes.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ==========================================\n",
    "# MODULE: ADD BREMSSTRAHLUNG CONTRIBUTION\n",
    "# ==========================================\n",
    "# Assumes gamma_energies and beta_emitter_energies are already defined elsewhere\n",
    "\n",
    "Z_air = 7.3  # effective atomic number of air\n",
    "\n",
    "for iso, E_beta in beta_emitter_energies.items():\n",
    "    # Add bremsstrahlung energy (in MeV)\n",
    "    E_brem = 1.33e-4 * Z_air * E_beta**2\n",
    "    gamma_energies[iso] = gamma_energies.get(iso, 0) + E_brem\n",
    "\n",
    "print(\"[INFO] Bremsstrahlung energy added to gamma_energies for all isotopes.\")\n",
    "\n",
    "# ==========================================\n",
    "# SKIPPING AVERAGE GAMMA ENERGY CALCULATION\n",
    "# ==========================================\n",
    "# This block previously calculated the average gamma energy per class and per time step.\n",
    "# It has been intentionally removed since only the bremsstrahlung correction is needed.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28fa095",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.special as sp\n",
    "import json\n",
    "\n",
    "# ==================================\n",
    "# LOAD GAMMA ENERGIES (with bremsstrahlung already added)\n",
    "# ==================================\n",
    "with open(\"energies_data.json\", \"r\") as f:\n",
    "    energies_data = json.load(f)\n",
    "\n",
    "gamma_energies = energies_data[\"gamma_energies\"]\n",
    "\n",
    "# ==================================\n",
    "# CONSTANTS FOR DOSE RATE CALCULATION\n",
    "# ==================================\n",
    "\n",
    "# These are updated dynamically per batch in the next cell\n",
    "density = 0.001  # g/cm³\n",
    "\n",
    "# ==================================\n",
    "# MASS ATTENUATION AND ABSORPTION FUNCTIONS\n",
    "# ==================================\n",
    "\n",
    "def mass_att(E, a1=-0.037274, b1=0.101714, c1=-0.274123):\n",
    "    \"\"\"Mass attenuation coefficient as a function of photon energy E (MeV).\"\"\"\n",
    "    if E <= 0:\n",
    "        return 0\n",
    "    return a1 + b1 * E**c1\n",
    "\n",
    "def mass_ab(E, a2=0, b2=-5.2588e-4, c2=-5.2077e-3, d=2.8172e-2, e=-1.7809e-2):\n",
    "    \"\"\"Mass absorption coefficient as a function of photon energy E (MeV).\"\"\"\n",
    "    if E <= 0:\n",
    "        return 0\n",
    "    return a2 + b2 * E + c2 * (math.log(E))**2 + d * math.sqrt(E) + e * math.log(E)\n",
    "\n",
    "def calc_mu_m(E):\n",
    "    \"\"\"Compute μm depending on photon energy E (keV).\"\"\"\n",
    "    if 0 <= E <= 200:\n",
    "        B0, B1, B2, B3 = 0.29839, -0.00269, 1.67948E-5, -3.75963E-8\n",
    "        mu_m = B3 * E**3 + B2 * E**2 + B1 * E + B0\n",
    "    elif E > 200:\n",
    "        B0, B1, B2 = 0.13556, -9.10106E-5, 2.39846E-8\n",
    "        mu_m = B2 * E**2 + B1 * E + B0\n",
    "    else:\n",
    "        return 0\n",
    "    return mu_m\n",
    "\n",
    "# ==================================\n",
    "# CIRCULAR BASE METHOD FOR GAMMA FLUX\n",
    "# ==================================\n",
    "\n",
    "def gamma_flux_circular_base(activity, R, h, mass_att_func, E):\n",
    "    \"\"\"Computes gamma flux using the circular base method.\"\"\"\n",
    "    if E <= 0 or activity <= 0:\n",
    "        return 0.0\n",
    "    mu = mass_att_func(E)\n",
    "    if mu <= 0:\n",
    "        return 0.0\n",
    "\n",
    "    r = np.linspace(0, R, 10)\n",
    "    theta = np.linspace(0, np.arctan(R / h), 10)\n",
    "    R_grid, Theta_grid = np.meshgrid(r, theta)\n",
    "    path_length = np.sqrt(R_grid**2 + h**2)\n",
    "    b1 = mu * path_length\n",
    "    E1_term = sp.exp1(b1)\n",
    "    E1_sec_term = sp.exp1(b1 / np.cos(Theta_grid))\n",
    "    integrand = (((3.7e10) * activity) / (2 * np.pi * R**2)) * (E1_term - E1_sec_term)\n",
    "    result = np.trapz(np.trapz(integrand * R_grid, r, axis=0), theta)\n",
    "    return result\n",
    "\n",
    "# ==================================\n",
    "# PLOTTING FUNCTIONS FOR DOSE RATES\n",
    "# ==================================\n",
    "\n",
    "def plot_dose_rates(dose_rates, title, filename, out_dir):\n",
    "    \"\"\"Plot dose rate evolution for multiple isotopes.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for iso, dr in dose_rates.items():\n",
    "        plt.plot(time_steps, dr, label=f\"{iso} Dose Rate (rads/h)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Dose Rate (rads/h)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(out_dir, filename))\n",
    "    plt.close()\n",
    "\n",
    "def plot_accumulated_dose(total_dose, title, filename, out_dir):\n",
    "    \"\"\"Plot total accumulated dose as a function of time.\"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(time_steps, total_dose, label=\"Total Accumulated Dose (rads)\")\n",
    "    plt.xlabel(\"Time (s)\")\n",
    "    plt.ylabel(\"Accumulated Dose (rads)\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(out_dir, filename))\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3569061",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Dose Rates (Sphere) ===\n",
      "[INFO] Per-class CSVs already exist.\n",
      "[INFO] Total accumulated CSV already exists. Reloading values…\n",
      "\n",
      "=== Batch 2 — Dose Rates (Sphere) ===\n",
      "[INFO] Per-class CSVs already exist.\n",
      "[INFO] Total accumulated CSV already exists. Reloading values…\n",
      "\n",
      "=== Batch 3 — Dose Rates (Sphere) ===\n",
      "[INFO] Per-class CSVs already exist.\n",
      "[INFO] Total accumulated CSV already exists. Reloading values…\n",
      "\n",
      "=== Batch 4 — Dose Rates (Sphere) ===\n",
      "[INFO] Per-class CSVs already exist.\n",
      "[INFO] Total accumulated CSV already exists. Reloading values…\n",
      "\n",
      "=== Batch 5 — Dose Rates (Sphere) ===\n",
      "[INFO] Per-class CSVs already exist.\n",
      "[INFO] Total accumulated CSV already exists. Reloading values…\n",
      "\n",
      "=== Batch 6 — Dose Rates (Sphere) ===\n",
      "[INFO] Per-class CSVs already exist.\n",
      "[INFO] Total accumulated CSV already exists. Reloading values…\n",
      "\n",
      "=== Batch 7 — Dose Rates (Sphere) ===\n",
      "[INFO] Per-class CSVs already exist.\n",
      "[INFO] Total accumulated CSV already exists. Reloading values…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: CALCULATION OR LOADING OF DOSE RATE (Sphere Hypothesis)\n",
    "# ===============================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Dose Rates (Sphere) ===\")\n",
    "\n",
    "    # 1) Output directories and control volume\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    plots_dir = os.path.join(output_directory, 'dose_rate_plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    V = V_values[batch_num]\n",
    "\n",
    "    # 2) Reload ACTIVITIES (gamma energies come from JSON)\n",
    "    all_class_activities = {}\n",
    "    for class_num in range(1, 10):\n",
    "        act_csv = os.path.join(output_directory, f\"class_{class_num}_activities.csv\")\n",
    "        df_act = pd.read_csv(act_csv)\n",
    "        isotopes = df_act.columns.tolist()[1:]\n",
    "        all_class_activities[class_num] = {iso: df_act[iso].values for iso in isotopes}\n",
    "\n",
    "    # 3) Geometric parameters\n",
    "    R_sphere = ((3 * V) / (4 * np.pi)) ** (1 / 3)\n",
    "    density = 0.001  # g/cm³\n",
    "\n",
    "    # 4) Check for per-class CSV files\n",
    "    class_csvs = [f\"dose_rate_sphere_class_{i}.csv\" for i in range(1, 10)]\n",
    "    have_class = all(fn in os.listdir(plots_dir) for fn in class_csvs)\n",
    "\n",
    "    # 5) Check for total accumulated CSV\n",
    "    total_csv = \"total_accumulated_dose_sphere_all_classes.csv\"\n",
    "    have_total = total_csv in os.listdir(plots_dir)\n",
    "\n",
    "    total_accumulated = np.zeros(len(time_steps))\n",
    "\n",
    "    # ===============================================\n",
    "    # CALCULATE IF MISSING\n",
    "    # ===============================================\n",
    "    if not have_class:\n",
    "        print(\"[INFO] Missing per-class dose rate CSVs → recalculating everything…\")\n",
    "\n",
    "        for class_num, isotopes in class_inventories.items():\n",
    "            acts = all_class_activities[class_num]\n",
    "            dose_rates = {iso: np.zeros(len(time_steps)) for iso in isotopes}\n",
    "            total_per_time = np.zeros(len(time_steps))\n",
    "\n",
    "            for i, t in enumerate(time_steps):\n",
    "                step_sum = 0.0\n",
    "                for iso in isotopes:\n",
    "                    E = gamma_energies.get(iso, 0.0)\n",
    "                    if E <= 0:\n",
    "                        continue\n",
    "                    A = acts.get(iso, np.zeros(len(time_steps)))[i]\n",
    "                    if A <= 0:\n",
    "                        continue\n",
    "\n",
    "                    mu = mass_att(E)\n",
    "                    sigma = max(1e-4, mass_ab(E))\n",
    "                    if mu == 0:\n",
    "                        continue\n",
    "\n",
    "                    flux = (3.7e10) * (A / (V * density * mu)) * (1 - np.exp(-density * R_sphere * mu))\n",
    "                    dr = 5.77e-5 * flux * E * sigma\n",
    "                    dose_rates[iso][i] = dr\n",
    "                    step_sum += dr\n",
    "\n",
    "                total_per_time[i] = step_sum / 3600.0  # rads/h\n",
    "\n",
    "            # Accumulate dose\n",
    "            acc = 0.0\n",
    "            for i in range(len(time_steps)):\n",
    "                acc += total_per_time[i]\n",
    "                total_accumulated[i] += acc\n",
    "\n",
    "            # Save per-class CSV\n",
    "            out_csv = os.path.join(plots_dir, f\"dose_rate_sphere_class_{class_num}.csv\")\n",
    "            with open(out_csv, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow([\"Time (s)\"] + list(dose_rates.keys()))\n",
    "                for j, tt in enumerate(time_steps):\n",
    "                    writer.writerow([tt] + [dose_rates[iso][j] for iso in dose_rates])\n",
    "\n",
    "            # Plot per-class dose rates\n",
    "            plot_dose_rates(\n",
    "                dose_rates,\n",
    "                f\"Dose Rates (Sphere) - Class {class_num}\",\n",
    "                f\"dose_rates_sphere_class_{class_num}.png\",\n",
    "                out_dir=plots_dir\n",
    "            )\n",
    "\n",
    "    # ===============================================\n",
    "    # IF EXISTS, JUST RELOAD\n",
    "    # ===============================================\n",
    "    else:\n",
    "        print(\"[INFO] Per-class CSVs already exist.\")\n",
    "        for class_num in range(1, 10):\n",
    "            df_dr = pd.read_csv(os.path.join(plots_dir, f\"dose_rate_sphere_class_{class_num}.csv\"))\n",
    "            isot = df_dr.columns.tolist()[1:]\n",
    "            drs = {iso: df_dr[iso].values for iso in isot}\n",
    "\n",
    "            acc = 0.0\n",
    "            for i in range(len(time_steps)):\n",
    "                step = sum(drs[iso][i] for iso in isot) / 3600.0\n",
    "                acc += step\n",
    "                total_accumulated[i] += acc\n",
    "\n",
    "    # 6) Save or reload total accumulated CSV\n",
    "    total_path = os.path.join(plots_dir, total_csv)\n",
    "    if not have_total:\n",
    "        print(\"[INFO] Missing total accumulated CSV → generating now…\")\n",
    "        with open(total_path, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "            for tt, val in zip(time_steps, total_accumulated):\n",
    "                w.writerow([tt, val])\n",
    "    else:\n",
    "        print(\"[INFO] Total accumulated CSV already exists. Reloading values…\")\n",
    "        df_tot = pd.read_csv(total_path)\n",
    "        total_accumulated = df_tot[\"Accumulated_Dose (rads)\"].values\n",
    "\n",
    "    # 7) Plot total accumulated dose\n",
    "    plot_accumulated_dose(\n",
    "        total_accumulated,\n",
    "        f\"Total Accumulated Dose (Sphere) - Batch {batch_num}\",\n",
    "        f\"total_accumulated_dose_sphere_batch_{batch_num}.png\",\n",
    "        out_dir=plots_dir\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81448689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Circular Base Method ===\n",
      "[INFO] Per-class CSV files exist → reloading dose rates from CSV…\n",
      "[Batch 1] Dose rates successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 2 — Circular Base Method ===\n",
      "[INFO] Per-class CSV files exist → reloading dose rates from CSV…\n",
      "[Batch 2] Dose rates successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 3 — Circular Base Method ===\n",
      "[INFO] Per-class CSV files exist → reloading dose rates from CSV…\n",
      "[Batch 3] Dose rates successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 4 — Circular Base Method ===\n",
      "[INFO] Per-class CSV files exist → reloading dose rates from CSV…\n",
      "[Batch 4] Dose rates successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 5 — Circular Base Method ===\n",
      "[INFO] Per-class CSV files exist → reloading dose rates from CSV…\n",
      "[Batch 5] Dose rates successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 6 — Circular Base Method ===\n",
      "[INFO] Per-class CSV files exist → reloading dose rates from CSV…\n",
      "[Batch 6] Dose rates successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 7 — Circular Base Method ===\n",
      "[INFO] Per-class CSV files exist → reloading dose rates from CSV…\n",
      "[Batch 7] Dose rates successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.special as sp\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: CALCULATION OR LOADING OF DOSE RATE (Circular Base Method)\n",
    "# ===============================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Circular Base Method ===\")\n",
    "\n",
    "    # 1) Output directory and control volume\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    plots_dir = os.path.join(output_directory, 'dose_rate_plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    V = V_values[batch_num]\n",
    "\n",
    "    # 2) Reload ACTIVITIES (gamma energies come from JSON)\n",
    "    all_class_activities = {}\n",
    "    for class_num in range(1, 10):\n",
    "        act_csv = os.path.join(output_directory, f\"class_{class_num}_activities.csv\")\n",
    "        df_act = pd.read_csv(act_csv)\n",
    "        isotopes = df_act.columns.tolist()[1:]\n",
    "        all_class_activities[class_num] = {iso: df_act[iso].values for iso in isotopes}\n",
    "\n",
    "    # 3) Parameters and total accumulator\n",
    "    total_accumulated_csv = f\"total_accumulated_dose_cb_batch_{batch_num}.csv\"\n",
    "    total_accumulated_path = os.path.join(plots_dir, total_accumulated_csv)\n",
    "\n",
    "    total_accumulated_dose_cb = np.zeros(len(time_steps))\n",
    "    h_base = 25  # cm (height of source)\n",
    "    R_base = 15  # cm (radius of circular base)\n",
    "\n",
    "    # 4) Check if per-class recalculation is needed\n",
    "    expected = [f\"dose_rate_circular_base_class_{i}.csv\" for i in range(1, 10)]\n",
    "    need_recalc = not all(fn in os.listdir(plots_dir) for fn in expected)\n",
    "\n",
    "    # ===============================================\n",
    "    # CALCULATE IF MISSING\n",
    "    # ===============================================\n",
    "    if need_recalc:\n",
    "        print(\"[INFO] Missing per-class CSV files → calculating dose rates (Circular Base)…\")\n",
    "\n",
    "        for class_num, isotopes in class_inventories.items():\n",
    "            acts = all_class_activities[class_num]\n",
    "            dose_rates_cb = {iso: np.zeros(len(time_steps)) for iso in isotopes}\n",
    "            total_per_timestep = np.zeros(len(time_steps))\n",
    "\n",
    "            for i, t in enumerate(time_steps):\n",
    "                sum_step = 0.0\n",
    "                for iso in isotopes:\n",
    "                    E = gamma_energies.get(iso, 0.0)\n",
    "                    if E <= 0:\n",
    "                        continue\n",
    "\n",
    "                    A = acts.get(iso, np.zeros(len(time_steps)))[i]\n",
    "                    if A <= 0:\n",
    "                        continue\n",
    "\n",
    "                    mu = mass_att(E)\n",
    "                    sigma = max(1e-4, mass_ab(E))\n",
    "                    if mu == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Compute gamma flux using the circular base geometry\n",
    "                    flux = gamma_flux_circular_base(A, R_base, h_base, mass_att, E)\n",
    "                    dr = 5.77e-5 * flux * E * sigma\n",
    "                    if np.isnan(dr):\n",
    "                        continue\n",
    "\n",
    "                    dose_rates_cb[iso][i] = dr\n",
    "                    sum_step += dr / 3600.0  # convert to rads/h\n",
    "\n",
    "                total_per_timestep[i] = sum_step\n",
    "\n",
    "            # Accumulate dose per class\n",
    "            acc = 0.0\n",
    "            for i in range(len(time_steps)):\n",
    "                acc += total_per_timestep[i]\n",
    "                total_accumulated_dose_cb[i] += acc\n",
    "\n",
    "            # Save per-class CSV\n",
    "            out_csv = os.path.join(plots_dir, f\"dose_rate_circular_base_class_{class_num}.csv\")\n",
    "            with open(out_csv, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\"] + list(dose_rates_cb.keys()))\n",
    "                for j, t in enumerate(time_steps):\n",
    "                    w.writerow([t] + [dose_rates_cb[iso][j] for iso in isotopes])\n",
    "\n",
    "            # Plot per-class dose rate\n",
    "            plot_dose_rates(\n",
    "                dose_rates_cb,\n",
    "                f\"Dose Rates (Circular Base) - Class {class_num}\",\n",
    "                f\"dose_rates_circular_base_class_{class_num}.png\",\n",
    "                out_dir=plots_dir\n",
    "            )\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Per-class dose rates calculated.\")\n",
    "\n",
    "    # ===============================================\n",
    "    # IF EXISTS, JUST RELOAD\n",
    "    # ===============================================\n",
    "    else:\n",
    "        print(\"[INFO] Per-class CSV files exist → reloading dose rates from CSV…\")\n",
    "\n",
    "        for class_num in range(1, 10):\n",
    "            df_cb = pd.read_csv(os.path.join(plots_dir, f\"dose_rate_circular_base_class_{class_num}.csv\"))\n",
    "            isot = df_cb.columns.tolist()[1:]\n",
    "            drs = {iso: df_cb[iso].values for iso in isot}\n",
    "\n",
    "            acc = 0.0\n",
    "            for i in range(len(time_steps)):\n",
    "                step = sum(drs[iso][i] for iso in isot) / 3600.0\n",
    "                acc += step\n",
    "                total_accumulated_dose_cb[i] += acc\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Dose rates successfully reloaded.\")\n",
    "\n",
    "    # ===============================================\n",
    "    # SAVE OR RELOAD TOTAL ACCUMULATED DOSE\n",
    "    # ===============================================\n",
    "    if not os.path.exists(total_accumulated_path):\n",
    "        print(\"[INFO] Missing total accumulated CSV → generating it now…\")\n",
    "        with open(total_accumulated_path, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "            for tt, val in zip(time_steps, total_accumulated_dose_cb):\n",
    "                w.writerow([tt, val])\n",
    "    else:\n",
    "        print(\"[INFO] Total accumulated CSV already exists → reloading…\")\n",
    "        df_tot = pd.read_csv(total_accumulated_path)\n",
    "        total_accumulated_dose_cb = df_tot[\"Accumulated_Dose (rads)\"].values\n",
    "\n",
    "    # ===============================================\n",
    "    # PLOT TOTAL ACCUMULATED DOSE\n",
    "    # ===============================================\n",
    "    plot_accumulated_dose(\n",
    "        total_accumulated_dose_cb,\n",
    "        f\"Total Accumulated Dose (Circular Base) - Batch {batch_num}\",\n",
    "        f\"total_accumulated_dose_circular_base_batch_{batch_num}.png\",\n",
    "        out_dir=plots_dir\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7e69bd05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Circular Base + Shielding ===\n",
      "[INFO] Per-class CSVs exist → reloading Shielding from CSV…\n",
      "[Batch 1] Shielding successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 2 — Circular Base + Shielding ===\n",
      "[INFO] Per-class CSVs exist → reloading Shielding from CSV…\n",
      "[Batch 2] Shielding successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 3 — Circular Base + Shielding ===\n",
      "[INFO] Per-class CSVs exist → reloading Shielding from CSV…\n",
      "[Batch 3] Shielding successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 4 — Circular Base + Shielding ===\n",
      "[INFO] Per-class CSVs exist → reloading Shielding from CSV…\n",
      "[Batch 4] Shielding successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 5 — Circular Base + Shielding ===\n",
      "[INFO] Per-class CSVs exist → reloading Shielding from CSV…\n",
      "[Batch 5] Shielding successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 6 — Circular Base + Shielding ===\n",
      "[INFO] Per-class CSVs exist → reloading Shielding from CSV…\n",
      "[Batch 6] Shielding successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 7 — Circular Base + Shielding ===\n",
      "[INFO] Per-class CSVs exist → reloading Shielding from CSV…\n",
      "[Batch 7] Shielding successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: CALCULATION OR LOADING OF DOSE RATE (Circular Base + Shielding)\n",
    "# ===============================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Circular Base + Shielding ===\")\n",
    "\n",
    "    # 1) Output directory and control volume\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    plots_dir = os.path.join(output_directory, 'dose_rate_plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "    V = V_values[batch_num]\n",
    "\n",
    "    # 2) Reload ACTIVITIES (gamma energies come from JSON)\n",
    "    all_class_activities = {}\n",
    "    for class_num in range(1, 10):\n",
    "        df = pd.read_csv(os.path.join(output_directory, f\"class_{class_num}_activities.csv\"))\n",
    "        isos = df.columns.tolist()[1:]\n",
    "        all_class_activities[class_num] = {iso: df[iso].values for iso in isos}\n",
    "\n",
    "    # 3) Geometrical parameters, material properties, and total accumulator\n",
    "    total_acc_csv = f\"total_accumulated_dose_shield_batch_{batch_num}.csv\"\n",
    "    total_acc_path = os.path.join(plots_dir, total_acc_csv)\n",
    "\n",
    "    total_accumulated_dose_shield = np.zeros(len(time_steps))\n",
    "    cylinder_radius = 15   # cm\n",
    "    cylinder_height = 80   # cm\n",
    "    R_shield = math.sqrt(2 * cylinder_radius * cylinder_height)\n",
    "    density_polymer = 0.92  # g/cm³\n",
    "    shield_thickness = 3    # cm\n",
    "\n",
    "    def linear_att(E_keV, rho):\n",
    "        \"\"\"Linear attenuation coefficient as μ = μm(E) * ρ\"\"\"\n",
    "        return calc_mu_m(E_keV) * rho\n",
    "\n",
    "    # 4) Check if per-class recalculation is needed\n",
    "    expected = [f\"dose_rate_shield_class_{i}.csv\" for i in range(1, 10)]\n",
    "    need_recalc = not all(fn in os.listdir(plots_dir) for fn in expected)\n",
    "\n",
    "    # ===============================================\n",
    "    # CALCULATE IF MISSING\n",
    "    # ===============================================\n",
    "    if need_recalc:\n",
    "        print(\"[INFO] Missing per-class CSVs → calculating Shielding…\")\n",
    "\n",
    "        for class_num, isotopes in class_inventories.items():\n",
    "            acts = all_class_activities[class_num]\n",
    "            dose_rates_shield = {iso: np.zeros(len(time_steps)) for iso in isotopes}\n",
    "            timestep_dose = np.zeros(len(time_steps))\n",
    "\n",
    "            for i, t in enumerate(time_steps):\n",
    "                for iso in isotopes:\n",
    "                    E = gamma_energies.get(iso, 0.0)\n",
    "                    if E <= 0:\n",
    "                        continue\n",
    "\n",
    "                    A = acts.get(iso, np.zeros(len(time_steps)))[i]\n",
    "                    if A <= 0:\n",
    "                        continue\n",
    "\n",
    "                    mu = mass_att(E)\n",
    "                    sigma = max(1e-4, mass_ab(E))\n",
    "                    if mu == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Compute unshielded flux using circular base geometry\n",
    "                    flux = gamma_flux_circular_base(A, R_shield, shield_thickness, mass_att, E)\n",
    "                    dr = 5.77e-5 * flux * E * sigma\n",
    "\n",
    "                    # Apply exponential attenuation through the shield\n",
    "                    dr_sh = dr * np.exp(-linear_att(E * 1000, density_polymer) * shield_thickness)\n",
    "\n",
    "                    if np.isnan(dr_sh):\n",
    "                        continue\n",
    "\n",
    "                    dose_rates_shield[iso][i] = dr_sh\n",
    "                    timestep_dose[i] += dr_sh / 3600.0  # convert to rads/h\n",
    "\n",
    "            # Accumulate per class\n",
    "            acc = np.cumsum(timestep_dose)\n",
    "            total_accumulated_dose_shield += acc\n",
    "\n",
    "            # Save per-class CSV\n",
    "            out_csv = os.path.join(plots_dir, f\"dose_rate_shield_class_{class_num}.csv\")\n",
    "            with open(out_csv, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\"] + list(dose_rates_shield.keys()))\n",
    "                for j, t in enumerate(time_steps):\n",
    "                    w.writerow([t] + [dose_rates_shield[iso][j] for iso in isotopes])\n",
    "\n",
    "            # Plot per-class dose rates\n",
    "            plot_dose_rates(\n",
    "                dose_rates_shield,\n",
    "                f\"Dose Rates (Shielding) - Class {class_num}\",\n",
    "                f\"dose_rate_shield_class_{class_num}.png\",\n",
    "                out_dir=plots_dir\n",
    "            )\n",
    "            print(f\"  Class {class_num} → final accumulated dose: {acc[-1]:.2f} rads\")\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Shielding calculated.\")\n",
    "\n",
    "    # ===============================================\n",
    "    # IF EXISTS, JUST RELOAD\n",
    "    # ===============================================\n",
    "    else:\n",
    "        print(\"[INFO] Per-class CSVs exist → reloading Shielding from CSV…\")\n",
    "\n",
    "        for class_num in range(1, 10):\n",
    "            df = pd.read_csv(os.path.join(plots_dir, f\"dose_rate_shield_class_{class_num}.csv\"))\n",
    "            isos = df.columns.tolist()[1:]\n",
    "            drs = {iso: df[iso].values for iso in isos}\n",
    "\n",
    "            # Accumulate\n",
    "            step = np.array([sum(drs[iso][i] for iso in isos) / 3600.0 for i in range(len(time_steps))])\n",
    "            total_accumulated_dose_shield += np.cumsum(step)\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Shielding successfully reloaded.\")\n",
    "\n",
    "    # ===============================================\n",
    "    # SAVE OR RELOAD TOTAL ACCUMULATED DOSE\n",
    "    # ===============================================\n",
    "    if not os.path.exists(total_acc_path):\n",
    "        print(\"[INFO] Missing total accumulated CSV → generating it now…\")\n",
    "        with open(total_acc_path, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "            for tt, val in zip(time_steps, total_accumulated_dose_shield):\n",
    "                w.writerow([tt, val])\n",
    "    else:\n",
    "        print(\"[INFO] Total accumulated CSV already exists → reloading…\")\n",
    "        df_tot = pd.read_csv(total_acc_path)\n",
    "        total_accumulated_dose_shield = df_tot[\"Accumulated_Dose (rads)\"].values\n",
    "\n",
    "    # ===============================================\n",
    "    # PLOT TOTAL ACCUMULATED DOSE\n",
    "    # ===============================================\n",
    "    plot_accumulated_dose(\n",
    "        total_accumulated_dose_shield,\n",
    "        f\"Total Accumulated Dose (Shielding) - Batch {batch_num}\",\n",
    "        f\"total_accumulated_dose_shield_batch_{batch_num}.png\",\n",
    "        out_dir=plots_dir\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35dff103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Point Source Method ===\n",
      "[INFO] Per-class CSVs already exist → reloading Point Source from CSV…\n",
      "[Batch 1] Point Source successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 2 — Point Source Method ===\n",
      "[INFO] Per-class CSVs already exist → reloading Point Source from CSV…\n",
      "[Batch 2] Point Source successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 3 — Point Source Method ===\n",
      "[INFO] Per-class CSVs already exist → reloading Point Source from CSV…\n",
      "[Batch 3] Point Source successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 4 — Point Source Method ===\n",
      "[INFO] Per-class CSVs already exist → reloading Point Source from CSV…\n",
      "[Batch 4] Point Source successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 5 — Point Source Method ===\n",
      "[INFO] Per-class CSVs already exist → reloading Point Source from CSV…\n",
      "[Batch 5] Point Source successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 6 — Point Source Method ===\n",
      "[INFO] Per-class CSVs already exist → reloading Point Source from CSV…\n",
      "[Batch 6] Point Source successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n",
      "\n",
      "=== Batch 7 — Point Source Method ===\n",
      "[INFO] Per-class CSVs already exist → reloading Point Source from CSV…\n",
      "[Batch 7] Point Source successfully reloaded.\n",
      "[INFO] Total accumulated CSV already exists → reloading…\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: CALCULATION OR LOADING OF DOSE RATE (Point Source Method)\n",
    "# ===============================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Point Source Method ===\")\n",
    "\n",
    "    # 1) Output directory and plots\n",
    "    output_directory = f\"output_batch_{batch_num}\"\n",
    "    plots_dir = os.path.join(output_directory, 'dose_rate_plots')\n",
    "    os.makedirs(plots_dir, exist_ok=True)\n",
    "\n",
    "    # 2) Reload ACTIVITIES\n",
    "    all_class_activities = {}\n",
    "    for class_num in range(1, 10):\n",
    "        df_act = pd.read_csv(os.path.join(output_directory, f\"class_{class_num}_activities.csv\"))\n",
    "        isos = df_act.columns.tolist()[1:]  # skip time column\n",
    "        all_class_activities[class_num] = {iso: df_act[iso].values for iso in isos}\n",
    "\n",
    "    # 3) Parameters and total accumulator\n",
    "    total_acc_csv = f\"total_accumulated_dose_point_batch_{batch_num}.csv\"\n",
    "    total_acc_path = os.path.join(plots_dir, total_acc_csv)\n",
    "    accumulated_dose_point = np.zeros(len(time_steps))\n",
    "    h_point = 25  # cm (distance from source to receptor)\n",
    "    density = 0.001  # g/cm³ (air density)\n",
    "\n",
    "    def gamma_flux_point_source(activity, h, mass_att_func, E):\n",
    "        \"\"\"Gamma flux for a point source with attenuation (μ * ρ * h).\"\"\"\n",
    "        mu = mass_att_func(E)\n",
    "        if mu <= 0:\n",
    "            return 0.0\n",
    "        # 3.7e10 converts Ci → disintegrations/s if activity is in Ci\n",
    "        return (3.7e10 * activity) / (4 * math.pi * h**2) * math.exp(-mu * density * h)\n",
    "\n",
    "    # 4) Check for per-class CSVs\n",
    "    expected = [f\"dose_rate_point_source_class_{i}.csv\" for i in range(1, 10)]\n",
    "    need_recalc = not all(fn in os.listdir(plots_dir) for fn in expected)\n",
    "\n",
    "    # ===============================================\n",
    "    # CALCULATE IF MISSING\n",
    "    # ===============================================\n",
    "    if need_recalc:\n",
    "        print(\"[INFO] Missing per-class CSVs → calculating Point Source…\")\n",
    "\n",
    "        for class_num, isotopes in class_inventories.items():\n",
    "            # Extract isotope names if dict\n",
    "            iso_names = list(isotopes.keys()) if isinstance(isotopes, dict) else list(isotopes)\n",
    "            acts = all_class_activities[class_num]  # dict: iso -> activity array\n",
    "\n",
    "            dose_rates_point = {iso: np.zeros(len(time_steps)) for iso in iso_names}\n",
    "            timestep_dose = np.zeros(len(time_steps))  # sum at each timestep\n",
    "\n",
    "            for i, t in enumerate(time_steps):\n",
    "                for iso in iso_names:\n",
    "                    E = gamma_energies.get(iso, 0.0)\n",
    "                    if E <= 0:\n",
    "                        continue\n",
    "\n",
    "                    A = acts.get(iso, np.zeros(len(time_steps)))[i]\n",
    "                    if A <= 0:\n",
    "                        continue\n",
    "\n",
    "                    sigma = max(1e-4, mass_ab(E))  # effective absorption coefficient\n",
    "                    flux = gamma_flux_point_source(A, h_point, mass_att, E)\n",
    "                    dr = 5.77e-5 * flux * E * sigma  # MeV → rads/s conversion\n",
    "\n",
    "                    if np.isnan(dr):\n",
    "                        continue\n",
    "\n",
    "                    dose_rates_point[iso][i] = dr\n",
    "                    timestep_dose[i] += dr / 3600.0  # convert to rads/h\n",
    "\n",
    "            # Accumulate over time\n",
    "            acc = np.cumsum(timestep_dose)\n",
    "            accumulated_dose_point += acc\n",
    "\n",
    "            # Save per-class CSV\n",
    "            out_csv = os.path.join(plots_dir, f\"dose_rate_point_source_class_{class_num}.csv\")\n",
    "            with open(out_csv, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\"] + iso_names)\n",
    "                for j, t in enumerate(time_steps):\n",
    "                    w.writerow([t] + [dose_rates_point[iso][j] for iso in iso_names])\n",
    "\n",
    "            # Plot per-class dose rates\n",
    "            plot_dose_rates(\n",
    "                dose_rates_point,\n",
    "                f\"Dose Rates (Point Source) - Class {class_num}\",\n",
    "                f\"dose_rate_point_source_class_{class_num}.png\",\n",
    "                out_dir=plots_dir\n",
    "            )\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Point Source dose rates calculated.\")\n",
    "\n",
    "    # ===============================================\n",
    "    # IF EXISTS, JUST RELOAD\n",
    "    # ===============================================\n",
    "    else:\n",
    "        print(\"[INFO] Per-class CSVs already exist → reloading Point Source from CSV…\")\n",
    "\n",
    "        for class_num in range(1, 10):\n",
    "            df_ps = pd.read_csv(os.path.join(plots_dir, f\"dose_rate_point_source_class_{class_num}.csv\"))\n",
    "            isos = df_ps.columns.tolist()[1:]\n",
    "            drs = {iso: df_ps[iso].values for iso in isos}\n",
    "\n",
    "            steps = np.array([sum(drs[iso][i] for iso in isos) / 3600.0 for i in range(len(time_steps))])\n",
    "            accumulated_dose_point += np.cumsum(steps)\n",
    "\n",
    "        print(f\"[Batch {batch_num}] Point Source successfully reloaded.\")\n",
    "\n",
    "    # ===============================================\n",
    "    # SAVE OR RELOAD TOTAL ACCUMULATED DOSE\n",
    "    # ===============================================\n",
    "    if not os.path.exists(total_acc_path):\n",
    "        print(\"[INFO] Missing total accumulated CSV → generating it now…\")\n",
    "        with open(total_acc_path, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "            for tt, val in zip(time_steps, accumulated_dose_point):\n",
    "                w.writerow([tt, val])\n",
    "    else:\n",
    "        print(\"[INFO] Total accumulated CSV already exists → reloading…\")\n",
    "        df_tot = pd.read_csv(total_acc_path)\n",
    "        accumulated_dose_point = df_tot[\"Accumulated_Dose (rads)\"].values\n",
    "\n",
    "    # ===============================================\n",
    "    # PLOT TOTAL ACCUMULATED DOSE\n",
    "    # ===============================================\n",
    "    plot_accumulated_dose(\n",
    "        accumulated_dose_point,\n",
    "        f\"Total Accumulated Dose (Point Source) - Batch {batch_num}\",\n",
    "        f\"total_accumulated_dose_point_source_batch_{batch_num}.png\",\n",
    "        out_dir=plots_dir\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6da5905f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 20300.53\n",
      "[With Shield] Final Level = 5 | Max Ratio = 794500.29\n",
      "[Sphere] Final Level = 5 | Max Ratio = 356.50\n",
      "→ Copied Sphere CSV for Batch 1 to current directory as 'sphere_damage_levels_1.csv'\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 63971.40\n",
      "[Batch 1] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 2 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 16039.55\n",
      "[With Shield] Final Level = 5 | Max Ratio = 628956.71\n",
      "[Sphere] Final Level = 5 | Max Ratio = 311.85\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 50631.38\n",
      "[Batch 2] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 3 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 5394.32\n",
      "[With Shield] Final Level = 5 | Max Ratio = 210613.35\n",
      "[Sphere] Final Level = 5 | Max Ratio = 37.83\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 16962.23\n",
      "[Batch 3] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 4 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 219702.19\n",
      "[With Shield] Final Level = 5 | Max Ratio = 8478329.74\n",
      "[Sphere] Final Level = 5 | Max Ratio = 297.11\n",
      "→ Copied Sphere CSV for Batch 4 to current directory as 'sphere_damage_levels_4.csv'\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 681925.13\n",
      "[Batch 4] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 5 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 1 | Max Ratio = 0.00\n",
      "[With Shield] Final Level = 1 | Max Ratio = 0.00\n",
      "[Sphere] Final Level = 1 | Max Ratio = 0.00\n",
      "→ Copied Sphere CSV for Batch 5 to current directory as 'sphere_damage_levels_5.csv'\n",
      "[Circular Base] Final Level = 1 | Max Ratio = 0.00\n",
      "[Batch 5] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 6 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 548085.55\n",
      "[With Shield] Final Level = 5 | Max Ratio = 20489102.00\n",
      "[Sphere] Final Level = 1 | Max Ratio = 0.01\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 1645688.48\n",
      "[Batch 6] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 7 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 84519.02\n",
      "[With Shield] Final Level = 5 | Max Ratio = 3287083.90\n",
      "[Sphere] Final Level = 5 | Max Ratio = 113.87\n",
      "→ Copied Sphere CSV for Batch 7 to current directory as 'sphere_damage_levels_7.csv'\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 264584.61\n",
      "[Batch 7] Damage Levels generated! ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: DAMAGE LEVELS (time-resolved calculation)\n",
    "# ===============================================\n",
    "\n",
    "eq_data = [\n",
    "    (3600,    4e6),    # 1 hour\n",
    "    (43200,   2e7),    # 12 hours\n",
    "    (86400,   2.4e7),  # 1 day\n",
    "    (864000,  4e7),    # 10 days\n",
    "    (2592000, 5.5e7),  # 1 month\n",
    "    (15552000,1.1e8),  # 6 months\n",
    "    (31536000,1.5e8)   # 1 year\n",
    "]\n",
    "\n",
    "def level_from_ratio(r):\n",
    "    if r < 1:\n",
    "        return 1\n",
    "    elif r < 4:\n",
    "        return 2\n",
    "    elif r < 7:\n",
    "        return 3\n",
    "    elif r < 10:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "def calculate_damage_level(acc_dose, EQ, current_level):\n",
    "    ratio = acc_dose / EQ if EQ > 0 else float('inf')\n",
    "    lvl = level_from_ratio(ratio)\n",
    "    return lvl, ratio, lvl\n",
    "\n",
    "# ===============================================\n",
    "# MAIN LOOP\n",
    "# ===============================================\n",
    "for batch_num in range(1, len(batches) + 1):\n",
    "    print(f\"\\n=== Batch {batch_num} — Damage Levels (time-resolved) ===\")\n",
    "\n",
    "    out_levels_dir = f\"damage_levels_{batch_num}\"\n",
    "    csv_levels_dir = os.path.join(out_levels_dir, \"csv_data\")\n",
    "    os.makedirs(csv_levels_dir, exist_ok=True)\n",
    "\n",
    "    max_t = time_steps.max()\n",
    "    segments = [(t, EQ) for t, EQ in eq_data if t <= max_t]\n",
    "\n",
    "    dose_methods = {\n",
    "        \"Point Source\":      \"dose_rate_point_source_class_\",\n",
    "        \"With Shield\":       \"dose_rate_shield_class_\",\n",
    "        \"Sphere\":            \"dose_rate_sphere_class_\",\n",
    "        \"Circular Base\":     \"dose_rate_circular_base_class_\",\n",
    "    }\n",
    "    accumulated = {}\n",
    "\n",
    "    # ===============================================\n",
    "    # LOAD OR GENERATE TOTAL ACCUMULATED DOSES\n",
    "    # ===============================================\n",
    "    for label, prefix in dose_methods.items():\n",
    "        plots_dir = os.path.join(f\"output_batch_{batch_num}\", \"dose_rate_plots\")\n",
    "        total_csv = os.path.join(plots_dir, f\"total_accumulated_{label.replace(' ', '_')}.csv\")\n",
    "\n",
    "        if os.path.exists(total_csv):\n",
    "            data = np.loadtxt(total_csv, delimiter=',', skiprows=1, usecols=1)\n",
    "            accumulated[label] = data\n",
    "        else:\n",
    "            cum_sum = np.zeros(len(time_steps))\n",
    "            for class_num in range(1, 10):\n",
    "                file_i = os.path.join(plots_dir, f\"{prefix}{class_num}.csv\")\n",
    "                if not os.path.exists(file_i):\n",
    "                    raise FileNotFoundError(f\"Missing {file_i}\")\n",
    "                arr = np.loadtxt(file_i, delimiter=',', skiprows=1)[:, 1:]\n",
    "                step = arr.sum(axis=1) / 3600.0\n",
    "                cum = np.cumsum(step)\n",
    "                cum_sum += cum\n",
    "            with open(total_csv, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "                for t, val in zip(time_steps, cum_sum):\n",
    "                    w.writerow([t, val])\n",
    "            accumulated[label] = cum_sum\n",
    "\n",
    "    # ===============================================\n",
    "    # CALCULATE TIME-RESOLVED DAMAGE LEVELS\n",
    "    # ===============================================\n",
    "    for label, dose_arr in accumulated.items():\n",
    "        key = label.replace(' ', '_').lower()\n",
    "        csv_out = os.path.join(csv_levels_dir, f\"{key}_dose_data.csv\")\n",
    "        damage_csv_out = os.path.join(csv_levels_dir, f\"{key}_damage_levels.csv\")\n",
    "        png_out = os.path.join(out_levels_dir, f\"damage_level_{key}.png\")\n",
    "\n",
    "        # --- Save accumulated dose data if not existing ---\n",
    "        if not os.path.exists(csv_out):\n",
    "            with open(csv_out, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time Step (s)\", \"Accumulated Dose (rads)\"])\n",
    "                for t, val in zip(time_steps, dose_arr):\n",
    "                    w.writerow([t, val])\n",
    "\n",
    "        # --- Initialize arrays ---\n",
    "        damage_levels_over_time = np.zeros(len(time_steps), dtype=int)\n",
    "        ratios_over_time = np.zeros(len(time_steps))\n",
    "        EQ_used_over_time = np.zeros(len(time_steps))\n",
    "\n",
    "        current_level = 1\n",
    "        segment_idx = 0\n",
    "\n",
    "        # --- Compute for each timestep ---\n",
    "        for i, t in enumerate(time_steps):\n",
    "            # If time exceeds the next segment boundary, move to next EQ\n",
    "            while segment_idx + 1 < len(segments) and t >= segments[segment_idx + 1][0]:\n",
    "                segment_idx += 1\n",
    "\n",
    "            EQ = segments[segment_idx][1]\n",
    "            EQ_used_over_time[i] = EQ\n",
    "            acc_dose = dose_arr[i]\n",
    "\n",
    "            level, ratio, _ = calculate_damage_level(acc_dose, EQ, current_level)\n",
    "            current_level = level\n",
    "            damage_levels_over_time[i] = level\n",
    "            ratios_over_time[i] = ratio\n",
    "\n",
    "        # --- Save detailed CSV ---\n",
    "        with open(damage_csv_out, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Time (s)\", \"Accumulated Dose (rads)\", \"EQ (rads)\", \"Ratio\", \"Damage Level\"])\n",
    "            for t, dose, EQ, ratio, lvl in zip(time_steps, dose_arr, EQ_used_over_time, ratios_over_time, damage_levels_over_time):\n",
    "                w.writerow([t, dose, EQ, ratio, lvl])\n",
    "\n",
    "        # --- Plot appearance preserved ---\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        x_hours = time_steps / 3600.0\n",
    "        plt.plot(x_hours, damage_levels_over_time, drawstyle='steps-post', linewidth=2.5, marker='o', markersize=4)\n",
    "        plt.title(f\"Damage Levels — {label} (Batch {batch_num})\")\n",
    "        plt.xlabel(\"Time (hours)\")\n",
    "        plt.ylabel(\"Damage Level (1–5)\")\n",
    "        plt.ylim(1, 6)\n",
    "        plt.yticks([1, 2, 3, 4, 5])\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(png_out)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"[{label}] Final Level = {damage_levels_over_time[-1]} | Max Ratio = {ratios_over_time.max():.2f}\")\n",
    "\n",
    "        # ============================================================\n",
    "        # ADDITION: COPY SPHERE DAMAGE LEVELS CSVs TO CURRENT FOLDER\n",
    "        # ============================================================\n",
    "        if label == \"Sphere\" and batch_num in [1, 4, 5, 7]:\n",
    "            dest_filename = f\"sphere_damage_levels_{batch_num}.csv\"\n",
    "            dest_path = os.path.join(os.getcwd(), dest_filename)\n",
    "            try:\n",
    "                import shutil\n",
    "                shutil.copyfile(damage_csv_out, dest_path)\n",
    "                print(f\"→ Copied Sphere CSV for Batch {batch_num} to current directory as '{dest_filename}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Could not copy Sphere CSV for Batch {batch_num}: {e}\")\n",
    "\n",
    "    print(f\"[Batch {batch_num}] Damage Levels generated! ✅\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7adf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 1) Import the level CSV files\n",
    "# ============================\n",
    "df1 = pd.read_csv(\"sphere_damage_levels_1.csv\")\n",
    "df4 = pd.read_csv(\"sphere_damage_levels_4.csv\")\n",
    "df5 = pd.read_csv(\"sphere_damage_levels_5.csv\")\n",
    "df7 = pd.read_csv(\"sphere_damage_levels_7.csv\")\n",
    "\n",
    "# ===================================\n",
    "# 2) Instrumentation to location definition\n",
    "# ===================================\n",
    "instrumentation_by_location = {\n",
    "    \"WETWELL\": [\"Suppression Pool Thermocouples\"],\n",
    "    \"DRYWELL\": [\n",
    "        \"SRV Position Indicators\",\n",
    "        \"Radiation Detectors in Containment\",\n",
    "        \"Boron Injection Pressure Transmitters\",\n",
    "        \"Boron Tank Level Transmitter\",\n",
    "        \"Drywell Pressure Transmitters\",\n",
    "        \"Containment Pressure Transmitters\",\n",
    "        \"Containment Thermocouples\",\n",
    "        \"Vessel Level (Wide Range)\",\n",
    "        \"Vessel Level (Fuel Range)\",\n",
    "        \"Vessel Pressure Transmitters\",\n",
    "        \"Feedwater Flow Transmitters\",\n",
    "        \"Drywell Thermocouples\",\n",
    "        \"Radiation Detectors in Drywell\",\n",
    "        \"Control Rods Position\",\n",
    "    ],\n",
    "    \"LOWER_HEAD\": [\"Vessel Thermocouples (Lower Head)\", \"FW Thermocouples\"],\n",
    "    \"DOME\": [\"Vessel Thermocouples (Upper Head)\"],\n",
    "    \"RECIRCULATION_PUMPS\": [\n",
    "        \"Suction Pipes Thermocouples\",\n",
    "        \"Recirculation Flow Transmitters\",\n",
    "        \"Recirculation Pressure Transmitters\",\n",
    "    ],\n",
    "    \"ANNULUS\": [\"Average Reactor Power Monitors\"],\n",
    "    \"AUXILIARY_BUILDING\": [\n",
    "        \"Containment Hydrogen Concentration Analyzer\",\n",
    "        \"Drywell Hydrogen Concentration Analyzer\",\n",
    "        \"Feedwater Pressure Transmitters\",\n",
    "        \"HPCS Flow Transmitter\",\n",
    "        \"Suppression Pool Level Transmitters\",\n",
    "    ],\n",
    "    \"FUEL_BUILDING\": [],\n",
    "}\n",
    "\n",
    "# =================================\n",
    "# 3) Link the location to level CSV files\n",
    "# =================================\n",
    "level_map = {\n",
    "    \"WETWELL\": 4,\n",
    "    \"DRYWELL\": 7,\n",
    "    \"LOWER_HEAD\": 1,\n",
    "    \"DOME\": 1,\n",
    "    \"RECIRCULATION_PUMPS\": 1,\n",
    "    \"ANNULUS\": 1,\n",
    "    \"AUXILIARY_BUILDING\": 5,\n",
    "    \"FUEL_BUILDING\": 5,\n",
    "}\n",
    "\n",
    "# ==============================\n",
    "# 4) CSV to dict conversion\n",
    "# ==============================\n",
    "level_df_map = {\n",
    "    1: df1.to_dict(orient=\"records\"),\n",
    "    4: df4.to_dict(orient=\"records\"),\n",
    "    5: df5.to_dict(orient=\"records\"),\n",
    "    7: df7.to_dict(orient=\"records\"),\n",
    "}\n",
    "\n",
    "# ===================================================\n",
    "# 5) Link instrument with damage level\n",
    "# ===================================================\n",
    "damage_by_instrument = {}\n",
    "for location, instruments in instrumentation_by_location.items():\n",
    "    level = level_map[location]\n",
    "    damage_data = level_df_map[level]\n",
    "    for instr in instruments:\n",
    "        damage_by_instrument[instr] = damage_data\n",
    "\n",
    "# =========================================================\n",
    "# 6) Actions and Guides\n",
    "# =========================================================\n",
    "actions_library = {\n",
    "    \"G1_BREACH_IN_VESSEL\": {\n",
    "        \"TEMPERATURE DRYWELL\": [\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"PRESSURE DRYWELL\": [\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitters\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\",\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G2_BORON_INJECTION\": {\n",
    "        \"LEVEL BORON TANK\": [\n",
    "            \"Boron Tank Level Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"G3_SPRAY\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G4_VENTING\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "    },\n",
    "    \"G5_INJECTION_RPV\": {\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"G6_INJECTION_RPV\": {\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"G7_INJECTION_PC_UP_TO_TAF\": {\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"PRESSURE SP\": [\n",
    "            \"Suppression Pool Thermocouples\",\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitters\"\n",
    "        ]\n",
    "    },\n",
    "    \"G9_SUPPORT_VENTING_VESSEL\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G10_EVIDENCES_LOCA\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE DRYWELL\": [\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitters\"\n",
    "        ],\n",
    "        \"SUPPRESSION POOL TEMPERATURE\": [\n",
    "            \"Suppression Pool Thermocouples\",\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G12_FLOOD_RPV_UP_TO_TAF\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"SRV POSITION\": [\"SRV Position Indicators\"],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ]\n",
    "    },\n",
    "    \"G13_SUPPORT_VENTING_RPV\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"SRV POSITION\": [\"SRV Position Indicators\"],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G14_DETERMINE_INVESSEL_RETENTION\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GP\": {\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"SRV POSITION\": [\"SRV Position Indicators\"],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"PRESSURE DRYWELL\": [\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitters\"\n",
    "        ]\n",
    "    },\n",
    "    \"GQ\": {\n",
    "        \"REACTOR POWER\": [\n",
    "            \"Average Reactor Power Monitors\",\n",
    "            \"Control Rods Position\"\n",
    "        ]\n",
    "    },\n",
    "    \"GT/D\": {\n",
    "        \"TEMPERATURE DRYWELL\": [\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GT/PC\": {\n",
    "        \"TEMPERATURE CONTAINMENT\": [\n",
    "            \"Containment Thermocouples\",\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GT/SP\": {\n",
    "        \"TEMPERATURE SUPPRESSION POOL\": [\n",
    "            \"Suppression Pool Thermocouples\",\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GH/PC\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitter (Auxiliary Building)\",\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitter (Auxiliary Building)\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"GR/PC\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitter (Auxiliary Building)\",\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitter (Auxiliary Building)\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ]\n",
    "    },\n",
    "    \"GL/SP\": {\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "actions_short = { k.split(\"_\")[0]: v for k,v in actions_library.items() }\n",
    "\n",
    "\n",
    "# SAMG1 and SAMG2\n",
    "SAMG1 = {\n",
    "    \"RC_F1\": [\"G1\", \"G3\", \"G4\", \"G5\", \"G6\", \"G7\"],\n",
    "    \"RC_F2\": [\"G12\", \"G3\", \"G4\", \"G7\", \"G9\", \"G13\"],\n",
    "    \"RC_F3\": [\"G3\", \"G4\", \"G12\"],\n",
    "    \"RC_F4\": [\"G14\", \"G3\", \"G4\", \"G6\"],\n",
    "    \"RC_F5\": [\"G3\", \"G4\", \"G5\", \"G7\", \"G14\"],\n",
    "    \"RC_Q\": [\"G1\", \"G2\", \"GQ\"],\n",
    "    \"RC_P\": [\"GP\"],\n",
    "}\n",
    "\n",
    "SAMG2 = {\n",
    "    \"DW_T\": [\"GT/D\"],\n",
    "    \"CN_T\": [\"GT/PC\"],\n",
    "    \"SP_T\": [\"GT/SP\"],\n",
    "    \"PC_P\": [\"G4\"],\n",
    "    \"PC_H\": [\"GH/PC\"],\n",
    "    \"PC_R\": [\"GR/PC\"],\n",
    "    \"SP_L\": [\"GL/SP\"],\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 7) Utilities functions\n",
    "# =========================================================\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def _detect_interval_key(sample_records):\n",
    "    if not sample_records:\n",
    "        return \"Interval\"\n",
    "    keys = list(sample_records[0].keys())\n",
    "    lowmap = {k.lower(): k for k in keys}\n",
    "    for cand in [\"intervalo\", \"interval\"]:\n",
    "        if cand in lowmap:\n",
    "            return lowmap[cand]\n",
    "    for k in keys:\n",
    "        if \"interval\" in k.lower():\n",
    "            return k\n",
    "    return keys[0]\n",
    "\n",
    "def _detect_level_key(sample_records):\n",
    "    if not sample_records:\n",
    "        return \"Damage Level\"\n",
    "    keys = list(sample_records[0].keys())\n",
    "    lowmap = {k.lower(): k for k in keys}\n",
    "    for cand in [\"nivel de daño\", \"nivel_de_daño\", \"damage level\", \"damage_level\", \"damage\"]:\n",
    "        if cand in lowmap:\n",
    "            return lowmap[cand]\n",
    "    for k in keys:\n",
    "        kl = k.lower()\n",
    "        if \"damage\" in kl or \"daño\" in kl:\n",
    "            return k\n",
    "    return keys[-1]\n",
    "\n",
    "# =========================================================\n",
    "# 8) Functions to build dataframes and states\n",
    "# =========================================================\n",
    "def _levels_dataframe_for_measure(instrs, damage_by_instrument, fallback_df_records):\n",
    "    sample = next((damage_by_instrument[i] for i in instrs if i in damage_by_instrument), fallback_df_records)\n",
    "    interval_key = _detect_interval_key(sample)\n",
    "    level_key = _detect_level_key(sample)\n",
    "    intervals = [r[interval_key] for r in sample]\n",
    "    data = {interval_key: intervals}\n",
    "    for instr in instrs:\n",
    "        recs = damage_by_instrument.get(instr)\n",
    "        if not recs:\n",
    "            data[instr] = [1] * len(intervals)\n",
    "            continue\n",
    "        vals_raw = [rec.get(level_key, None) for rec in recs]\n",
    "        vals = [int(v) if v is not None and str(v).strip() != \"\" else 1 for v in vals_raw]\n",
    "        if len(vals) < len(intervals):\n",
    "            vals += [vals[-1] if vals else 1] * (len(intervals) - len(vals))\n",
    "        elif len(vals) > len(intervals):\n",
    "            vals = vals[:len(intervals)]\n",
    "        data[instr] = vals\n",
    "    df = pd.DataFrame(data)\n",
    "    return interval_key, level_key, intervals, df\n",
    "\n",
    "def _availability_dataframe_for_measure(instrs, damage_by_instrument, fallback_df_records):\n",
    "    sample = next((damage_by_instrument[i] for i in instrs if i in damage_by_instrument), fallback_df_records)\n",
    "    interval_key = _detect_interval_key(sample)\n",
    "    level_key = _detect_level_key(sample)\n",
    "    intervals = [r[interval_key] for r in sample]\n",
    "    all_levels = []\n",
    "    for instr in instrs:\n",
    "        recs = damage_by_instrument.get(instr)\n",
    "        if not recs:\n",
    "            all_levels.append([1] * len(intervals))\n",
    "        else:\n",
    "            vals_raw = [rec.get(level_key, None) for rec in recs]\n",
    "            vals = [int(v) if v is not None and str(v).strip() != \"\" else 1 for v in vals_raw]\n",
    "            if len(vals) < len(intervals):\n",
    "                vals += [vals[-1] if vals else 1] * (len(intervals) - len(vals))\n",
    "            elif len(vals) > len(intervals):\n",
    "                vals = vals[:len(intervals)]\n",
    "            all_levels.append(vals)\n",
    "    states, codes = [], []\n",
    "    for i in range(len(intervals)):\n",
    "        lvls_t = [levels[i] for levels in all_levels] if all_levels else []\n",
    "        st = _classify_state_from_levels(lvls_t)\n",
    "        states.append(st)\n",
    "        codes.append(state_map[st])\n",
    "    df = pd.DataFrame({interval_key: intervals, \"state\": states, \"state_code\": codes})\n",
    "    return interval_key, intervals, df\n",
    "\n",
    "# =========================================================\n",
    "# 9) Plotting functions\n",
    "# =========================================================\n",
    "def plot_damage(instruments, damage_by_instrument, save_path, title):\n",
    "    # Tomamos una muestra para detectar claves\n",
    "    sample = next((damage_by_instrument[i] for i in instruments if i in damage_by_instrument), None)\n",
    "    if not sample:\n",
    "        return\n",
    "\n",
    "    interval_key = _detect_interval_key(sample)   # aquí detectará \"Time (s)\"\n",
    "    level_key    = _detect_level_key(sample)      # aquí detectará \"Damage Level\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7), dpi=120)\n",
    "    fig.patch.set_facecolor(\"#001F3F\")\n",
    "    ax.set_facecolor(\"#001F3F\")\n",
    "\n",
    "    # Paleta sencilla y sin marcadores (muchos puntos → carísimo)\n",
    "    colors = plt.cm.tab10.colors\n",
    "\n",
    "    for idx, instr in enumerate(instruments):\n",
    "        recs = damage_by_instrument.get(instr)\n",
    "        if not recs:\n",
    "            continue\n",
    "\n",
    "        # x = tiempo real; y = nivel de daño (1..5)\n",
    "        x = np.asarray([float(r[interval_key]) for r in recs])\n",
    "        y = np.asarray([int(r.get(level_key, 1)) for r in recs], dtype=int)\n",
    "\n",
    "        # Decimado automático si hay demasiados puntos (p. ej. > 3000)\n",
    "        max_points = 3000\n",
    "        n = len(x)\n",
    "        if n > max_points:\n",
    "            step = int(np.ceil(n / max_points))\n",
    "            x = x[::step]\n",
    "            y = y[::step]\n",
    "\n",
    "        ax.plot(\n",
    "            x, y,\n",
    "            linewidth=1.5,\n",
    "            label=instr,\n",
    "            color=colors[idx % len(colors)]\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Time (s)\", color=\"white\", fontsize=14)\n",
    "    ax.set_ylabel(\"Damage Level\", color=\"white\", fontsize=14)\n",
    "    ax.set_yticks([1, 2, 3, 4, 5])\n",
    "    ax.set_yticklabels([1, 2, 3, 4, 5], color=\"white\", fontsize=12)\n",
    "    ax.set_title(title, color=\"white\", fontsize=20, pad=16)\n",
    "\n",
    "    ax.tick_params(colors=\"white\", labelsize=12)\n",
    "    ax.grid(color=\"white\", linestyle=\"--\", alpha=0.2, linewidth=1)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"white\")\n",
    "\n",
    "    # Leyenda compacta\n",
    "    leg = ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.12),\n",
    "                    ncol=min(len(instruments), 3), frameon=False, fontsize=11)\n",
    "    for txt in (leg.get_texts() if leg else []):\n",
    "        txt.set_color(\"white\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 10) Availability functions\n",
    "# =========================================================\n",
    "state_map = {\"Good\": 0, \"Careful\": 1, \"Warning\": 2, \"Blind\": 3}\n",
    "zone_colors = {0: \"#006400\", 1: \"#CCCC00\", 2: \"#FF8C00\", 3: \"#8B0000\"}\n",
    "\n",
    "def plot_availability(measure, intervals, states, save_path):\n",
    "    # Convertimos estados a códigos 0..3\n",
    "    values = np.asarray([state_map[s] for s in states], dtype=int)\n",
    "    x = np.asarray(intervals, dtype=float)  # aquí será \"Time (s)\"\n",
    "\n",
    "    # Decimado automático (mismo criterio)\n",
    "    max_points = 3000\n",
    "    n = len(x)\n",
    "    if n > max_points:\n",
    "        step = int(np.ceil(n / max_points))\n",
    "        x = x[::step]\n",
    "        values = values[::step]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 6), dpi=120)\n",
    "    fig.patch.set_facecolor(\"#001F3F\")\n",
    "    ax.set_facecolor(\"#001F3F\")\n",
    "\n",
    "    # Bandas de fondo por zona\n",
    "    for lvl, col in zone_colors.items():\n",
    "        ax.axhspan(lvl, lvl + 1, color=col, alpha=0.25)\n",
    "\n",
    "    # Línea simple (sin marcadores)\n",
    "    ax.plot(x, values, linewidth=2, color=\"#00CED1\")\n",
    "\n",
    "    ax.set_xlabel(\"Time (s)\", color=\"white\", fontsize=14)\n",
    "    ax.set_ylabel(\"State\", color=\"white\", fontsize=14)\n",
    "    ax.set_yticks(list(state_map.values()))\n",
    "    ax.set_yticklabels(list(state_map.keys()), color=\"white\", fontsize=12)\n",
    "    ax.set_title(f\"{measure} Availability\", color=\"white\", fontsize=20, pad=16)\n",
    "\n",
    "    ax.tick_params(colors=\"white\", labelsize=12)\n",
    "    ax.grid(color=\"white\", linestyle=\"--\", alpha=0.2, linewidth=1)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"white\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _classify_state_from_levels(levels):\n",
    "    if not levels:\n",
    "        return \"Blind\"\n",
    "    lvls = [int(x) for x in levels if x is not None]\n",
    "    if all(l == 1 for l in lvls):\n",
    "        return \"Good\"\n",
    "    if all(l == 5 for l in lvls):\n",
    "        return \"Blind\"\n",
    "    if any(l in (3, 4) for l in lvls):\n",
    "        return \"Warning\"\n",
    "    if any(l == 2 for l in lvls) and all(l <= 2 for l in lvls):\n",
    "        return \"Careful\"\n",
    "    return \"Warning\"\n",
    "\n",
    "# =========================================================\n",
    "# 11) CSV and graphs generators\n",
    "# =========================================================\n",
    "def generate_graphs(samg_name, samg_dict, actions_map, damage_by_instrument):\n",
    "    create_directory(samg_name)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(samg_name, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                base = measure.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                interval_key, level_key, intervals, df_levels = _levels_dataframe_for_measure(\n",
    "                    instrs, damage_by_instrument, df1.to_dict(orient=\"records\")\n",
    "                )\n",
    "                df_levels.to_csv(os.path.join(path_code, base + \".csv\"), index=False, encoding=\"utf-8\")\n",
    "                plot_damage(instrs, damage_by_instrument, os.path.join(path_code, base + \".png\"), measure)\n",
    "\n",
    "def generate_availability(samg_name, samg_dict, actions_map, damage_by_instrument):\n",
    "    base = f\"Availability_{samg_name}\"\n",
    "    create_directory(base)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(base, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                safe = measure.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                interval_key, intervals, df_av = _availability_dataframe_for_measure(\n",
    "                    instrs, damage_by_instrument, df1.to_dict(orient=\"records\")\n",
    "                )\n",
    "                df_av.to_csv(os.path.join(path_code, safe + \"_availability.csv\"), index=False, encoding=\"utf-8\")\n",
    "                plot_availability(measure, intervals, df_av[\"state\"].tolist(), os.path.join(path_code, safe + \"_availability.png\"))\n",
    "\n",
    "# =========================================================\n",
    "# 12) Execution\n",
    "# =========================================================\n",
    "generate_graphs(\"SAMG1_R\", SAMG1, actions_short, damage_by_instrument)\n",
    "generate_graphs(\"SAMG2_R\", SAMG2, actions_short, damage_by_instrument)\n",
    "generate_availability(\"SAMG1_R\", SAMG1, actions_short, damage_by_instrument)\n",
    "generate_availability(\"SAMG2_R\", SAMG2, actions_short, damage_by_instrument)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4efb1eac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardado CSV: csv_niveles\\SuppressionPoolThermocouples_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\SuppressionPoolThermocouples_niveles.png\n",
      "Guardado CSV: csv_niveles\\SRVPositionIndicators_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\SRVPositionIndicators_niveles.png\n",
      "Guardado CSV: csv_niveles\\RadiationDetectorsContainment_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\RadiationDetectorsContainment_niveles.png\n",
      "Guardado CSV: csv_niveles\\BoronInjectionPressureTransmitters_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\BoronInjectionPressureTransmitters_niveles.png\n",
      "Guardado CSV: csv_niveles\\BoronTankLevelTransmitter_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\BoronTankLevelTransmitter_niveles.png\n",
      "Guardado CSV: csv_niveles\\DrywellPressureTransmitters_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\DrywellPressureTransmitters_niveles.png\n",
      "Guardado CSV: csv_niveles\\ContainmentPressureTransmitters_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\ContainmentPressureTransmitters_niveles.png\n",
      "Guardado CSV: csv_niveles\\ContainmentThermocouples_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\ContainmentThermocouples_niveles.png\n",
      "Guardado CSV: csv_niveles\\VesselLevelWideRange_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\VesselLevelWideRange_niveles.png\n",
      "Guardado CSV: csv_niveles\\VesselLevelFuelRange_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\VesselLevelFuelRange_niveles.png\n",
      "Guardado CSV: csv_niveles\\VesselPressureTransmitters_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\VesselPressureTransmitters_niveles.png\n",
      "Guardado CSV: csv_niveles\\FeedwaterFlowTransmitters_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\FeedwaterFlowTransmitters_niveles.png\n",
      "Guardado CSV: csv_niveles\\DrywellThermocouples_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\DrywellThermocouples_niveles.png\n",
      "Guardado CSV: csv_niveles\\RadiationDetectorsDrywell_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\RadiationDetectorsDrywell_niveles.png\n",
      "Guardado CSV: csv_niveles\\ControlRodsPosition_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\ControlRodsPosition_niveles.png\n",
      "Guardado CSV: csv_niveles\\RecirculationPressureTransmitters_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\RecirculationPressureTransmitters_niveles.png\n",
      "Guardado CSV: csv_niveles\\RecirculationFlowTransmitters_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\RecirculationFlowTransmitters_niveles.png\n",
      "Guardado CSV: csv_niveles\\AverageReactorPowerMonitors_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\AverageReactorPowerMonitors_niveles.png\n",
      "Guardado CSV: csv_niveles\\VesselThermocouplesUpperHead_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\VesselThermocouplesUpperHead_niveles.png\n",
      "Guardado CSV: csv_niveles\\VesselThermocouplesLowerHead_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\VesselThermocouplesLowerHead_niveles.png\n",
      "Guardado CSV: csv_niveles\\FWThermocouples_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\FWThermocouples_niveles.png\n",
      "Guardado CSV: csv_niveles\\SuctionPipesThermocouples_niveles.csv\n",
      "Guardada gráfica: graficas_niveles\\SuctionPipesThermocouples_niveles.png\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pypost.codes.melcor import MELCOR\n",
    "\n",
    "file_path_melcor = \"MC_Step.ptf\"   \n",
    "file_index_melcor = MELCOR.openPlotFile(file_path_melcor)\n",
    "\n",
    "def cargar(var_code: str):\n",
    "    data = np.array(MELCOR.getData(file_index_melcor, var_code))\n",
    "    if data.ndim != 2 or data.shape[1] < 2:\n",
    "        raise RuntimeError(f\"Unexpected format for {var_code}: shape={data.shape}\")\n",
    "    return data[:, 0], data[:, 1]\n",
    "\n",
    "# =========================\n",
    "# Import of MELCOR variables\n",
    "# =========================\n",
    "tiempo_s, TempVapor_Wetwell = cargar(\"CVH-TVAP_305\")\n",
    "\n",
    "def cargar_misma_malla(var_code: str):\n",
    "    t, v = cargar(var_code)\n",
    "    if not np.array_equal(tiempo_s, t):\n",
    "        if np.allclose(tiempo_s, t, rtol=0, atol=1e-12):\n",
    "            return v\n",
    "        raise ValueError(f\"La malla de tiempo en {var_code} no coincide con la referencia.\")\n",
    "    return v\n",
    "\n",
    "Presion_Wetwell          = cargar_misma_malla(\"CVH-P_305\")\n",
    "TempVapor_Drywell        = cargar_misma_malla(\"CVH-TVAP_201\")\n",
    "Presion_Drywell          = cargar_misma_malla(\"CVH-P_201\")\n",
    "TempVapor_CabezaSuperior = cargar_misma_malla(\"CVH-TVAP_160\")\n",
    "Presion_CabezaSuperior   = cargar_misma_malla(\"CVH-P_160\")\n",
    "TempVapor_CabezaInferior = cargar_misma_malla(\"CVH-TVAP_120\")\n",
    "Presion_CabezaInferior   = cargar_misma_malla(\"CVH-P_120\")\n",
    "TempVapor_BombaRecir     = cargar_misma_malla(\"CVH-TVAP_106\")\n",
    "Presion_BombaRecir       = cargar_misma_malla(\"CVH-P_106\")\n",
    "\n",
    "# =========================\n",
    "# VARIABLES CONSTANTES\n",
    "# =========================\n",
    "EQ_PRESSURE = 410000   # Pa\n",
    "EQ_TEMP = 422          # K\n",
    "\n",
    "# =========================\n",
    "# CRITERIO DE FALLO DE VASIJA\n",
    "# =========================\n",
    "VESSEL_FAILURE = Presion_BombaRecir < 6_000_000  # Boolean array\n",
    "\n",
    "# =========================\n",
    "# DICCIONARIO PARA USO POSTERIOR\n",
    "# =========================\n",
    "variables_melcor = {\n",
    "    \"tiempo_s\": tiempo_s,\n",
    "    \"TempVapor_Wetwell\":        TempVapor_Wetwell,\n",
    "    \"Presion_Wetwell\":          Presion_Wetwell,\n",
    "    \"TempVapor_Drywell\":        TempVapor_Drywell,\n",
    "    \"Presion_Drywell\":          Presion_Drywell,\n",
    "    \"TempVapor_CabezaSuperior\": TempVapor_CabezaSuperior,\n",
    "    \"Presion_CabezaSuperior\":   Presion_CabezaSuperior,\n",
    "    \"TempVapor_CabezaInferior\": TempVapor_CabezaInferior,\n",
    "    \"Presion_CabezaInferior\":   Presion_CabezaInferior,\n",
    "    \"TempVapor_BombaRecir\":     TempVapor_BombaRecir,\n",
    "    \"Presion_BombaRecir\":       Presion_BombaRecir,\n",
    "    \"EQ_PRESSURE\":              EQ_PRESSURE,\n",
    "    \"EQ_TEMP\":                  EQ_TEMP,\n",
    "    \"VESSEL_FAILURE\":           VESSEL_FAILURE\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# CONTENEDOR: niveles por instrumento\n",
    "# =========================\n",
    "niveles_instrumentos = {}  # { nombre_instrumento: ndarray[int] (niveles 1..5 en cada t) }\n",
    "\n",
    "def guardar_nivel_instrumento(nombre: str, level_array: np.ndarray):\n",
    "    \"\"\"\n",
    "    Guarda la serie de niveles (1..5) a lo largo del tiempo para un instrumento.\n",
    "    \"\"\"\n",
    "    if level_array.shape != tiempo_s.shape:\n",
    "        raise ValueError(f\"Longitud de niveles de '{nombre}' no coincide con tiempo.\")\n",
    "    niveles_instrumentos[nombre] = level_array.astype(int, copy=False)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Suppression Pool Thermocouples (niveles 1–5)\n",
    "# Reglas interpretadas:\n",
    "# 1: 273–422 K (nominal)  [Estado base; no fuerza 1 si hay niveles superiores]\n",
    "# 2: CEC>EQ => T_wet > EQ_TEMP  OR  P_wet > EQ_PRESSURE\n",
    "# 3: T_wet > 673 K\n",
    "# 5: T_wet > 1530 K\n",
    "# (Nivel 4 aún sin criterio)\n",
    "# =========================\n",
    "# HISTÉRESIS TEMPORAL (30 min para bajar de nivel)\n",
    "# =========================\n",
    "def aplicar_histeresis(tiempo, niveles_condiciones, retardo_bajada_s):\n",
    "    \"\"\"\n",
    "    Aplica histéresis temporal a una serie de niveles (1..5).\n",
    "    - Subida inmediata al nivel mayor si se detecta.\n",
    "    - Bajada solo si han pasado retardo_bajada_s desde que se cumplen condiciones de nivel menor.\n",
    "    \"\"\"\n",
    "    niveles_final = np.zeros_like(niveles_condiciones)\n",
    "    niveles_final[0] = niveles_condiciones[0]\n",
    "    tiempo_ultimo_cambio = tiempo[0]\n",
    "\n",
    "    for i in range(1, len(tiempo)):\n",
    "        nivel_actual = niveles_final[i-1]\n",
    "        nivel_cond = niveles_condiciones[i]\n",
    "\n",
    "        if nivel_cond > nivel_actual:\n",
    "            # Subida inmediata\n",
    "            niveles_final[i] = nivel_cond\n",
    "            tiempo_ultimo_cambio = tiempo[i]\n",
    "        elif nivel_cond < nivel_actual:\n",
    "            # Baja solo si ha pasado el retardo\n",
    "            if tiempo[i] - tiempo_ultimo_cambio >= retardo_bajada_s:\n",
    "                niveles_final[i] = nivel_cond\n",
    "                tiempo_ultimo_cambio = tiempo[i]\n",
    "            else:\n",
    "                niveles_final[i] = nivel_actual\n",
    "        else:\n",
    "            # Mismo nivel\n",
    "            niveles_final[i] = nivel_actual\n",
    "\n",
    "    return niveles_final\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Suppression Pool Thermocouples con histéresis\n",
    "# =========================\n",
    "T_wet = TempVapor_Wetwell\n",
    "P_wet = Presion_Wetwell\n",
    "\n",
    "# Niveles por condiciones instantáneas\n",
    "niveles_cond = np.ones_like(tiempo_s, dtype=int)\n",
    "niveles_cond[(T_wet > EQ_TEMP) | (P_wet > EQ_PRESSURE)] = 2\n",
    "niveles_cond[T_wet > 673.0] = 3\n",
    "niveles_cond[T_wet > 1530.0] = 5\n",
    "\n",
    "# Aplicar histéresis de 1800 s para bajar\n",
    "SuppressionPool_TC_Level = aplicar_histeresis(tiempo_s, niveles_cond, 1800.0)\n",
    "\n",
    "# Guardar\n",
    "guardar_nivel_instrumento(\"SuppressionPoolThermocouples\", SuppressionPool_TC_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: SRV Position Indicators (con T y P del DRYWELL)\n",
    "# =========================\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_srv = np.ones_like(tiempo_s, dtype=int)\n",
    "\n",
    "# Nivel 2: CEC>EQ usando Drywell\n",
    "niveles_cond_srv[(TempVapor_Drywell > EQ_TEMP) | (Presion_Drywell > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 5: Vessel Failure (ya definido con Presion_BombaRecir < 6 MPa)\n",
    "niveles_cond_srv[VESSEL_FAILURE] = 5\n",
    "\n",
    "# Aplicar histéresis de 1800 s para bajar\n",
    "SRV_PositionIndicators_Level = aplicar_histeresis(tiempo_s, niveles_cond_srv, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles en el contenedor general\n",
    "guardar_nivel_instrumento(\"SRVPositionIndicators\", SRV_PositionIndicators_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Radiation Detectors in Containment (Drywell)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_rad = np.ones_like(tiempo_s, dtype=int)\n",
    "\n",
    "# Aplicar de menor a mayor gravedad; los superiores sobreescriben a los inferiores\n",
    "# Nivel 2: CEC>EQ (OR en T o P)\n",
    "niveles_cond_rad[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: 1.5*CEC>EQ\n",
    "niveles_cond_rad[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "\n",
    "# Nivel 5: 2*CEC>EQ\n",
    "niveles_cond_rad[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "RadiationDetectorsContainment_Level = aplicar_histeresis(tiempo_s, niveles_cond_rad, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"RadiationDetectorsContainment\", RadiationDetectorsContainment_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Boron Injection Pressure Transmitters (como presión en contención)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_bipt = np.ones_like(tiempo_s, dtype=int)\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P)\n",
    "niveles_cond_bipt[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: 1.5*CEC>EQ\n",
    "niveles_cond_bipt[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "\n",
    "# Nivel 5: 2*CEC>EQ\n",
    "niveles_cond_bipt[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "BoronInjectionPressureTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_bipt, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"BoronInjectionPressureTransmitters\", BoronInjectionPressureTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Boron Tank Level Transmitter (Drywell)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "# Helper: duración continua de una condición booleana (segundos)\n",
    "def duracion_continua(tiempo, mask_bool):\n",
    "    dur = np.zeros_like(tiempo, dtype=float)\n",
    "    for i in range(1, len(tiempo)):\n",
    "        if mask_bool[i]:\n",
    "            dur[i] = (dur[i-1] + (tiempo[i] - tiempo[i-1])) if mask_bool[i-1] else 0.0\n",
    "        else:\n",
    "            dur[i] = 0.0\n",
    "    return dur\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_btl = np.ones_like(tiempo_s, dtype=int)\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P del Drywell)\n",
    "niveles_cond_btl[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: 30 min después de Tcont>422 K (condición mantenida de forma continua)\n",
    "mask_T422 = T_dw > 422.0\n",
    "dur_T422 = duracion_continua(tiempo_s, mask_T422)\n",
    "niveles_cond_btl[dur_T422 >= 1800.0] = 3\n",
    "\n",
    "# Nivel 5: Tcont > 1530 K\n",
    "niveles_cond_btl[T_dw > 1530.0] = 5\n",
    "\n",
    "# Aplicar histéresis de 1800 s para bajar de nivel\n",
    "BoronTankLevelTransmitter_Level = aplicar_histeresis(tiempo_s, niveles_cond_btl, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"BoronTankLevelTransmitter\", BoronTankLevelTransmitter_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Drywell Pressure Transmitters\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "niveles_cond_dpt = np.ones_like(tiempo_s, dtype=int)\n",
    "# Nivel 2: CEC>EQ (OR)\n",
    "niveles_cond_dpt[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "# Nivel 3: 1.5*CEC>EQ\n",
    "niveles_cond_dpt[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "# Nivel 5: 2*CEC>EQ\n",
    "niveles_cond_dpt[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "\n",
    "DrywellPressureTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_dpt, 1800.0)\n",
    "guardar_nivel_instrumento(\"DrywellPressureTransmitters\", DrywellPressureTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Containment Pressure Transmitters\n",
    "# =========================\n",
    "niveles_cond_cpt = np.ones_like(tiempo_s, dtype=int)\n",
    "# Nivel 2: CEC>EQ (OR)\n",
    "niveles_cond_cpt[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "# Nivel 3: 1.5*CEC>EQ\n",
    "niveles_cond_cpt[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "# Nivel 5: 2*CEC>EQ\n",
    "niveles_cond_cpt[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "\n",
    "ContainmentPressureTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_cpt, 1800.0)\n",
    "guardar_nivel_instrumento(\"ContainmentPressureTransmitters\", ContainmentPressureTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Containment Thermocouples (Drywell)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_ctc = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto (base)\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P)\n",
    "niveles_cond_ctc[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: Tcont > 673 K\n",
    "niveles_cond_ctc[T_dw > 673.0] = 3\n",
    "\n",
    "# Nivel 5: Tcont > 1530 K\n",
    "niveles_cond_ctc[T_dw > 1530.0] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "ContainmentThermocouples_Level = aplicar_histeresis(tiempo_s, niveles_cond_ctc, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"ContainmentThermocouples\", ContainmentThermocouples_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Vessel Level (Wide Range)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "niveles_cond_vlwr = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P)\n",
    "niveles_cond_vlwr[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: 30 min continuos tras Tcont>422 K\n",
    "mask_T422_dw = T_dw > 422.0\n",
    "dur_T422_dw  = duracion_continua(tiempo_s, mask_T422_dw)\n",
    "niveles_cond_vlwr[dur_T422_dw >= 1800.0] = 3\n",
    "\n",
    "# Nivel 5: Vessel Failure (omite nivel 4)\n",
    "niveles_cond_vlwr[VESSEL_FAILURE] = 5\n",
    "\n",
    "VesselLevelWideRange_Level = aplicar_histeresis(tiempo_s, niveles_cond_vlwr, 1800.0)\n",
    "guardar_nivel_instrumento(\"VesselLevelWideRange\", VesselLevelWideRange_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Vessel Level (Fuel Range)\n",
    "# =========================\n",
    "niveles_cond_vlfr = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P)\n",
    "niveles_cond_vlfr[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 3: 30 min continuos tras Tcont>422 K\n",
    "niveles_cond_vlfr[dur_T422_dw >= 1800.0] = 3  # reutilizamos dur_T422_dw calculado arriba\n",
    "\n",
    "# Nivel 5: Vessel Failure (omite nivel 4)\n",
    "niveles_cond_vlfr[VESSEL_FAILURE] = 5\n",
    "\n",
    "VesselLevelFuelRange_Level = aplicar_histeresis(tiempo_s, niveles_cond_vlfr, 1800.0)\n",
    "guardar_nivel_instrumento(\"VesselLevelFuelRange\", VesselLevelFuelRange_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Vessel Pressure Transmitters\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "PRCS = Presion_BombaRecir  # presión de bomba de recirculación\n",
    "\n",
    "# Duración continua de T_dw > 422 K (para el nivel 3)\n",
    "mask_T422_dw = T_dw > 422.0\n",
    "dur_T422_dw  = duracion_continua(tiempo_s, mask_T422_dw)\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_vpt = np.ones_like(tiempo_s, dtype=int)\n",
    "\n",
    "# --- Nivel 2 ---\n",
    "# Condición A: PRCS < 0.25 MPa (250000 Pa) AND Pcont > 0.2 MPa (200000 Pa)\n",
    "cond_A = (PRCS < 250_000.0) & (P_dw > 200_000.0)\n",
    "\n",
    "# Condición B: CEC > EQ en Drywell (T o P)\n",
    "cond_B = (T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)\n",
    "\n",
    "niveles_cond_vpt[cond_A | cond_B] = 2\n",
    "\n",
    "# --- Nivel 3 ---\n",
    "niveles_cond_vpt[dur_T422_dw >= 1800.0] = 3  # 30 min (1800 s) continuos tras T_dw > 422 K\n",
    "\n",
    "# --- Nivel 5 ---\n",
    "niveles_cond_vpt[T_dw > 1530.0] = 5  # nivel 4 omitido\n",
    "\n",
    "# Aplicar histéresis de 1800 s para bajar\n",
    "VesselPressureTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_vpt, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"VesselPressureTransmitters\", VesselPressureTransmitters_Level)\n",
    "\n",
    "# Referencias Drywell\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "# =========================\n",
    "# Feedwater Flow Transmitters\n",
    "# Niveles: 1(base), 2: CEC>EQ, 3: 1.5*EQ, 5: 2*EQ (4 omitido)\n",
    "# =========================\n",
    "niveles_cond_fwft = np.ones_like(tiempo_s, dtype=int)\n",
    "niveles_cond_fwft[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "niveles_cond_fwft[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "niveles_cond_fwft[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "FeedwaterFlowTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_fwft, 1800.0)\n",
    "guardar_nivel_instrumento(\"FeedwaterFlowTransmitters\", FeedwaterFlowTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# Drywell Thermocouples\n",
    "# Niveles: 1 (273–422 K base), 2: CEC>EQ, 3: T>673 K, 5: T>1530 K (4 omitido)\n",
    "# =========================\n",
    "niveles_cond_dwtc = np.ones_like(tiempo_s, dtype=int)\n",
    "# (si quieres forzar estrictamente 273–422K para nivel 1, dilo y lo ajusto)\n",
    "niveles_cond_dwtc[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "niveles_cond_dwtc[T_dw > 673.0] = 3\n",
    "niveles_cond_dwtc[T_dw > 1530.0] = 5\n",
    "DrywellThermocouples_Level = aplicar_histeresis(tiempo_s, niveles_cond_dwtc, 1800.0)\n",
    "guardar_nivel_instrumento(\"DrywellThermocouples\", DrywellThermocouples_Level)\n",
    "\n",
    "# =========================\n",
    "# Radiation Detectors in Drywell\n",
    "# Niveles: 1(base), 2: CEC>EQ, 3: 1.5*EQ, 5: 2*EQ (4 omitido)\n",
    "# =========================\n",
    "niveles_cond_rddw = np.ones_like(tiempo_s, dtype=int)\n",
    "niveles_cond_rddw[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "niveles_cond_rddw[(T_dw > 1.5*EQ_TEMP) | (P_dw > 1.5*EQ_PRESSURE)] = 3\n",
    "niveles_cond_rddw[(T_dw > 2.0*EQ_TEMP) | (P_dw > 2.0*EQ_PRESSURE)] = 5\n",
    "RadiationDetectorsDrywell_Level = aplicar_histeresis(tiempo_s, niveles_cond_rddw, 1800.0)\n",
    "guardar_nivel_instrumento(\"RadiationDetectorsDrywell\", RadiationDetectorsDrywell_Level)\n",
    "\n",
    "# =========================\n",
    "# Control Rods Position\n",
    "# Niveles: 1(base), 2: CEC>EQ, 5: Vessel Failure (3 y 4 omitidos)\n",
    "# =========================\n",
    "niveles_cond_crp = np.ones_like(tiempo_s, dtype=int)\n",
    "niveles_cond_crp[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "niveles_cond_crp[VESSEL_FAILURE] = 5\n",
    "ControlRodsPosition_Level = aplicar_histeresis(tiempo_s, niveles_cond_crp, 1800.0)\n",
    "guardar_nivel_instrumento(\"ControlRodsPosition\", ControlRodsPosition_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Recirculation Pressure Transmitters (P106 / T106)\n",
    "# =========================\n",
    "P106 = Presion_BombaRecir        # Pa\n",
    "T106 = TempVapor_BombaRecir      # K\n",
    "\n",
    "# Umbrales en Pa/K (conversión MPa -> Pa incluida)\n",
    "P2_thr = 8_000_000.0     # 8 MPa\n",
    "T2_thr = 573.0           # 573 K\n",
    "P3_thr = 12_000_000.0    # 12 MPa\n",
    "T3_thr = 1100.0          # 1100 K\n",
    "P4_thr = 17_200_000.0    # 17.2 MPa\n",
    "T4_thr = 1530.0          # 1530 K\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_rpt = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto (base)\n",
    "\n",
    "# Nivel 2\n",
    "niveles_cond_rpt[(P106 > P2_thr) | (T106 > T2_thr)] = 2\n",
    "\n",
    "# Nivel 3\n",
    "niveles_cond_rpt[(P106 > P3_thr) | (T106 > T3_thr)] = 3\n",
    "\n",
    "# Nivel 4\n",
    "niveles_cond_rpt[(P106 > P4_thr) | (T106 > T4_thr)] = 4\n",
    "\n",
    "# Nivel 5 (Vessel Failure)\n",
    "niveles_cond_rpt[VESSEL_FAILURE] = 5\n",
    "\n",
    "# Aplicar histéresis de 1800 s para bajar\n",
    "RecirculationPressureTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_rpt, 10000.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"RecirculationPressureTransmitters\", RecirculationPressureTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Recirculation Flow Transmitters (P106 / T106)\n",
    "# =========================\n",
    "P106 = Presion_BombaRecir   # Pa\n",
    "T106 = TempVapor_BombaRecir # K\n",
    "\n",
    "# Umbrales (MPa -> Pa)\n",
    "P2_thr = 8_000_000.0     # 8 MPa\n",
    "T2_thr = 573.0           # 573 K\n",
    "P3_thr = 12_000_000.0    # 12 MPa\n",
    "T3_thr = 1100.0          # 1100 K\n",
    "P4_thr = 17_200_000.0    # 17.2 MPa\n",
    "T4_thr = 1530.0          # 1530 K\n",
    "\n",
    "# Niveles por condiciones instantáneas (1..5)\n",
    "niveles_cond_rft = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2\n",
    "niveles_cond_rft[(P106 > P2_thr) | (T106 > T2_thr)] = 2\n",
    "\n",
    "# Nivel 3\n",
    "niveles_cond_rft[(P106 > P3_thr) | (T106 > T3_thr)] = 3\n",
    "\n",
    "# Nivel 4\n",
    "niveles_cond_rft[(P106 > P4_thr) | (T106 > T4_thr)] = 4\n",
    "\n",
    "# Nivel 5 (Vessel Failure)\n",
    "niveles_cond_rft[VESSEL_FAILURE] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "RecirculationFlowTransmitters_Level = aplicar_histeresis(tiempo_s, niveles_cond_rft, 10000.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"RecirculationFlowTransmitters\", RecirculationFlowTransmitters_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Average Reactor Power Monitors (Drywell)\n",
    "# Niveles: 1(base), 2: CEC>EQ, 5: Vessel Failure (3 y 4 omitidos)\n",
    "# =========================\n",
    "T_dw = TempVapor_Drywell\n",
    "P_dw = Presion_Drywell\n",
    "\n",
    "niveles_cond_arpm = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2: CEC>EQ (OR en T o P del Drywell)\n",
    "niveles_cond_arpm[(T_dw > EQ_TEMP) | (P_dw > EQ_PRESSURE)] = 2\n",
    "\n",
    "# Nivel 5: Vessel Failure\n",
    "niveles_cond_arpm[VESSEL_FAILURE] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "AverageReactorPowerMonitors_Level = aplicar_histeresis(tiempo_s, niveles_cond_arpm, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"AverageReactorPowerMonitors\", AverageReactorPowerMonitors_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Vessel Thermocouples (Upper Head)\n",
    "# Niveles (1–5):\n",
    "# 1: 273–645 K (base)\n",
    "# 2: 645 K < T < 873 K\n",
    "# 3: 923 K < T < 1173 K\n",
    "# 4: 1173 K < T < 1530 K\n",
    "# 5: T > 1570 K\n",
    "# (Quedan huecos 873–923 K y 1530–1570 K tal como indican los rangos)\n",
    "# =========================\n",
    "T_uh = TempVapor_CabezaSuperior\n",
    "P_uh = Presion_CabezaSuperior  # No interviene en estos criterios, pero lo dejamos referenciado\n",
    "\n",
    "niveles_cond_vtuh = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2: 645 K < T < 873 K\n",
    "niveles_cond_vtuh[(T_uh > 645.0) & (T_uh < 873.0)] = 2\n",
    "\n",
    "# Nivel 3: 923 K < T < 1173 K\n",
    "niveles_cond_vtuh[(T_uh > 923.0) & (T_uh < 1173.0)] = 3\n",
    "\n",
    "# Nivel 4: 1173 K < T < 1530 K\n",
    "niveles_cond_vtuh[(T_uh > 1173.0) & (T_uh < 1530.0)] = 4\n",
    "\n",
    "# Nivel 5: T > 1570 K\n",
    "niveles_cond_vtuh[T_uh > 1570.0] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "VesselThermocouplesUpperHead_Level = aplicar_histeresis(tiempo_s, niveles_cond_vtuh, 1800.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"VesselThermocouplesUpperHead\", VesselThermocouplesUpperHead_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Vessel Thermocouples (Lower Head)\n",
    "# Niveles (1–5):\n",
    "# 1: 273–645 K (base)\n",
    "# 2: 645 K < T < 873 K\n",
    "# 3: 923 K < T < 1173 K\n",
    "# 4: 1173 K < T < 1530 K\n",
    "# 5: T > 1570 K\n",
    "# (Quedan huecos 873–923 K y 1530–1570 K, igual que el de Upper Head)\n",
    "# =========================\n",
    "T_lh = TempVapor_CabezaInferior\n",
    "P_lh = Presion_CabezaInferior  # no usado en estos criterios\n",
    "\n",
    "niveles_cond_vtlh = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2: 645 K < T < 873 K\n",
    "niveles_cond_vtlh[(T_lh > 645.0) & (T_lh < 873.0)] = 2\n",
    "\n",
    "# Nivel 3: 923 K < T < 1173 K\n",
    "niveles_cond_vtlh[(T_lh > 923.0) & (T_lh < 1173.0)] = 3\n",
    "\n",
    "# Nivel 4: 1173 K < T < 1530 K\n",
    "niveles_cond_vtlh[(T_lh > 1173.0) & (T_lh < 1530.0)] = 4\n",
    "\n",
    "# Nivel 5: Vessel Failure\n",
    "niveles_cond_vtlh[VESSEL_FAILURE] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "VesselThermocouplesLowerHead_Level = aplicar_histeresis(tiempo_s, niveles_cond_vtlh, 20000.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"VesselThermocouplesLowerHead\", VesselThermocouplesLowerHead_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: FW Thermocouples (usando Cabeza Inferior como proxy de Tcore)\n",
    "# Niveles (1–5):\n",
    "# 1: 273–645 K (base)\n",
    "# 2: 645 K < Tcore < 873 K\n",
    "# 3: — (omitido)\n",
    "# 4: 873 K < Tcore < 1530 K\n",
    "# 5: Tcore > 1570 K\n",
    "# =========================\n",
    "Tcore = TempVapor_CabezaInferior  # proxy Tcore con Cabeza Inferior\n",
    "\n",
    "niveles_cond_fwtc = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2\n",
    "niveles_cond_fwtc[(Tcore > 645.0) & (Tcore < 873.0)] = 2\n",
    "\n",
    "# Nivel 4\n",
    "niveles_cond_fwtc[(Tcore > 873.0) & (Tcore < 1530.0)] = 4\n",
    "\n",
    "# Nivel 5\n",
    "niveles_cond_fwtc[Tcore > 1570.0] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "FWThermocouples_Level = aplicar_histeresis(tiempo_s, niveles_cond_fwtc, 25000.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"FWThermocouples\", FWThermocouples_Level)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTO: Suction Pipes Thermocouples (T106)\n",
    "# Niveles (1–5):\n",
    "# 1: 273–645 K (base)\n",
    "# 2: 645 K < T < 873 K\n",
    "# 3: 923 K < T < 1173 K\n",
    "# 4: 1173 K < T < 1530 K\n",
    "# 5: T > 1570 K\n",
    "# (Quedan huecos 873–923 K y 1530–1570 K, según tu tabla)\n",
    "# =========================\n",
    "T106 = TempVapor_BombaRecir  # K\n",
    "\n",
    "niveles_cond_sptc = np.ones_like(tiempo_s, dtype=int)  # Nivel 1 por defecto\n",
    "\n",
    "# Nivel 2\n",
    "niveles_cond_sptc[(T106 > 645.0) & (T106 < 873.0)] = 2\n",
    "# Nivel 3\n",
    "niveles_cond_sptc[(T106 > 923.0) & (T106 < 1173.0)] = 3\n",
    "# Nivel 4\n",
    "niveles_cond_sptc[(T106 > 1173.0) & (T106 < 1530.0)] = 4\n",
    "# Nivel 5\n",
    "niveles_cond_sptc[T106 > 1570.0] = 5\n",
    "\n",
    "# Histéresis: 1800 s para bajar de nivel\n",
    "SuctionPipesThermocouples_Level = aplicar_histeresis(tiempo_s, niveles_cond_sptc, 100000.0)\n",
    "\n",
    "# Guardar serie de niveles\n",
    "guardar_nivel_instrumento(\"SuctionPipesThermocouples\", SuctionPipesThermocouples_Level)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def exportar_niveles_y_graficas(niveles_instrumentos: dict, tiempo_s: np.ndarray,\n",
    "                                carpeta_csv: str = \"csv_niveles\",\n",
    "                                carpeta_figs: str = \"graficas_niveles\"):\n",
    "    \"\"\"\n",
    "    Para cada instrumento en `niveles_instrumentos`:\n",
    "      - Guarda CSV con columnas: tiempo_s, nivel\n",
    "      - Genera PNG con step-plot del nivel (1–5) vs tiempo\n",
    "    \"\"\"\n",
    "    os.makedirs(carpeta_csv, exist_ok=True)\n",
    "    os.makedirs(carpeta_figs, exist_ok=True)\n",
    "\n",
    "    for nombre, niveles in niveles_instrumentos.items():\n",
    "        if niveles.shape != tiempo_s.shape:\n",
    "            print(f\"[ADVERTENCIA] Longitud diferente en '{nombre}': \"\n",
    "                  f\"tiempo={tiempo_s.shape}, niveles={niveles.shape}. Se omite.\")\n",
    "            continue\n",
    "\n",
    "        # Nombre de archivo seguro\n",
    "        safe = \"\".join(c if c.isalnum() or c in (\"_\", \"-\") else \"_\" for c in nombre)\n",
    "\n",
    "        # ----- CSV -----\n",
    "        df = pd.DataFrame({\"tiempo_s\": tiempo_s, \"nivel\": niveles.astype(int)})\n",
    "        ruta_csv = os.path.join(carpeta_csv, f\"{safe}_niveles.csv\")\n",
    "        df.to_csv(ruta_csv, index=False)\n",
    "\n",
    "        # ----- Gráfica -----\n",
    "        plt.figure()\n",
    "        plt.step(tiempo_s, niveles, where=\"post\")\n",
    "        plt.xlabel(\"Tiempo [s]\")\n",
    "        plt.ylabel(\"Nivel de daño (1–5)\")\n",
    "        plt.title(f\"{nombre} – Nivel (1–5)\")\n",
    "        plt.yticks([1, 2, 3, 4, 5])\n",
    "        plt.ylim(0.8, 5.2)  # para ver bien los extremos\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        ruta_png = os.path.join(carpeta_figs, f\"{safe}_niveles.png\")\n",
    "        plt.savefig(ruta_png, dpi=200)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"Guardado CSV: {ruta_csv}\")\n",
    "        print(f\"Guardada gráfica: {ruta_png}\")\n",
    "\n",
    "# Ejecuta la exportación\n",
    "exportar_niveles_y_graficas(niveles_instrumentos, tiempo_s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c400637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ No encontrado: FeedwaterPressureTransmitters_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: SuppressionPoolLevelTransmitters_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: HPCSFlowTransmitter_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: ContainmentHydrogenAnalyzer_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: DrywellHydrogenAnalyzer_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: ContainmentPressureTransmitterAux_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: DrywellPressureTransmitterAux_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN\n",
    "# ============================================================\n",
    "carpeta = Path(\"csv_niveles\")\n",
    "\n",
    "state_order = {'Good':0, 'Careful':1, 'Warning':2, 'Blind':3}\n",
    "\n",
    "# ============================================================\n",
    "# MAPEO CSV POR INSTRUMENTO\n",
    "# ============================================================\n",
    "instrument_to_csv = {\n",
    "    \"Average Reactor Power Monitors\": \"AverageReactorPowerMonitors\",\n",
    "    \"Boron Injection Pressure Transmitters\": \"BoronInjectionPressureTransmitters\",\n",
    "    \"Boron Tank Level Transmitter\": \"BoronTankLevelTransmitter\",\n",
    "    \"Containment Pressure Transmitters\": \"ContainmentPressureTransmitters\",\n",
    "    \"Containment Thermocouples\": \"ContainmentThermocouples\",\n",
    "    \"Control Rods Position\": \"ControlRodsPosition\",\n",
    "    \"Drywell Pressure Transmitters\": \"DrywellPressureTransmitters\",\n",
    "    \"Drywell Thermocouples\": \"DrywellThermocouples\",\n",
    "    \"Feedwater Flow Transmitters\": \"FeedwaterFlowTransmitters\",\n",
    "    \"Feedwater Pressure Transmitters\": \"FeedwaterPressureTransmitters\",\n",
    "    \"FW Thermocouples\": \"FWThermocouples\",\n",
    "    \"Radiation Detectors in Containment\": \"RadiationDetectorsContainment\",\n",
    "    \"Radiation Detectors in Drywell\": \"RadiationDetectorsDrywell\",\n",
    "    \"Recirculation Flow Transmitters\": \"RecirculationFlowTransmitters\",\n",
    "    \"Recirculation Pressure Transmitters\": \"RecirculationPressureTransmitters\",\n",
    "    \"SRV Position Indicators\": \"SRVPositionIndicators\",\n",
    "    \"Suction Pipes Thermocouples\": \"SuctionPipesThermocouples\",\n",
    "    \"Supression Pool Thermocouples\": \"SuppressionPoolThermocouples\",  # base 'pp'\n",
    "    \"Suppresion Pool Level Transmitters\": \"SuppressionPoolLevelTransmitters\",\n",
    "    \"Vessel Level (Fuel Range)\": \"VesselLevelFuelRange\",\n",
    "    \"Vessel Level (Wide Range)\": \"VesselLevelWideRange\",\n",
    "    \"Vessel Pressure Transmitters\": \"VesselPressureTransmitters\",\n",
    "    \"Vessel Thermocouples (Lower Head)\": \"VesselThermocouplesLowerHead\",\n",
    "    \"Vessel Thermocouples (Upper Head)\": \"VesselThermocouplesUpperHead\",\n",
    "    \"HPCS Flow Transmitter\": \"HPCSFlowTransmitter\",\n",
    "    \"Containment Hydrogen Concentration Analyzer\": \"ContainmentHydrogenAnalyzer\",\n",
    "    \"Drywell Hydrogen Concentration Analyzer\": \"DrywellHydrogenAnalyzer\",\n",
    "    # Opcionales si existen CSV:\n",
    "    \"Containment Pressure Transmitter (Auxiliary Building)\": \"ContainmentPressureTransmitterAux\",\n",
    "    \"Drywell Pressure Transmitter (Auxiliary Building)\": \"DrywellPressureTransmitterAux\",\n",
    "}\n",
    "\n",
    "# Alias (por si aparecen variantes de escritura)\n",
    "name_aliases = {\n",
    "    \"Suppression Pool Thermocouples\": \"Supression Pool Thermocouples\",\n",
    "    \"Suppression Pool Level Transmitters\": \"Suppresion Pool Level Transmitters\",\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# UTILIDADES\n",
    "# ============================================================\n",
    "def _canon(s: str) -> str:\n",
    "    return \"\".join(ch.lower() for ch in s if ch.isalnum())\n",
    "\n",
    "def resolve_instrument_name(name: str, available: dict) -> str | None:\n",
    "    name = name_aliases.get(name, name)\n",
    "    if name in available:\n",
    "        return name\n",
    "    idx = { _canon(k): k for k in available.keys() }\n",
    "    return idx.get(_canon(name))\n",
    "\n",
    "def leer_csv_flexible(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Lee CSV con separador auto (, ; \\t) y devuelve DF con columnas 'tiempo_s','nivel'.\"\"\"\n",
    "    seps = [\",\",\";\",\"\\t\",\"|\"]\n",
    "    last_err = None\n",
    "    for sep in seps:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=sep)\n",
    "            if df.shape[1] < 1:\n",
    "                continue\n",
    "            # limpiar columnas unnamed\n",
    "            df = df.loc[:, ~df.columns.astype(str).str.startswith(\"Unnamed\")]\n",
    "            cols = [c.lower().strip() for c in df.columns.astype(str)]\n",
    "\n",
    "            # Caso NUEVO (ancho): columnas tiempo_s, nivel\n",
    "            if \"tiempo_s\" in cols and \"nivel\" in cols:\n",
    "                tcol = df.columns[cols.index(\"tiempo_s\")]\n",
    "                ncol = df.columns[cols.index(\"nivel\")]\n",
    "                out = df[[tcol,ncol]].rename(columns={tcol:\"tiempo_s\", ncol:\"nivel\"}).copy()\n",
    "                out[\"tiempo_s\"] = pd.to_numeric(out[\"tiempo_s\"], errors=\"coerce\")\n",
    "                out[\"nivel\"]    = pd.to_numeric(out[\"nivel\"], errors=\"coerce\")\n",
    "                out = out.dropna(subset=[\"tiempo_s\",\"nivel\"])\n",
    "                out[\"nivel\"] = out[\"nivel\"].round().clip(1,5).astype(int)\n",
    "                out = out.sort_values(\"tiempo_s\").reset_index(drop=True)\n",
    "                return out\n",
    "\n",
    "            # Caso ANTIGUO (largo): Intervalo / Nivel de Daño\n",
    "            if \"intervalo\" in cols and \"nivel de daño\" in cols:\n",
    "                icol = df.columns[cols.index(\"intervalo\")]\n",
    "                lcol = df.columns[cols.index(\"nivel de daño\")]\n",
    "                tmp = df[[icol,lcol]].rename(columns={icol:\"Intervalo\", lcol:\"Nivel de Daño\"}).copy()\n",
    "                tmp[\"Intervalo\"] = tmp[\"Intervalo\"].astype(str)\n",
    "                tmp[\"Nivel de Daño\"] = pd.to_numeric(tmp[\"Nivel de Daño\"], errors=\"coerce\").fillna(1).astype(int).clip(1,5)\n",
    "                # inventamos tiempo_s como 0,1,2,... (pasos)\n",
    "                out = pd.DataFrame({\n",
    "                    \"tiempo_s\": np.arange(len(tmp), dtype=float),\n",
    "                    \"nivel\": tmp[\"Nivel de Daño\"].to_numpy(int)\n",
    "                })\n",
    "                return out\n",
    "\n",
    "            # Si tiene dos columnas cualesquiera, intentamos mapear a tiempo,nivel por posición\n",
    "            if df.shape[1] >= 2:\n",
    "                out = df.iloc[:, :2].copy()\n",
    "                out.columns = [\"tiempo_s\",\"nivel\"]\n",
    "                out[\"tiempo_s\"] = pd.to_numeric(out[\"tiempo_s\"], errors=\"coerce\")\n",
    "                out[\"nivel\"]    = pd.to_numeric(out[\"nivel\"], errors=\"coerce\")\n",
    "                out = out.dropna(subset=[\"tiempo_s\",\"nivel\"])\n",
    "                out[\"nivel\"] = out[\"nivel\"].round().clip(1,5).astype(int)\n",
    "                out = out.sort_values(\"tiempo_s\").reset_index(drop=True)\n",
    "                return out\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    # Si no pudimos leer, relanza último error\n",
    "    raise last_err if last_err else RuntimeError(f\"No se pudo leer {path}\")\n",
    "\n",
    "# ====== NUEVO: utilidades para construir y guardar CSV ======\n",
    "def _levels_dataframe(instrs):\n",
    "    \"\"\"\n",
    "    Devuelve (t_ref, df) donde df contiene 'tiempo_s' y,\n",
    "    por cada instrumento, una columna con su nivel remuestreado (1..5).\n",
    "    \"\"\"\n",
    "    t_ref = _reference_time(instrs)\n",
    "    data = {\"tiempo_s\": t_ref}\n",
    "    for i_name in instrs:\n",
    "        resolved = resolve_instrument_name(i_name, damage_by_instrument) or i_name\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        y = _resample_to_reference(df, t_ref)\n",
    "        data[resolved] = y.astype(int)\n",
    "    out = pd.DataFrame(data)\n",
    "    return t_ref, out\n",
    "\n",
    "def _availability_dataframe(instrs):\n",
    "    \"\"\"\n",
    "    Calcula availability y devuelve (t_ref, df) con columnas:\n",
    "    'tiempo_s', 'state', 'state_code' (0..3).\n",
    "    \"\"\"\n",
    "    t_ref = _reference_time(instrs)\n",
    "    levels = []\n",
    "    for i_name in instrs:\n",
    "        resolved = resolve_instrument_name(i_name, damage_by_instrument) or i_name\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        y = _resample_to_reference(df, t_ref)\n",
    "        levels.append(y.astype(int))\n",
    "\n",
    "    states, codes = [], []\n",
    "    for i in range(len(t_ref)):\n",
    "        lvls_t = [int(arr[i]) for arr in levels]\n",
    "        st = determine_state_from_levels(lvls_t)\n",
    "        states.append(st)\n",
    "        codes.append(state_order[st])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"tiempo_s\": t_ref,\n",
    "        \"state\": states,\n",
    "        \"state_code\": np.array(codes, dtype=int)\n",
    "    })\n",
    "    return t_ref, df\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CARGA TODOS LOS INSTRUMENTOS + TIEMPO DE REFERENCIA\n",
    "# ============================================================\n",
    "raw_data = {}\n",
    "ref_time = None\n",
    "\n",
    "for visible_name, base in instrument_to_csv.items():\n",
    "    ruta = carpeta / f\"{base}_niveles.csv\"\n",
    "    if ruta.exists():\n",
    "        df = leer_csv_flexible(ruta)\n",
    "        raw_data[visible_name] = df\n",
    "        if ref_time is None and not df.empty:\n",
    "            ref_time = df[\"tiempo_s\"].to_numpy()\n",
    "    else:\n",
    "        # se rellena luego con fallback\n",
    "        pass\n",
    "\n",
    "# Si no hay ningún CSV real, inventamos ref_time\n",
    "if ref_time is None:\n",
    "    ref_time = np.arange(100, dtype=float)  # 100 puntos por defecto\n",
    "\n",
    "# Completar faltantes con nivel=1 y mismo eje temporal\n",
    "for visible_name, base in instrument_to_csv.items():\n",
    "    if visible_name not in raw_data:\n",
    "        print(f\"⚠ No encontrado: {base}_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\")\n",
    "        raw_data[visible_name] = pd.DataFrame({\n",
    "            \"tiempo_s\": ref_time,\n",
    "            \"nivel\": np.ones_like(ref_time, dtype=int)\n",
    "        })\n",
    "\n",
    "# ============================================================\n",
    "# PREPARACIÓN DE ESTRUCTURAS\n",
    "# ============================================================\n",
    "damage_by_instrument = {name: df for name, df in raw_data.items()}\n",
    "\n",
    "# ============================================================\n",
    "# LÓGICA AVAILABILITY (tu regla)\n",
    "# ============================================================\n",
    "def determine_state_from_levels(lvls: list[int]) -> str:\n",
    "    if all(l == 1 for l in lvls):\n",
    "        return 'Good'\n",
    "    if any(l == 2 for l in lvls) and all(l <= 2 for l in lvls):\n",
    "        return 'Careful'\n",
    "    if all(l == 5 for l in lvls):\n",
    "        return 'Blind'\n",
    "    if any(l in (3,4) for l in lvls):\n",
    "        return 'Warning'\n",
    "    return 'Warning'\n",
    "\n",
    "# ============================================================\n",
    "# PLOTS\n",
    "# ============================================================\n",
    "def create_directory(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def _reference_time(instruments):\n",
    "    \"\"\"Devuelve el vector tiempo_s de referencia (el del primer instrumento con datos).\"\"\"\n",
    "    for instr in instruments:\n",
    "        resolved = resolve_instrument_name(instr, damage_by_instrument) or instr\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        if df is not None and not df.empty:\n",
    "            return df[\"tiempo_s\"].to_numpy()\n",
    "    return ref_time\n",
    "\n",
    "def _resample_to_reference(df: pd.DataFrame, t_ref: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ajusta la serie (tiempo_s, nivel) al eje temporal t_ref:\n",
    "    - si longitudes coinciden y tiempos iguales ≈: devuelve niveles tal cual\n",
    "    - si difiere, interpola 'nearest' por escalón (usamos pandas merge_asof).\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return np.ones_like(t_ref, dtype=int)\n",
    "    src_t = df[\"tiempo_s\"].to_numpy()\n",
    "    src_y = df[\"nivel\"].to_numpy(int)\n",
    "\n",
    "    if len(src_t) == len(t_ref) and np.allclose(src_t, t_ref, rtol=0, atol=1e-9):\n",
    "        return src_y\n",
    "\n",
    "    # merge_asof para asignar al tiempo de referencia el nivel más cercano (look-up tipo nearest)\n",
    "    a = pd.DataFrame({\"t\": t_ref})\n",
    "    b = pd.DataFrame({\"t\": src_t, \"y\": src_y}).sort_values(\"t\")\n",
    "    out = pd.merge_asof(a.sort_values(\"t\"), b, on=\"t\", direction=\"nearest\")\n",
    "    y = out[\"y\"].fillna(1).round().clip(1,5).astype(int).to_numpy()\n",
    "    return y\n",
    "\n",
    "def plot_damage(instruments, save_path, title):\n",
    "    t_ref = _reference_time(instruments)\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), dpi=100)\n",
    "    fig.patch.set_facecolor('#001F3F')\n",
    "    ax.set_facecolor('#001F3F')\n",
    "\n",
    "    markers = ['o','s','D','^','v','P','X','*','<','>']\n",
    "    for idx, instr in enumerate(instruments):\n",
    "        resolved = resolve_instrument_name(instr, damage_by_instrument) or instr\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        y = _resample_to_reference(df, t_ref)\n",
    "        jitter = (idx - len(instruments)/2) * 0.05\n",
    "        ax.plot(\n",
    "            t_ref, y + jitter,\n",
    "            marker=markers[idx % len(markers)],\n",
    "            markersize=6,\n",
    "            linewidth=1.8,\n",
    "            label=resolved,\n",
    "            markevery=max(1, len(t_ref)//20)\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Time (s)\", color='white', fontsize=20)\n",
    "    ax.set_ylabel(\"Damage Level\", color='white', fontsize=20)\n",
    "    ax.set_yticks([1,2,3,4,5])\n",
    "    ax.set_yticklabels([1,2,3,4,5], color='white', fontsize=18)\n",
    "    ax.tick_params(colors='white', labelsize=16)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('white')\n",
    "    ax.grid(color='white', linestyle='--', alpha=0.2, linewidth=1)\n",
    "    ax.set_title(title, color='white', fontsize=28, pad=24)\n",
    "\n",
    "    # leyenda abajo\n",
    "    leg_cols = len(instruments) if len(instruments) <= 2 else (len(instruments)+1)//2\n",
    "    leg = ax.legend(\n",
    "        loc='upper center', bbox_to_anchor=(0.5, -0.12),\n",
    "        ncol=max(1, leg_cols), frameon=False, fontsize=14\n",
    "    )\n",
    "    for txt in leg.get_texts():\n",
    "        txt.set_color('white')\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.25)\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_availability(measure, t_ref, states, save_path):\n",
    "    import numpy as np\n",
    "    values = np.array([state_order[s] for s in states], dtype=int)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), dpi=100)\n",
    "    fig.patch.set_facecolor('#001F3F')\n",
    "    ax.set_facecolor('#001F3F')\n",
    "\n",
    "    # bandas por estado (Good/Careful/Warning/Blind)\n",
    "    bands = {0:'#2E7D32', 1:'#F9A825', 2:'#EF6C00', 3:'#B71C1C'}\n",
    "    for lvl, col in bands.items():\n",
    "        ax.axhspan(lvl, lvl+1, color=col, alpha=0.25)\n",
    "\n",
    "    # línea escalonada (mismo estilo que daño)\n",
    "    ax.plot(t_ref, values, drawstyle='steps-post', marker='o',\n",
    "            markersize=6, linewidth=1.8)\n",
    "\n",
    "    # === Igualamos estilo de ejes al de \"daño\" ===\n",
    "    ax.set_xlabel(\"Time (s)\", color='white', fontsize=20)\n",
    "    ax.set_ylabel(\"\", color='white', fontsize=20)  # sin etiqueta textual\n",
    "    ax.set_yticks([0,1,2,3])\n",
    "    ax.set_yticklabels(list(state_order.keys()), color='white', fontsize=18)\n",
    "\n",
    "    # ¡NO fijamos los xticks! (dejamos el auto-locator como en daño)\n",
    "    ax.tick_params(colors='white', labelsize=16)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('white')\n",
    "    ax.grid(color='white', linestyle='--', alpha=0.2, linewidth=1)\n",
    "    ax.set_title(f\"{measure} Availability\", color='white', fontsize=28, pad=24)\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.25)\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GENERACIÓN DE SALIDAS\n",
    "# ============================================================\n",
    "def create_directory(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def generate_graphs(samg_name, samg_dict, actions_map):\n",
    "    create_directory(samg_name)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(samg_name, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                base = measure.replace(' ', '_').replace('/', '_')\n",
    "                # --- nuevo: CSV de niveles por instrumento (remuestreados) ---\n",
    "                _, df_levels = _levels_dataframe(instrs)\n",
    "                df_levels.to_csv(os.path.join(path_code, base + \".csv\"),\n",
    "                                 index=False, encoding=\"utf-8\")\n",
    "                # --- gráfico como antes ---\n",
    "                plot_damage(instrs, os.path.join(path_code, base + \".png\"), measure)\n",
    "\n",
    "\n",
    "def generate_availability(samg_name, samg_dict, actions_map):\n",
    "    base_dir = f\"Availability_{samg_name}\"\n",
    "    create_directory(base_dir)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(base_dir, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                safe = measure.replace(' ', '_').replace('/', '_')\n",
    "                # --- nuevo: CSV de availability ---\n",
    "                t_ref, df_av = _availability_dataframe(instrs)\n",
    "                df_av.to_csv(os.path.join(path_code, safe + \"_availability.csv\"),\n",
    "                             index=False, encoding=\"utf-8\")\n",
    "                # --- gráfico como antes ---\n",
    "                states = df_av[\"state\"].tolist()\n",
    "                plot_availability(measure, t_ref, states,\n",
    "                                  os.path.join(path_code, safe + \"_availability.png\"))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EJECUCIÓN\n",
    "# ============================================================\n",
    "generate_graphs(\"SAMG1_PyT\", SAMG1, actions_short)\n",
    "generate_graphs(\"SAMG2_PyT\", SAMG2, actions_short)\n",
    "generate_availability(\"SAMG1_PyT\", SAMG1, actions_short)\n",
    "generate_availability(\"SAMG2_PyT\", SAMG2, actions_short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9105b29d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠️  Omito TEMPERATURE_DRYWELL: faltan TEMPERATURE_DRYWELL_1.csv o TEMPERATURE_DRYWELL_2.csv\n",
      "⚠️  Omito PRESSURE_DRYWELL: faltan PRESSURE_DRYWELL_1.csv o PRESSURE_DRYWELL_2.csv\n",
      "⚠️  Omito RADIATION_CONTAINMENT: faltan RADIATION_CONTAINMENT_1.csv o RADIATION_CONTAINMENT_2.csv\n",
      "⚠️  Omito HYDROGEN_CONTAINMENT: faltan HYDROGEN_CONTAINMENT_1.csv o HYDROGEN_CONTAINMENT_2.csv\n",
      "⚠️  Omito LEVEL_BORON_TANK: faltan LEVEL_BORON_TANK_1.csv o LEVEL_BORON_TANK_2.csv\n",
      "⚠️  Omito INJECTED_FLOW_RPV: faltan INJECTED_FLOW_RPV_1.csv o INJECTED_FLOW_RPV_2.csv\n",
      "⚠️  Omito LEVEL_RPV: faltan LEVEL_RPV_1.csv o LEVEL_RPV_2.csv\n",
      "⚠️  Omito PRESSURE_RPV: faltan PRESSURE_RPV_1.csv o PRESSURE_RPV_2.csv\n",
      "⚠️  Omito TEMPERATURE_RPV: faltan TEMPERATURE_RPV_1.csv o TEMPERATURE_RPV_2.csv\n",
      "⚠️  Omito PRESSURE_CONTAINMENT: faltan PRESSURE_CONTAINMENT_1.csv o PRESSURE_CONTAINMENT_2.csv\n",
      "⚠️  Omito LEVEL_CONTAINMENT: faltan LEVEL_CONTAINMENT_1.csv o LEVEL_CONTAINMENT_2.csv\n",
      "⚠️  Omito PRESSURE_SP: faltan PRESSURE_SP_1.csv o PRESSURE_SP_2.csv\n",
      "⚠️  Omito TEMPERATURE_SP: faltan TEMPERATURE_SP_1.csv o TEMPERATURE_SP_2.csv\n",
      "⚠️  Omito SRV_POSITION: faltan SRV_POSITION_1.csv o SRV_POSITION_2.csv\n",
      "⚠️  Omito REACTOR_POWER: faltan REACTOR_POWER_1.csv o REACTOR_POWER_2.csv\n",
      "⚠️  Omito TEMPERATURE_CONTAINMENT: faltan TEMPERATURE_CONTAINMENT_1.csv o TEMPERATURE_CONTAINMENT_2.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===========================\n",
    "# CONFIGURATION\n",
    "# ===========================\n",
    "\n",
    "VARIABLES = [\n",
    "    \"TEMPERATURE_DRYWELL\",\n",
    "    \"PRESSURE_DRYWELL\",\n",
    "    \"RADIATION_CONTAINMENT\",\n",
    "    \"HYDROGEN_CONTAINMENT\",\n",
    "    \"LEVEL_BORON_TANK\",\n",
    "    \"INJECTED_FLOW_RPV\",\n",
    "    \"LEVEL_RPV\",\n",
    "    \"PRESSURE_RPV\",\n",
    "    \"TEMPERATURE_RPV\",\n",
    "    \"PRESSURE_CONTAINMENT\",\n",
    "    \"LEVEL_CONTAINMENT\",\n",
    "    \"PRESSURE_SP\",\n",
    "    \"TEMPERATURE_SP\",\n",
    "    \"SRV_POSITION\",\n",
    "    \"REACTOR_POWER\",\n",
    "    \"TEMPERATURE_CONTAINMENT\"\n",
    "]\n",
    "\n",
    "OUT_DIR = \"GLOBAL_EVALUATION\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "T_MAX = 86400\n",
    "\n",
    "MARKERS = [\"o\", \"s\", \"^\", \"D\", \"v\", \"P\", \"X\", \"<\", \">\", \"h\"]\n",
    "\n",
    "STATE_MAP = {\"Good\": 0, \"Careful\": 1, \"Warning\": 2, \"Blind\": 3}\n",
    "ZONE_COLORS = {0: \"#006400\", 1: \"#CCCC00\", 2: \"#FF8C00\", 3: \"#8B0000\"}\n",
    "\n",
    "# ===========================\n",
    "# UTILITIES\n",
    "# ===========================\n",
    "\n",
    "def interval_to_seconds(interval_str: str):\n",
    "    norm = str(interval_str).strip().lower().replace(\" \", \"\")\n",
    "    if norm in (\"12h-1d\", \"12h-1dia\", \"12h-1día\", \"12h_a_1d\"):\n",
    "        return (12*3600, 24*3600)\n",
    "    if norm in (\"0-1d\", \"0-1dia\", \"0-1día\"):\n",
    "        return (12*3600, 24*3600)\n",
    "    if norm in (\"0-1h\", \"0h-1h\"):\n",
    "        return (0, 1*3600)\n",
    "    if norm in (\"1-12h\", \"1h-12h\"):\n",
    "        return (1*3600, 12*3600)\n",
    "    if \"-\" in norm:\n",
    "        a, b = norm.split(\"-\")\n",
    "        def to_s(x):\n",
    "            if x.endswith(\"h\"):\n",
    "                return int(float(x[:-1]) * 3600)\n",
    "            if x.endswith(\"d\"):\n",
    "                return int(float(x[:-1]) * 86400)\n",
    "            return int(float(x))\n",
    "        return (to_s(a), to_s(b))\n",
    "    raise ValueError(f\"No puedo interpretar el intervalo: {interval_str!r}\")\n",
    "\n",
    "def load_interval_table(csv1_path: str) -> pd.DataFrame:\n",
    "    df1 = pd.read_csv(csv1_path)\n",
    "    col_interval = None\n",
    "    for c in df1.columns:\n",
    "        if str(c).strip().lower() == \"interval\":\n",
    "            col_interval = c\n",
    "            break\n",
    "    if col_interval is None:\n",
    "        raise ValueError(f\"{csv1_path}: no encuentro columna 'Interval'.\")\n",
    "    inst_cols = [c for c in df1.columns if c != col_interval]\n",
    "    rows = []\n",
    "    for _, r in df1.iterrows():\n",
    "        start, end = interval_to_seconds(r[col_interval])\n",
    "        for col in inst_cols:\n",
    "            val = int(r[col])\n",
    "            rows.append({\"start\": start, \"end\": end, \"Instrument\": col, \"Damage\": val})\n",
    "    return pd.DataFrame(rows).sort_values([\"Instrument\", \"start\"]).reset_index(drop=True)\n",
    "\n",
    "def load_timeseries_table(csv2_path: str) -> pd.DataFrame:\n",
    "    df2 = pd.read_csv(csv2_path)\n",
    "    time_col = None\n",
    "    for c in df2.columns:\n",
    "        if str(c).strip().lower() in (\"tiempo_s\", \"time_s\", \"t\", \"tiempo\"):\n",
    "            time_col = c\n",
    "            break\n",
    "    if time_col is None:\n",
    "        raise ValueError(f\"{csv2_path}: no encuentro columna de tiempo en segundos.\")\n",
    "    if time_col != \"tiempo_s\":\n",
    "        df2 = df2.rename(columns={time_col: \"tiempo_s\"})\n",
    "    return df2\n",
    "\n",
    "def df1_value_at(df1_intervals: pd.DataFrame, instrument: str, t: float) -> int:\n",
    "    sub = df1_intervals[(df1_intervals[\"Instrument\"] == instrument) &\n",
    "                        (df1_intervals[\"start\"] <= t) &\n",
    "                        (t < df1_intervals[\"end\"])]\n",
    "    if not sub.empty:\n",
    "        return int(sub.iloc[0][\"Damage\"])\n",
    "    if math.isclose(t, T_MAX, rel_tol=0, abs_tol=1e-9):\n",
    "        last = df1_intervals[df1_intervals[\"Instrument\"] == instrument].sort_values(\"end\").iloc[-1]\n",
    "        return int(last[\"Damage\"])\n",
    "    return np.nan\n",
    "\n",
    "def df2_value_at(df2: pd.DataFrame, instrument: str, t: float) -> int:\n",
    "    sub = df2[df2[\"tiempo_s\"] <= t]\n",
    "    if sub.empty:\n",
    "        return int(df2.iloc[0][instrument])\n",
    "    return int(sub.iloc[-1][instrument])\n",
    "\n",
    "def build_series_max(csv1_path: str, csv2_path: str):\n",
    "    df1_intervals = load_interval_table(csv1_path)\n",
    "    df2 = load_timeseries_table(csv2_path)\n",
    "    insts = sorted(set(df1_intervals[\"Instrument\"].unique()).union(\n",
    "                   set([c for c in df2.columns if c != \"tiempo_s\"])))\n",
    "    T = set([0, T_MAX])\n",
    "    for _, r in df1_intervals.iterrows():\n",
    "        T.add(int(r[\"start\"]))\n",
    "        T.add(int(r[\"end\"]))\n",
    "    for t in df2[\"tiempo_s\"].values:\n",
    "        if 0 <= t <= T_MAX:\n",
    "            T.add(float(t))\n",
    "    T = sorted(T)\n",
    "    series = {}\n",
    "    for inst in insts:\n",
    "        y_vals = []\n",
    "        for tt in T:\n",
    "            v1 = df1_value_at(df1_intervals, inst, tt)\n",
    "            v2 = df2_value_at(df2, inst, tt) if inst in df2.columns else np.nan\n",
    "            y_vals.append(int(max(v1, v2)))\n",
    "        x_comp, y_comp = [T[0]], [y_vals[0]]\n",
    "        for i in range(1, len(T)):\n",
    "            if y_vals[i] != y_comp[-1]:\n",
    "                x_comp.append(T[i])\n",
    "                y_comp.append(y_vals[i])\n",
    "        if x_comp[-1] != T_MAX:\n",
    "            x_comp.append(T_MAX)\n",
    "            y_comp.append(y_comp[-1])\n",
    "        series[inst] = (np.array(x_comp), np.array(y_comp))\n",
    "    return series, insts\n",
    "\n",
    "def auto_offsets(n: int, base=0.06):  # más separación que antes\n",
    "    if n == 1:\n",
    "        return [0.0]\n",
    "    idx = np.arange(n) - (n-1)/2.0\n",
    "    return (idx / max(1, (n-1)/2.0)) * base\n",
    "\n",
    "def plot_variable(name: str, series: dict, insts: list, out_dir=OUT_DIR):\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    fig.patch.set_facecolor(\"#06243A\")\n",
    "    ax.set_facecolor(\"#06243A\")\n",
    "    offs = auto_offsets(len(insts), base=0.06)\n",
    "    markers = {insts[i]: MARKERS[i % len(MARKERS)] for i in range(len(insts))}\n",
    "    line_kwargs = dict(\n",
    "        where=\"post\",\n",
    "        linewidth=2.0,\n",
    "        markersize=7,\n",
    "        markeredgewidth=1.8,\n",
    "        solid_capstyle=\"butt\",\n",
    "        mfc=\"none\",\n",
    "        markevery=None\n",
    "    )\n",
    "    y_all = []\n",
    "    for i, inst in enumerate(insts):\n",
    "        x, y = series[inst]\n",
    "        y_shift = y + offs[i]\n",
    "        y_all.extend(list(y_shift))\n",
    "        ln = ax.step(x, y_shift, marker=markers[inst], label=inst, **line_kwargs)[0]\n",
    "        ln.set_zorder(3)\n",
    "    ax.set_title(name.replace(\"_\", \" \"), fontsize=34, fontweight=\"bold\", color=\"white\", pad=20)\n",
    "    ax.set_xlabel(\"Time (s)\", fontsize=20, color=\"white\", labelpad=15)\n",
    "    ax.set_ylabel(\"Damage Level\", fontsize=24, color=\"white\", labelpad=15)\n",
    "    ax.set_xlim(0, T_MAX)\n",
    "    ymin = max(0.9, np.nanmin(y_all) - 0.1)\n",
    "    ymax = min(5.1, np.nanmax(y_all) + 0.1)\n",
    "    ax.set_ylim(ymin, ymax)\n",
    "    ax.tick_params(axis=\"both\", colors=\"white\", labelsize=14)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color(\"white\")\n",
    "        spine.set_alpha(0.6)\n",
    "    plt.subplots_adjust(bottom=0.24)\n",
    "    leg_cols = min(4, max(2, int(math.ceil(len(insts)/2))))\n",
    "    legend = ax.legend(\n",
    "        loc=\"upper center\",\n",
    "        bbox_to_anchor=(0.5, -0.18),\n",
    "        ncol=leg_cols,\n",
    "        frameon=False,\n",
    "        fontsize=14,\n",
    "        handlelength=2.6,\n",
    "        handletextpad=0.8,\n",
    "        columnspacing=1.8,\n",
    "    )\n",
    "    for text in legend.get_texts():\n",
    "        text.set_color(\"white\")\n",
    "    plt.tight_layout()\n",
    "    out_path = os.path.join(out_dir, f\"{name}_COMBINED.png\")\n",
    "    plt.savefig(out_path, dpi=220, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    print(f\"✓ Guardado: {out_path}\")\n",
    "\n",
    "# ===========================\n",
    "# AVAILABILITY\n",
    "# ===========================\n",
    "\n",
    "def classify_state_from_levels(levels):\n",
    "    if not levels:\n",
    "        return \"Blind\"\n",
    "    lvls = [int(x) for x in levels if x is not None]\n",
    "    if all(l == 1 for l in lvls):\n",
    "        return \"Good\"\n",
    "    if all(l == 5 for l in lvls):\n",
    "        return \"Blind\"\n",
    "    if any(l in (3, 4) for l in lvls):\n",
    "        return \"Warning\"\n",
    "    if any(l == 2 for l in lvls) and all(l <= 2 for l in lvls):\n",
    "        return \"Careful\"\n",
    "    return \"Warning\"\n",
    "\n",
    "def build_availability_from_series(series: dict, insts: list):\n",
    "    all_times = set()\n",
    "    for inst in insts:\n",
    "        x, _ = series[inst]\n",
    "        all_times.update(x.tolist())\n",
    "    times = sorted(all_times)\n",
    "    states, codes = [], []\n",
    "    for t in times:\n",
    "        lvls = []\n",
    "        for inst in insts:\n",
    "            x, y = series[inst]\n",
    "            idx = np.searchsorted(x, t, side=\"right\") - 1\n",
    "            idx = max(0, min(idx, len(y) - 1))\n",
    "            lvls.append(int(y[idx]))\n",
    "        st = classify_state_from_levels(lvls)\n",
    "        states.append(st)\n",
    "        codes.append(STATE_MAP[st])\n",
    "    return pd.DataFrame({\"time_s\": times, \"state\": states, \"state_code\": codes})\n",
    "\n",
    "def plot_availability_timeseries(var_name: str, df_av: pd.DataFrame, save_path: str):\n",
    "    times = df_av[\"time_s\"].tolist()\n",
    "    values = df_av[\"state_code\"].tolist()\n",
    "    fig, ax = plt.subplots(figsize=(16, 9), dpi=120)\n",
    "    fig.patch.set_facecolor(\"#06243A\")\n",
    "    ax.set_facecolor(\"#06243A\")\n",
    "    for lvl, col in ZONE_COLORS.items():\n",
    "        ax.axhspan(lvl, lvl + 1, color=col, alpha=0.28)\n",
    "    ax.step(times, values, where=\"post\", marker=\"o\", mfc=\"none\",\n",
    "            markersize=6, linewidth=1.8, color=\"#00CED1\")\n",
    "    ax.set_xlim(0, T_MAX)\n",
    "    ax.set_xlabel(\"Time (s)\", fontsize=20, color=\"white\", labelpad=15)\n",
    "    ax.set_ylabel(\"Availability State\", fontsize=20, color=\"white\", labelpad=15)\n",
    "    ax.set_yticks(list(STATE_MAP.values()))\n",
    "    ax.set_yticklabels(list(STATE_MAP.keys()), color=\"white\", fontsize=16)\n",
    "    ax.set_title(f\"{var_name.replace('_',' ')} Availability\", color=\"white\", fontsize=28, pad=40)\n",
    "    ax.tick_params(colors=\"white\", labelsize=14)\n",
    "    ax.grid(color=\"white\", linestyle=\"--\", alpha=0.25, linewidth=1)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"white\")\n",
    "    fig.subplots_adjust(top=0.88, bottom=0.18)\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=220)\n",
    "    plt.close(fig)\n",
    "    print(f\"✓ Guardado: {save_path}\")\n",
    "\n",
    "# ===========================\n",
    "# EJECUCIÓN\n",
    "# ===========================\n",
    "\n",
    "for var in VARIABLES:\n",
    "    csv1 = f\"{var}_1.csv\"\n",
    "    csv2 = f\"{var}_2.csv\"\n",
    "    if not (os.path.exists(csv1) and os.path.exists(csv2)):\n",
    "        print(f\"⚠️  Omito {var}: faltan {csv1} o {csv2}\")\n",
    "        continue\n",
    "    series, insts = build_series_max(csv1, csv2)\n",
    "    # Plot damage curves\n",
    "    plot_variable(var, series, insts, out_dir=OUT_DIR)\n",
    "    # Availability\n",
    "    df_av = build_availability_from_series(series, insts)\n",
    "    csv_out = os.path.join(OUT_DIR, f\"{var}_availability.csv\")\n",
    "    df_av.to_csv(csv_out, index=False)\n",
    "    plot_availability_timeseries(var, df_av, os.path.join(OUT_DIR, f\"{var}_availability.png\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
