{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9adc9c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Batch 1 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 20300.53\n",
      "[With Shield] Final Level = 5 | Max Ratio = 794500.29\n",
      "[Sphere] Final Level = 5 | Max Ratio = 356.50\n",
      "→ Copied Sphere CSV for Batch 1 to current directory as 'sphere_damage_levels_1.csv'\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 63971.40\n",
      "[Batch 1] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 2 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 16039.55\n",
      "[With Shield] Final Level = 5 | Max Ratio = 628956.71\n",
      "[Sphere] Final Level = 5 | Max Ratio = 311.85\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 50631.38\n",
      "[Batch 2] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 3 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 5394.32\n",
      "[With Shield] Final Level = 5 | Max Ratio = 210613.35\n",
      "[Sphere] Final Level = 5 | Max Ratio = 37.83\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 16962.23\n",
      "[Batch 3] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 4 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 219702.19\n",
      "[With Shield] Final Level = 5 | Max Ratio = 8478329.74\n",
      "[Sphere] Final Level = 5 | Max Ratio = 297.11\n",
      "→ Copied Sphere CSV for Batch 4 to current directory as 'sphere_damage_levels_4.csv'\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 681925.13\n",
      "[Batch 4] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 5 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 1 | Max Ratio = 0.00\n",
      "[With Shield] Final Level = 1 | Max Ratio = 0.00\n",
      "[Sphere] Final Level = 1 | Max Ratio = 0.00\n",
      "→ Copied Sphere CSV for Batch 5 to current directory as 'sphere_damage_levels_5.csv'\n",
      "[Circular Base] Final Level = 1 | Max Ratio = 0.00\n",
      "[Batch 5] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 6 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 548085.55\n",
      "[With Shield] Final Level = 5 | Max Ratio = 20489102.00\n",
      "[Sphere] Final Level = 1 | Max Ratio = 0.01\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 1645688.48\n",
      "[Batch 6] Damage Levels generated! ✅\n",
      "\n",
      "=== Batch 7 — Damage Levels (time-resolved) ===\n",
      "[Point Source] Final Level = 5 | Max Ratio = 84519.02\n",
      "[With Shield] Final Level = 5 | Max Ratio = 3287083.90\n",
      "[Sphere] Final Level = 5 | Max Ratio = 113.87\n",
      "→ Copied Sphere CSV for Batch 7 to current directory as 'sphere_damage_levels_7.csv'\n",
      "[Circular Base] Final Level = 5 | Max Ratio = 264584.61\n",
      "[Batch 7] Damage Levels generated! ✅\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===============================================\n",
    "# MODULE: DAMAGE LEVELS (time-resolved calculation)\n",
    "# ===============================================\n",
    "\n",
    "eq_data = [\n",
    "    (3600,    4e6),    # 1 hour\n",
    "    (43200,   2e7),    # 12 hours\n",
    "    (86400,   2.4e7),  # 1 day\n",
    "    (864000,  4e7),    # 10 days\n",
    "    (2592000, 5.5e7),  # 1 month\n",
    "    (15552000,1.1e8),  # 6 months\n",
    "    (31536000,1.5e8)   # 1 year\n",
    "]\n",
    "\n",
    "def level_from_ratio(r):\n",
    "    if r < 1:\n",
    "        return 1\n",
    "    elif r < 4:\n",
    "        return 2\n",
    "    elif r < 7:\n",
    "        return 3\n",
    "    elif r < 10:\n",
    "        return 4\n",
    "    else:\n",
    "        return 5\n",
    "\n",
    "def calculate_damage_level(acc_dose, EQ, current_level):\n",
    "    ratio = acc_dose / EQ if EQ > 0 else float('inf')\n",
    "    lvl = level_from_ratio(ratio)\n",
    "    return lvl, ratio, lvl\n",
    "\n",
    "# -----------------------------------------------\n",
    "# Helpers para autodetectar batches y time_steps\n",
    "# -----------------------------------------------\n",
    "def find_batches(base_dir=\".\"):\n",
    "    \"\"\"Devuelve la lista ordenada de números de batch detectados en carpetas output_batch_N.\"\"\"\n",
    "    batches = []\n",
    "    for name in os.listdir(base_dir):\n",
    "        m = re.match(r\"output_batch_(\\d+)$\", name)\n",
    "        if m and os.path.isdir(os.path.join(base_dir, name)):\n",
    "            batches.append(int(m.group(1)))\n",
    "    return sorted(batches)\n",
    "\n",
    "def load_time_steps_for_batch(batch_num, dose_methods):\n",
    "    \"\"\"\n",
    "    Intenta cargar el vector de time_steps (en segundos) para un batch:\n",
    "    1) Si existe un 'total_accumulated_*.csv', lee su primera columna.\n",
    "    2) Si no, toma cualquier 'dose_rate_..._class_1.csv' y lee la primera columna.\n",
    "    \"\"\"\n",
    "    plots_dir = os.path.join(f\"output_batch_{batch_num}\", \"dose_rate_plots\")\n",
    "\n",
    "    # 1) ¿Hay algún total acumulado ya generado?\n",
    "    for label in dose_methods.keys():\n",
    "        total_csv = os.path.join(plots_dir, f\"total_accumulated_{label.replace(' ', '_')}.csv\")\n",
    "        if os.path.exists(total_csv):\n",
    "            # primera columna = tiempo (s)\n",
    "            try:\n",
    "                data = np.loadtxt(total_csv, delimiter=',', skiprows=1, usecols=0)\n",
    "                return np.asarray(data, dtype=float)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "    # 2) Buscar un CSV de una clase para deducir el eje temporal\n",
    "    candidates = []\n",
    "    for prefix in dose_methods.values():\n",
    "        candidates.append(os.path.join(plots_dir, f\"{prefix}1.csv\"))\n",
    "    for cand in candidates:\n",
    "        if os.path.exists(cand):\n",
    "            try:\n",
    "                # asume formato: [Time(s), class1, class2, ...] -> cogemos la 1ª columna\n",
    "                arr = np.loadtxt(cand, delimiter=',', skiprows=1)\n",
    "                return np.asarray(arr[:, 0], dtype=float)\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "    raise FileNotFoundError(\n",
    "        f\"No pude deducir 'time_steps' para el batch {batch_num}. \"\n",
    "        f\"Revisa que existan CSVs en {plots_dir}.\"\n",
    "    )\n",
    "\n",
    "# ===============================================\n",
    "# MAIN LOOP\n",
    "# ===============================================\n",
    "\n",
    "dose_methods = {\n",
    "    \"Point Source\":      \"dose_rate_point_source_class_\",\n",
    "    \"With Shield\":       \"dose_rate_shield_class_\",\n",
    "    \"Sphere\":            \"dose_rate_sphere_class_\",\n",
    "    \"Circular Base\":     \"dose_rate_circular_base_class_\",\n",
    "}\n",
    "\n",
    "batch_list = find_batches(\".\")\n",
    "if not batch_list:\n",
    "    raise RuntimeError(\"No se encontraron carpetas 'output_batch_N'. Crea/coloca los datos primero.\")\n",
    "\n",
    "for batch_num in batch_list:\n",
    "    print(f\"\\n=== Batch {batch_num} — Damage Levels (time-resolved) ===\")\n",
    "\n",
    "    # Cargar/descubrir time_steps para este batch\n",
    "    time_steps = load_time_steps_for_batch(batch_num, dose_methods)\n",
    "    if time_steps.ndim != 1:\n",
    "        time_steps = np.ravel(time_steps)\n",
    "    if not np.all(np.diff(time_steps) >= 0):\n",
    "        # Garantizar orden creciente (por si acaso)\n",
    "        idx = np.argsort(time_steps)\n",
    "        time_steps = time_steps[idx]\n",
    "\n",
    "    out_levels_dir = f\"damage_levels_{batch_num}\"\n",
    "    csv_levels_dir = os.path.join(out_levels_dir, \"csv_data\")\n",
    "    os.makedirs(csv_levels_dir, exist_ok=True)\n",
    "\n",
    "    max_t = float(time_steps.max())\n",
    "    segments = [(t, EQ) for t, EQ in eq_data if t <= max_t]\n",
    "    if not segments:\n",
    "        # Si todas las EQ quedan por encima de max_t, al menos usa el primer tramo.\n",
    "        segments = [eq_data[0]]\n",
    "\n",
    "    accumulated = {}\n",
    "\n",
    "    # ===============================================\n",
    "    # LOAD OR GENERATE TOTAL ACCUMULATED DOSES\n",
    "    # ===============================================\n",
    "    plots_dir = os.path.join(f\"output_batch_{batch_num}\", \"dose_rate_plots\")\n",
    "\n",
    "    for label, prefix in dose_methods.items():\n",
    "        total_csv = os.path.join(plots_dir, f\"total_accumulated_{label.replace(' ', '_')}.csv\")\n",
    "\n",
    "        if os.path.exists(total_csv):\n",
    "            # solo la columna de dosis acumulada\n",
    "            data = np.loadtxt(total_csv, delimiter=',', skiprows=1, usecols=1)\n",
    "            # si el fichero trae tiempos distintos, re-usa los 'time_steps' ya cargados\n",
    "            accumulated[label] = np.asarray(data, dtype=float)\n",
    "        else:\n",
    "            # construir total acumulado sumando clases 1..9\n",
    "            cum_sum = np.zeros(len(time_steps), dtype=float)\n",
    "            for class_num in range(1, 10):\n",
    "                file_i = os.path.join(plots_dir, f\"{prefix}{class_num}.csv\")\n",
    "                if not os.path.exists(file_i):\n",
    "                    raise FileNotFoundError(f\"Missing {file_i}\")\n",
    "\n",
    "                arr = np.loadtxt(file_i, delimiter=',', skiprows=1)\n",
    "                # Verificar que el eje temporal coincide; si no, interpolar\n",
    "                t_i = arr[:, 0].astype(float)\n",
    "                vals = arr[:, 1:].astype(float)  # columnas de tasas por isótopos de la clase\n",
    "                # Convertir a dosis por paso en rads: suma de columnas y dividir entre 3600 (si eran rads/h)\n",
    "                step = vals.sum(axis=1) / 3600.0\n",
    "\n",
    "                if len(t_i) != len(time_steps) or np.max(np.abs(t_i - time_steps)) > 1e-6:\n",
    "                    # Interpolar sobre el eje común 'time_steps'\n",
    "                    step = np.interp(time_steps, t_i, step)\n",
    "\n",
    "                cum = np.cumsum(step)\n",
    "                cum_sum += cum\n",
    "\n",
    "            # Guardar CSV total\n",
    "            with open(total_csv, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time (s)\", \"Accumulated_Dose (rads)\"])\n",
    "                for t, val in zip(time_steps, cum_sum):\n",
    "                    w.writerow([float(t), float(val)])\n",
    "\n",
    "            accumulated[label] = cum_sum\n",
    "\n",
    "    # ===============================================\n",
    "    # CALCULATE TIME-RESOLVED DAMAGE LEVELS\n",
    "    # ===============================================\n",
    "    for label, dose_arr in accumulated.items():\n",
    "        key = label.replace(' ', '_').lower()\n",
    "        csv_out = os.path.join(csv_levels_dir, f\"{key}_dose_data.csv\")\n",
    "        damage_csv_out = os.path.join(csv_levels_dir, f\"{key}_damage_levels.csv\")\n",
    "        png_out = os.path.join(out_levels_dir, f\"damage_level_{key}.png\")\n",
    "\n",
    "        # --- Save accumulated dose data if not existing ---\n",
    "        if not os.path.exists(csv_out):\n",
    "            with open(csv_out, 'w', newline='') as f:\n",
    "                w = csv.writer(f)\n",
    "                w.writerow([\"Time Step (s)\", \"Accumulated Dose (rads)\"])\n",
    "                for t, val in zip(time_steps, dose_arr):\n",
    "                    w.writerow([float(t), float(val)])\n",
    "\n",
    "        # --- Initialize arrays ---\n",
    "        damage_levels_over_time = np.zeros(len(time_steps), dtype=int)\n",
    "        ratios_over_time = np.zeros(len(time_steps), dtype=float)\n",
    "        EQ_used_over_time = np.zeros(len(time_steps), dtype=float)\n",
    "\n",
    "        current_level = 1\n",
    "        segment_idx = 0\n",
    "\n",
    "        # --- Compute for each timestep ---\n",
    "        for i, t in enumerate(time_steps):\n",
    "            while segment_idx + 1 < len(segments) and t >= segments[segment_idx + 1][0]:\n",
    "                segment_idx += 1\n",
    "\n",
    "            EQ = segments[segment_idx][1]\n",
    "            EQ_used_over_time[i] = EQ\n",
    "            acc_dose = dose_arr[i]\n",
    "\n",
    "            level, ratio, _ = calculate_damage_level(acc_dose, EQ, current_level)\n",
    "            current_level = level\n",
    "            damage_levels_over_time[i] = level\n",
    "            ratios_over_time[i] = ratio\n",
    "\n",
    "        # --- Save detailed CSV ---\n",
    "        with open(damage_csv_out, 'w', newline='') as f:\n",
    "            w = csv.writer(f)\n",
    "            w.writerow([\"Time (s)\", \"Accumulated Dose (rads)\", \"EQ (rads)\", \"Ratio\", \"Damage Level\"])\n",
    "            for t, dose, EQ, ratio, lvl in zip(time_steps, dose_arr, EQ_used_over_time, ratios_over_time, damage_levels_over_time):\n",
    "                w.writerow([float(t), float(dose), float(EQ), float(ratio), int(lvl)])\n",
    "\n",
    "        # --- Plot ---\n",
    "        plt.figure(figsize=(8, 4))\n",
    "        x_hours = time_steps / 3600.0\n",
    "        plt.plot(x_hours, damage_levels_over_time, drawstyle='steps-post', linewidth=2.5, marker='o', markersize=4)\n",
    "        plt.title(f\"Damage Levels — {label} (Batch {batch_num})\")\n",
    "        plt.xlabel(\"Time (hours)\")\n",
    "        plt.ylabel(\"Damage Level (1–5)\")\n",
    "        plt.ylim(1, 6)\n",
    "        plt.yticks([1, 2, 3, 4, 5])\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(png_out, dpi=150)\n",
    "        plt.close()\n",
    "\n",
    "        print(f\"[{label}] Final Level = {damage_levels_over_time[-1]} | Max Ratio = {ratios_over_time.max():.2f}\")\n",
    "\n",
    "        # ============================================================\n",
    "        # ADDITION: COPY SPHERE DAMAGE LEVELS CSVs TO CURRENT FOLDER\n",
    "        # ============================================================\n",
    "        if label == \"Sphere\" and batch_num in [1, 4, 5, 7]:\n",
    "            dest_filename = f\"sphere_damage_levels_{batch_num}.csv\"\n",
    "            dest_path = os.path.join(os.getcwd(), dest_filename)\n",
    "            try:\n",
    "                import shutil\n",
    "                shutil.copyfile(damage_csv_out, dest_path)\n",
    "                print(f\"→ Copied Sphere CSV for Batch {batch_num} to current directory as '{dest_filename}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"[WARNING] Could not copy Sphere CSV for Batch {batch_num}: {e}\")\n",
    "\n",
    "    print(f\"[Batch {batch_num}] Damage Levels generated! ✅\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fbe4401",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# ============================\n",
    "# 1) Import the level CSV files\n",
    "# ============================\n",
    "df1 = pd.read_csv(\"sphere_damage_levels_1.csv\")\n",
    "df4 = pd.read_csv(\"sphere_damage_levels_4.csv\")\n",
    "df5 = pd.read_csv(\"sphere_damage_levels_5.csv\")\n",
    "df7 = pd.read_csv(\"sphere_damage_levels_7.csv\")\n",
    "\n",
    "# ===================================\n",
    "# 2) Instrumentation to location definition\n",
    "# ===================================\n",
    "instrumentation_by_location = {\n",
    "    \"WETWELL\": [\"Suppression Pool Thermocouples\"],\n",
    "    \"DRYWELL\": [\n",
    "        \"SRV Position Indicators\",\n",
    "        \"Radiation Detectors in Containment\",\n",
    "        \"Boron Injection Pressure Transmitters\",\n",
    "        \"Boron Tank Level Transmitter\",\n",
    "        \"Drywell Pressure Transmitters\",\n",
    "        \"Containment Pressure Transmitters\",\n",
    "        \"Containment Thermocouples\",\n",
    "        \"Vessel Level (Wide Range)\",\n",
    "        \"Vessel Level (Fuel Range)\",\n",
    "        \"Vessel Pressure Transmitters\",\n",
    "        \"Feedwater Flow Transmitters\",\n",
    "        \"Drywell Thermocouples\",\n",
    "        \"Radiation Detectors in Drywell\",\n",
    "        \"Control Rods Position\",\n",
    "    ],\n",
    "    \"LOWER_HEAD\": [\"Vessel Thermocouples (Lower Head)\", \"FW Thermocouples\"],\n",
    "    \"DOME\": [\"Vessel Thermocouples (Upper Head)\"],\n",
    "    \"RECIRCULATION_PUMPS\": [\n",
    "        \"Suction Pipes Thermocouples\",\n",
    "        \"Recirculation Flow Transmitters\",\n",
    "        \"Recirculation Pressure Transmitters\",\n",
    "    ],\n",
    "    \"ANNULUS\": [\"Average Reactor Power Monitors\"],\n",
    "    \"AUXILIARY_BUILDING\": [\n",
    "        \"Containment Hydrogen Concentration Analyzer\",\n",
    "        \"Drywell Hydrogen Concentration Analyzer\",\n",
    "        \"Feedwater Pressure Transmitters\",\n",
    "        \"HPCS Flow Transmitter\",\n",
    "        \"Suppression Pool Level Transmitters\",\n",
    "    ],\n",
    "    \"FUEL_BUILDING\": [],\n",
    "}\n",
    "\n",
    "# =================================\n",
    "# 3) Link the location to level CSV files\n",
    "# =================================\n",
    "level_map = {\n",
    "    \"WETWELL\": 4,\n",
    "    \"DRYWELL\": 7,\n",
    "    \"LOWER_HEAD\": 1,\n",
    "    \"DOME\": 1,\n",
    "    \"RECIRCULATION_PUMPS\": 1,\n",
    "    \"ANNULUS\": 1,\n",
    "    \"AUXILIARY_BUILDING\": 5,\n",
    "    \"FUEL_BUILDING\": 5,\n",
    "}\n",
    "\n",
    "# ==============================\n",
    "# 4) CSV to dict conversion\n",
    "# ==============================\n",
    "level_df_map = {\n",
    "    1: df1.to_dict(orient=\"records\"),\n",
    "    4: df4.to_dict(orient=\"records\"),\n",
    "    5: df5.to_dict(orient=\"records\"),\n",
    "    7: df7.to_dict(orient=\"records\"),\n",
    "}\n",
    "\n",
    "# ===================================================\n",
    "# 5) Link instrument with damage level\n",
    "# ===================================================\n",
    "damage_by_instrument = {}\n",
    "for location, instruments in instrumentation_by_location.items():\n",
    "    level = level_map[location]\n",
    "    damage_data = level_df_map[level]\n",
    "    for instr in instruments:\n",
    "        damage_by_instrument[instr] = damage_data\n",
    "\n",
    "# =========================================================\n",
    "# 6) Actions and Guides\n",
    "# =========================================================\n",
    "actions_library = {\n",
    "    \"G1_BREACH_IN_VESSEL\": {\n",
    "        \"TEMPERATURE DRYWELL\": [\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"PRESSURE DRYWELL\": [\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitters\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\",\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G2_BORON_INJECTION\": {\n",
    "        \"LEVEL BORON TANK\": [\n",
    "            \"Boron Tank Level Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"G3_SPRAY\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G4_VENTING\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "    },\n",
    "    \"G5_INJECTION_RPV\": {\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"G6_INJECTION_RPV\": {\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"G7_INJECTION_PC_UP_TO_TAF\": {\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"PRESSURE SP\": [\n",
    "            \"Suppression Pool Thermocouples\",\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitters\"\n",
    "        ]\n",
    "    },\n",
    "    \"G9_SUPPORT_VENTING_VESSEL\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G10_EVIDENCES_LOCA\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"PRESSURE DRYWELL\": [\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitters\"\n",
    "        ],\n",
    "        \"SUPPRESSION POOL TEMPERATURE\": [\n",
    "            \"Suppression Pool Thermocouples\",\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G12_FLOOD_RPV_UP_TO_TAF\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"SRV POSITION\": [\"SRV Position Indicators\"],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ]\n",
    "    },\n",
    "    \"G13_SUPPORT_VENTING_RPV\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"INJECTED FLOW RPV\": [\n",
    "            \"Feedwater Flow Transmitters\",\n",
    "            \"HPCS Flow Transmitter\",\n",
    "            \"Boron Injection Pressure Transmitters\",\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\",\n",
    "            \"Feedwater Pressure Transmitters\"\n",
    "        ],\n",
    "        \"SRV POSITION\": [\"SRV Position Indicators\"],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"G14_DETERMINE_INVESSEL_RETENTION\": {\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"LEVEL RPV\": [\n",
    "            \"Vessel Level (Wide Range)\",\n",
    "            \"Vessel Level (Fuel Range)\"\n",
    "        ],\n",
    "        \"TEMPERATURE RPV\": [\n",
    "            \"Vessel Thermocouples (Upper Head)\",\n",
    "            \"Vessel Thermocouples (Lower Head)\",\n",
    "            \"FW Thermocouples\",\n",
    "            \"Suction Pipes Thermocouples\"\n",
    "        ],\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GP\": {\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ],\n",
    "        \"SRV POSITION\": [\"SRV Position Indicators\"],\n",
    "        \"PRESSURE RPV\": [\n",
    "            \"Vessel Pressure Transmitters\",\n",
    "            \"Recirculation Pressure Transmitters\"\n",
    "        ],\n",
    "        \"PRESSURE DRYWELL\": [\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitters\"\n",
    "        ]\n",
    "    },\n",
    "    \"GQ\": {\n",
    "        \"REACTOR POWER\": [\n",
    "            \"Average Reactor Power Monitors\",\n",
    "            \"Control Rods Position\"\n",
    "        ]\n",
    "    },\n",
    "    \"GT/D\": {\n",
    "        \"TEMPERATURE DRYWELL\": [\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GT/PC\": {\n",
    "        \"TEMPERATURE CONTAINMENT\": [\n",
    "            \"Containment Thermocouples\",\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GT/SP\": {\n",
    "        \"TEMPERATURE SUPPRESSION POOL\": [\n",
    "            \"Suppression Pool Thermocouples\",\n",
    "            \"Drywell Thermocouples\",\n",
    "            \"Containment Thermocouples\"\n",
    "        ]\n",
    "    },\n",
    "    \"GH/PC\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitter (Auxiliary Building)\",\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitter (Auxiliary Building)\"\n",
    "        ],\n",
    "        \"HYDROGEN CONTAINMENT\": [\n",
    "            \"Containment Hydrogen Concentration Analyzer\",\n",
    "            \"Drywell Hydrogen Concentration Analyzer\"\n",
    "        ]\n",
    "    },\n",
    "    \"GR/PC\": {\n",
    "        \"PRESSURE CONTAINMENT\": [\n",
    "            \"Containment Pressure Transmitters\",\n",
    "            \"Containment Pressure Transmitter (Auxiliary Building)\",\n",
    "            \"Drywell Pressure Transmitters\",\n",
    "            \"Drywell Pressure Transmitter (Auxiliary Building)\"\n",
    "        ],\n",
    "        \"RADIATION CONTAINMENT\": [\n",
    "            \"Radiation Detectors in Containment\",\n",
    "            \"Radiation Detectors in Drywell\"\n",
    "        ]\n",
    "    },\n",
    "    \"GL/SP\": {\n",
    "        \"LEVEL CONTAINMENT\": [\n",
    "            \"Suppression Pool Level Transmitters\",\n",
    "            \"Suppression Pool Thermocouples\"\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "actions_short = { k.split(\"_\")[0]: v for k,v in actions_library.items() }\n",
    "\n",
    "\n",
    "# SAMG1 and SAMG2\n",
    "SAMG1 = {\n",
    "    \"RC_F1\": [\"G1\", \"G3\", \"G4\", \"G5\", \"G6\", \"G7\"],\n",
    "    \"RC_F2\": [\"G12\", \"G3\", \"G4\", \"G7\", \"G9\", \"G13\"],\n",
    "    \"RC_F3\": [\"G3\", \"G4\", \"G12\"],\n",
    "    \"RC_F4\": [\"G14\", \"G3\", \"G4\", \"G6\"],\n",
    "    \"RC_F5\": [\"G3\", \"G4\", \"G5\", \"G7\", \"G14\"],\n",
    "    \"RC_Q\": [\"G1\", \"G2\", \"GQ\"],\n",
    "    \"RC_P\": [\"GP\"],\n",
    "}\n",
    "\n",
    "SAMG2 = {\n",
    "    \"DW_T\": [\"GT/D\"],\n",
    "    \"CN_T\": [\"GT/PC\"],\n",
    "    \"SP_T\": [\"GT/SP\"],\n",
    "    \"PC_P\": [\"G4\"],\n",
    "    \"PC_H\": [\"GH/PC\"],\n",
    "    \"PC_R\": [\"GR/PC\"],\n",
    "    \"SP_L\": [\"GL/SP\"],\n",
    "}\n",
    "\n",
    "# =========================================================\n",
    "# 7) Utilities functions\n",
    "# =========================================================\n",
    "def create_directory(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def _detect_interval_key(sample_records):\n",
    "    if not sample_records:\n",
    "        return \"Interval\"\n",
    "    keys = list(sample_records[0].keys())\n",
    "    lowmap = {k.lower(): k for k in keys}\n",
    "    for cand in [\"intervalo\", \"interval\"]:\n",
    "        if cand in lowmap:\n",
    "            return lowmap[cand]\n",
    "    for k in keys:\n",
    "        if \"interval\" in k.lower():\n",
    "            return k\n",
    "    return keys[0]\n",
    "\n",
    "def _detect_level_key(sample_records):\n",
    "    if not sample_records:\n",
    "        return \"Damage Level\"\n",
    "    keys = list(sample_records[0].keys())\n",
    "    lowmap = {k.lower(): k for k in keys}\n",
    "    for cand in [\"nivel de daño\", \"nivel_de_daño\", \"damage level\", \"damage_level\", \"damage\"]:\n",
    "        if cand in lowmap:\n",
    "            return lowmap[cand]\n",
    "    for k in keys:\n",
    "        kl = k.lower()\n",
    "        if \"damage\" in kl or \"daño\" in kl:\n",
    "            return k\n",
    "    return keys[-1]\n",
    "\n",
    "# === Coloca esto junto a tus utils, antes de generate_graphs ===\n",
    "ACTIONS_R_DIR = \"ACTIONS_CSV_R\"\n",
    "create_directory(ACTIONS_R_DIR)\n",
    "\n",
    "# Conjunto global para evitar duplicados entre múltiples llamadas (SAMG1_R y SAMG2_R)\n",
    "ACTIONS_SAVED = set()\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 8) Functions to build dataframes and states\n",
    "# =========================================================\n",
    "def _levels_dataframe_for_measure(instrs, damage_by_instrument, fallback_df_records):\n",
    "    sample = next((damage_by_instrument[i] for i in instrs if i in damage_by_instrument), fallback_df_records)\n",
    "    interval_key = _detect_interval_key(sample)\n",
    "    level_key = _detect_level_key(sample)\n",
    "    intervals = [r[interval_key] for r in sample]\n",
    "    data = {interval_key: intervals}\n",
    "    for instr in instrs:\n",
    "        recs = damage_by_instrument.get(instr)\n",
    "        if not recs:\n",
    "            data[instr] = [1] * len(intervals)\n",
    "            continue\n",
    "        vals_raw = [rec.get(level_key, None) for rec in recs]\n",
    "        vals = [int(v) if v is not None and str(v).strip() != \"\" else 1 for v in vals_raw]\n",
    "        if len(vals) < len(intervals):\n",
    "            vals += [vals[-1] if vals else 1] * (len(intervals) - len(vals))\n",
    "        elif len(vals) > len(intervals):\n",
    "            vals = vals[:len(intervals)]\n",
    "        data[instr] = vals\n",
    "    df = pd.DataFrame(data)\n",
    "    return interval_key, level_key, intervals, df\n",
    "\n",
    "def _availability_dataframe_for_measure(instrs, damage_by_instrument, fallback_df_records):\n",
    "    sample = next((damage_by_instrument[i] for i in instrs if i in damage_by_instrument), fallback_df_records)\n",
    "    interval_key = _detect_interval_key(sample)\n",
    "    level_key = _detect_level_key(sample)\n",
    "    intervals = [r[interval_key] for r in sample]\n",
    "    all_levels = []\n",
    "    for instr in instrs:\n",
    "        recs = damage_by_instrument.get(instr)\n",
    "        if not recs:\n",
    "            all_levels.append([1] * len(intervals))\n",
    "        else:\n",
    "            vals_raw = [rec.get(level_key, None) for rec in recs]\n",
    "            vals = [int(v) if v is not None and str(v).strip() != \"\" else 1 for v in vals_raw]\n",
    "            if len(vals) < len(intervals):\n",
    "                vals += [vals[-1] if vals else 1] * (len(intervals) - len(vals))\n",
    "            elif len(vals) > len(intervals):\n",
    "                vals = vals[:len(intervals)]\n",
    "            all_levels.append(vals)\n",
    "    states, codes = [], []\n",
    "    for i in range(len(intervals)):\n",
    "        lvls_t = [levels[i] for levels in all_levels] if all_levels else []\n",
    "        st = _classify_state_from_levels(lvls_t)\n",
    "        states.append(st)\n",
    "        codes.append(state_map[st])\n",
    "    df = pd.DataFrame({interval_key: intervals, \"state\": states, \"state_code\": codes})\n",
    "    return interval_key, intervals, df\n",
    "\n",
    "# =========================================================\n",
    "# 9) Plotting functions\n",
    "# =========================================================\n",
    "def plot_damage(instruments, damage_by_instrument, save_path, title):\n",
    "    # Tomamos una muestra para detectar claves\n",
    "    sample = next((damage_by_instrument[i] for i in instruments if i in damage_by_instrument), None)\n",
    "    if not sample:\n",
    "        return\n",
    "\n",
    "    interval_key = _detect_interval_key(sample)   # aquí detectará \"Time (s)\"\n",
    "    level_key    = _detect_level_key(sample)      # aquí detectará \"Damage Level\"\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 7), dpi=120)\n",
    "    fig.patch.set_facecolor(\"#001F3F\")\n",
    "    ax.set_facecolor(\"#001F3F\")\n",
    "\n",
    "    # Paleta sencilla y sin marcadores (muchos puntos → carísimo)\n",
    "    colors = plt.cm.tab10.colors\n",
    "\n",
    "    for idx, instr in enumerate(instruments):\n",
    "        recs = damage_by_instrument.get(instr)\n",
    "        if not recs:\n",
    "            continue\n",
    "\n",
    "        # x = tiempo real; y = nivel de daño (1..5)\n",
    "        x = np.asarray([float(r[interval_key]) for r in recs])\n",
    "        y = np.asarray([int(r.get(level_key, 1)) for r in recs], dtype=int)\n",
    "\n",
    "        # Decimado automático si hay demasiados puntos (p. ej. > 3000)\n",
    "        max_points = 3000\n",
    "        n = len(x)\n",
    "        if n > max_points:\n",
    "            step = int(np.ceil(n / max_points))\n",
    "            x = x[::step]\n",
    "            y = y[::step]\n",
    "\n",
    "        ax.plot(\n",
    "            x, y,\n",
    "            linewidth=1.5,\n",
    "            label=instr,\n",
    "            color=colors[idx % len(colors)]\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Time (s)\", color=\"white\", fontsize=14)\n",
    "    ax.set_ylabel(\"Damage Level\", color=\"white\", fontsize=14)\n",
    "    ax.set_yticks([1, 2, 3, 4, 5])\n",
    "    ax.set_yticklabels([1, 2, 3, 4, 5], color=\"white\", fontsize=12)\n",
    "    ax.set_title(title, color=\"white\", fontsize=20, pad=16)\n",
    "\n",
    "    ax.tick_params(colors=\"white\", labelsize=12)\n",
    "    ax.grid(color=\"white\", linestyle=\"--\", alpha=0.2, linewidth=1)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"white\")\n",
    "\n",
    "    # Leyenda compacta\n",
    "    leg = ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.12),\n",
    "                    ncol=min(len(instruments), 3), frameon=False, fontsize=11)\n",
    "    for txt in (leg.get_texts() if leg else []):\n",
    "        txt.set_color(\"white\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# =========================================================\n",
    "# 10) Availability functions\n",
    "# =========================================================\n",
    "state_map = {\"Good\": 0, \"Careful\": 1, \"Warning\": 2, \"Blind\": 3}\n",
    "zone_colors = {0: \"#006400\", 1: \"#CCCC00\", 2: \"#FF8C00\", 3: \"#8B0000\"}\n",
    "\n",
    "def plot_availability(measure, intervals, states, save_path):\n",
    "    # Convertimos estados a códigos 0..3\n",
    "    values = np.asarray([state_map[s] for s in states], dtype=int)\n",
    "    x = np.asarray(intervals, dtype=float)  # aquí será \"Time (s)\"\n",
    "\n",
    "    # Decimado automático (mismo criterio)\n",
    "    max_points = 3000\n",
    "    n = len(x)\n",
    "    if n > max_points:\n",
    "        step = int(np.ceil(n / max_points))\n",
    "        x = x[::step]\n",
    "        values = values[::step]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(14, 6), dpi=120)\n",
    "    fig.patch.set_facecolor(\"#001F3F\")\n",
    "    ax.set_facecolor(\"#001F3F\")\n",
    "\n",
    "    # Bandas de fondo por zona\n",
    "    for lvl, col in zone_colors.items():\n",
    "        ax.axhspan(lvl, lvl + 1, color=col, alpha=0.25)\n",
    "\n",
    "    # Línea simple (sin marcadores)\n",
    "    ax.plot(x, values, linewidth=2, color=\"#00CED1\")\n",
    "\n",
    "    ax.set_xlabel(\"Time (s)\", color=\"white\", fontsize=14)\n",
    "    ax.set_ylabel(\"State\", color=\"white\", fontsize=14)\n",
    "    ax.set_yticks(list(state_map.values()))\n",
    "    ax.set_yticklabels(list(state_map.keys()), color=\"white\", fontsize=12)\n",
    "    ax.set_title(f\"{measure} Availability\", color=\"white\", fontsize=20, pad=16)\n",
    "\n",
    "    ax.tick_params(colors=\"white\", labelsize=12)\n",
    "    ax.grid(color=\"white\", linestyle=\"--\", alpha=0.2, linewidth=1)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"white\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=150)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "def _classify_state_from_levels(levels):\n",
    "    if not levels:\n",
    "        return \"Blind\"\n",
    "    lvls = [int(x) for x in levels if x is not None]\n",
    "    if all(l == 1 for l in lvls):\n",
    "        return \"Good\"\n",
    "    if all(l == 5 for l in lvls):\n",
    "        return \"Blind\"\n",
    "    if any(l in (3, 4) for l in lvls):\n",
    "        return \"Warning\"\n",
    "    if any(l == 2 for l in lvls) and all(l <= 2 for l in lvls):\n",
    "        return \"Careful\"\n",
    "    return \"Warning\"\n",
    "\n",
    "# =========================================================\n",
    "# 11) CSV and graphs generators\n",
    "# =========================================================\n",
    "def generate_graphs(samg_name, samg_dict, actions_map, damage_by_instrument):\n",
    "    # (todo lo que ya hacía tu función)\n",
    "    create_directory(samg_name)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(samg_name, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                base = measure.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "\n",
    "                # Construir DF (igual que antes)\n",
    "                interval_key, level_key, intervals, df_levels = _levels_dataframe_for_measure(\n",
    "                    instrs, damage_by_instrument, df1.to_dict(orient=\"records\")\n",
    "                )\n",
    "\n",
    "                # 1) Guardado ORIGINAL (igual)\n",
    "                df_levels.to_csv(os.path.join(path_code, base + \".csv\"), index=False, encoding=\"utf-8\")\n",
    "\n",
    "                # 2) Gráfico ORIGINAL (igual)\n",
    "                plot_damage(instrs, damage_by_instrument, os.path.join(path_code, base + \".png\"), measure)\n",
    "\n",
    "                # 3) NUEVO: copia única por ACTION en carpeta global, con sufijo _R\n",
    "                #    - No se repite aunque aparezca en varias G*/SAMG*\n",
    "                if base not in ACTIONS_SAVED:\n",
    "                    df_levels.to_csv(os.path.join(ACTIONS_R_DIR, base + \"_R.csv\"), index=False, encoding=\"utf-8\")\n",
    "                    ACTIONS_SAVED.add(base)\n",
    "\n",
    "\n",
    "\n",
    "def generate_availability(samg_name, samg_dict, actions_map, damage_by_instrument):\n",
    "    base = f\"Availability_{samg_name}\"\n",
    "    create_directory(base)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(base, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                safe = measure.replace(\" \", \"_\").replace(\"/\", \"_\")\n",
    "                interval_key, intervals, df_av = _availability_dataframe_for_measure(\n",
    "                    instrs, damage_by_instrument, df1.to_dict(orient=\"records\")\n",
    "                )\n",
    "                df_av.to_csv(os.path.join(path_code, safe + \"_availability.csv\"), index=False, encoding=\"utf-8\")\n",
    "                plot_availability(measure, intervals, df_av[\"state\"].tolist(), os.path.join(path_code, safe + \"_availability.png\"))\n",
    "\n",
    "# =========================================================\n",
    "# 12) Execution\n",
    "# =========================================================\n",
    "generate_graphs(\"SAMG1_R\", SAMG1, actions_short, damage_by_instrument)\n",
    "generate_graphs(\"SAMG2_R\", SAMG2, actions_short, damage_by_instrument)\n",
    "generate_availability(\"SAMG1_R\", SAMG1, actions_short, damage_by_instrument)\n",
    "generate_availability(\"SAMG2_R\", SAMG2, actions_short, damage_by_instrument)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fc8c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pypost.codes.melcor import MELCOR\n",
    "\n",
    "# =========================\n",
    "# CARGA MELCOR\n",
    "# =========================\n",
    "file_path_melcor = \"MC_Step.ptf\"\n",
    "file_index_melcor = MELCOR.openPlotFile(file_path_melcor)\n",
    "\n",
    "def cargar(var_code: str):\n",
    "    data = np.array(MELCOR.getData(file_index_melcor, var_code))\n",
    "    if data.ndim != 2 or data.shape[1] < 2:\n",
    "        raise RuntimeError(f\"Unexpected format for {var_code}: shape={data.shape}\")\n",
    "    return data[:, 0], data[:, 1]\n",
    "\n",
    "tiempo_s, TempVapor_Wetwell = cargar(\"CVH-TVAP_305\")\n",
    "\n",
    "def cargar_misma_malla(var_code: str):\n",
    "    t, v = cargar(var_code)\n",
    "    if not np.array_equal(tiempo_s, t):\n",
    "        if np.allclose(tiempo_s, t, rtol=0, atol=1e-12):\n",
    "            return v\n",
    "        raise ValueError(f\"La malla de tiempo en {var_code} no coincide con la referencia.\")\n",
    "    return v\n",
    "\n",
    "Presion_Wetwell          = cargar_misma_malla(\"CVH-P_305\")\n",
    "TempVapor_Drywell        = cargar_misma_malla(\"CVH-TVAP_201\")\n",
    "Presion_Drywell          = cargar_misma_malla(\"CVH-P_201\")\n",
    "TempVapor_CabezaSuperior = cargar_misma_malla(\"CVH-TVAP_160\")\n",
    "Presion_CabezaSuperior   = cargar_misma_malla(\"CVH-P_160\")\n",
    "TempVapor_CabezaInferior = cargar_misma_malla(\"CVH-TVAP_120\")\n",
    "Presion_CabezaInferior   = cargar_misma_malla(\"CVH-P_120\")\n",
    "TempVapor_BombaRecir     = cargar_misma_malla(\"CVH-TVAP_106\")\n",
    "Presion_BombaRecir       = cargar_misma_malla(\"CVH-P_106\")\n",
    "\n",
    "# =========================\n",
    "# CONSTANTES\n",
    "# =========================\n",
    "EQ_PRESSURE = 410000.0   # Pa\n",
    "EQ_TEMP     = 422.0      # K\n",
    "VESSEL_FAILURE = Presion_BombaRecir < 6_000_000.0  # bool array\n",
    "\n",
    "variables_melcor = {\n",
    "    \"tiempo_s\": tiempo_s,\n",
    "    \"TempVapor_Wetwell\":        TempVapor_Wetwell,\n",
    "    \"Presion_Wetwell\":          Presion_Wetwell,\n",
    "    \"TempVapor_Drywell\":        TempVapor_Drywell,\n",
    "    \"Presion_Drywell\":          Presion_Drywell,\n",
    "    \"TempVapor_CabezaSuperior\": TempVapor_CabezaSuperior,\n",
    "    \"Presion_CabezaSuperior\":   Presion_CabezaSuperior,\n",
    "    \"TempVapor_CabezaInferior\": TempVapor_CabezaInferior,\n",
    "    \"Presion_CabezaInferior\":   Presion_CabezaInferior,\n",
    "    \"TempVapor_BombaRecir\":     TempVapor_BombaRecir,\n",
    "    \"Presion_BombaRecir\":       Presion_BombaRecir,\n",
    "    \"EQ_PRESSURE\":              EQ_PRESSURE,\n",
    "    \"EQ_TEMP\":                  EQ_TEMP,\n",
    "    \"VESSEL_FAILURE\":           VESSEL_FAILURE\n",
    "}\n",
    "\n",
    "# =========================\n",
    "# UTILIDADES (histeresis, duración, constructores de niveles)\n",
    "# =========================\n",
    "def aplicar_histeresis(tiempo, niveles_condiciones, retardo_bajada_s):\n",
    "    \"\"\"\n",
    "    Subida inmediata al nivel mayor; bajada solo tras 'retardo_bajada_s' continuos cumpliendo nivel menor.\n",
    "    \"\"\"\n",
    "    out = np.zeros_like(niveles_condiciones)\n",
    "    out[0] = niveles_condiciones[0]\n",
    "    t_last = tiempo[0]\n",
    "    for i in range(1, len(tiempo)):\n",
    "        prev, want = out[i-1], niveles_condiciones[i]\n",
    "        if want > prev:\n",
    "            out[i] = want; t_last = tiempo[i]\n",
    "        elif want < prev:\n",
    "            out[i] = want if (tiempo[i] - t_last) >= retardo_bajada_s else prev\n",
    "            if out[i] == want: t_last = tiempo[i]\n",
    "        else:\n",
    "            out[i] = prev\n",
    "    return out\n",
    "\n",
    "def duracion_continua(tiempo, mask_bool):\n",
    "    dur = np.zeros_like(tiempo, dtype=float)\n",
    "    for i in range(1, len(tiempo)):\n",
    "        dur[i] = (dur[i-1] + (tiempo[i]-tiempo[i-1])) if (mask_bool[i] and mask_bool[i-1]) else (tiempo[i]-tiempo[i-1] if mask_bool[i] else 0.0)\n",
    "    return dur\n",
    "\n",
    "def niveles_base(n):\n",
    "    return np.ones(n, dtype=int)\n",
    "\n",
    "def set_or(mask_dest, mask_src, level):\n",
    "    \"\"\"Asigna 'level' donde mask_src True (sobrescribe niveles menores).\"\"\"\n",
    "    mask_dest[mask_src] = level\n",
    "\n",
    "def levels_cec(T, P, mults=((2,1.0),(3,1.5),(5,2.0)), eqT=EQ_TEMP, eqP=EQ_PRESSURE):\n",
    "    lv = niveles_base(len(T))\n",
    "    for L, m in mults:\n",
    "        set_or(lv, (T > m*eqT) | (P > m*eqP), L)\n",
    "    return lv\n",
    "\n",
    "def levels_temp_steps(T, rules):\n",
    "    \"\"\"\n",
    "    'rules' = lista ordenada de tuplas (level, cond_bool) que pisan niveles previos.\n",
    "    Ej.: [(2, T>EQ), (3, T>673), (5, T>1530)]\n",
    "    \"\"\"\n",
    "    lv = niveles_base(len(T))\n",
    "    for L, cond in rules:\n",
    "        set_or(lv, cond, L)\n",
    "    return lv\n",
    "\n",
    "def apply_and_save(name, lv_cond, delay_s):\n",
    "    lv = aplicar_histeresis(tiempo_s, lv_cond, delay_s)\n",
    "    guardar_nivel_instrumento(name, lv)\n",
    "    return lv\n",
    "\n",
    "# =========================\n",
    "# CONTENEDOR NIVELES\n",
    "# =========================\n",
    "niveles_instrumentos = {}  # { nombre: ndarray[int] }\n",
    "\n",
    "def guardar_nivel_instrumento(nombre: str, level_array: np.ndarray):\n",
    "    if level_array.shape != tiempo_s.shape:\n",
    "        raise ValueError(f\"Longitud de niveles de '{nombre}' no coincide con tiempo.\")\n",
    "    niveles_instrumentos[nombre] = level_array.astype(int, copy=False)\n",
    "\n",
    "# =========================\n",
    "# INSTRUMENTOS (compactados por patrón)\n",
    "# =========================\n",
    "\n",
    "# 1) Suppression Pool Thermocouples (Twet/Pwet): 2:CEC>EQ, 3:T>673, 5:T>1530\n",
    "T_wet, P_wet = TempVapor_Wetwell, Presion_Wetwell\n",
    "lv = levels_temp_steps(T_wet, [(2, (T_wet>EQ_TEMP)|(P_wet>EQ_PRESSURE)),\n",
    "                               (3, T_wet>673.0),\n",
    "                               (5, T_wet>1530.0)])\n",
    "apply_and_save(\"SuppressionPoolThermocouples\", lv, 1800.0)\n",
    "\n",
    "# 2) SRV Position Indicators: 2:CEC>EQ (Drywell), 5:Vessel Failure\n",
    "T_dw, P_dw = TempVapor_Drywell, Presion_Drywell\n",
    "lv = levels_temp_steps(T_dw, [(2, (T_dw>EQ_TEMP)|(P_dw>EQ_PRESSURE)),\n",
    "                              (5, VESSEL_FAILURE)])\n",
    "apply_and_save(\"SRVPositionIndicators\", lv, 1800.0)\n",
    "\n",
    "# 3) Radiation Detectors in Containment: CEC mults 1.0/1.5/2.0 (Drywell)\n",
    "lv = levels_cec(T_dw, P_dw, mults=((2,1.0),(3,1.5),(5,2.0)))\n",
    "apply_and_save(\"RadiationDetectorsContainment\", lv, 1800.0)\n",
    "\n",
    "# 4) Boron Injection Pressure Transmitters: CEC mults 1.0/1.5/2.0 (Drywell)\n",
    "lv = levels_cec(T_dw, P_dw, mults=((2,1.0),(3,1.5),(5,2.0)))\n",
    "apply_and_save(\"BoronInjectionPressureTransmitters\", lv, 1800.0)\n",
    "\n",
    "# 5) Boron Tank Level Transmitter:\n",
    "#    2:CEC>EQ; 3: 30min T_dw>422 continuos; 5: T_dw>1530\n",
    "dur_T422 = duracion_continua(tiempo_s, T_dw>422.0)\n",
    "lv = levels_temp_steps(T_dw, [(2, (T_dw>EQ_TEMP)|(P_dw>EQ_PRESSURE)),\n",
    "                              (3, dur_T422>=1800.0),\n",
    "                              (5, T_dw>1530.0)])\n",
    "apply_and_save(\"BoronTankLevelTransmitter\", lv, 1800.0)\n",
    "\n",
    "# 6) Drywell Pressure Transmitters: CEC mults 1.0/1.5/2.0\n",
    "lv = levels_cec(T_dw, P_dw, mults=((2,1.0),(3,1.5),(5,2.0)))\n",
    "apply_and_save(\"DrywellPressureTransmitters\", lv, 1800.0)\n",
    "\n",
    "# 7) Containment Pressure Transmitters: CEC mults 1.0/1.5/2.0\n",
    "lv = levels_cec(T_dw, P_dw, mults=((2,1.0),(3,1.5),(5,2.0)))\n",
    "apply_and_save(\"ContainmentPressureTransmitters\", lv, 1800.0)\n",
    "\n",
    "# 8) Containment Thermocouples (Drywell): 2:CEC>EQ; 3:T>673; 5:T>1530\n",
    "lv = levels_temp_steps(T_dw, [(2, (T_dw>EQ_TEMP)|(P_dw>EQ_PRESSURE)),\n",
    "                              (3, T_dw>673.0),\n",
    "                              (5, T_dw>1530.0)])\n",
    "apply_and_save(\"ContainmentThermocouples\", lv, 1800.0)\n",
    "\n",
    "# 9) Vessel Level (Wide Range): 2:CEC>EQ; 3:30min T_dw>422; 5:Vessel Failure\n",
    "lv = levels_temp_steps(T_dw, [(2, (T_dw>EQ_TEMP)|(P_dw>EQ_PRESSURE)),\n",
    "                              (3, dur_T422>=1800.0),\n",
    "                              (5, VESSEL_FAILURE)])\n",
    "apply_and_save(\"VesselLevelWideRange\", lv, 1800.0)\n",
    "\n",
    "# 10) Vessel Level (Fuel Range): igual que (9)\n",
    "lv = levels_temp_steps(T_dw, [(2, (T_dw>EQ_TEMP)|(P_dw>EQ_PRESSURE)),\n",
    "                              (3, dur_T422>=1800.0),\n",
    "                              (5, VESSEL_FAILURE)])\n",
    "apply_and_save(\"VesselLevelFuelRange\", lv, 1800.0)\n",
    "\n",
    "# 11) Vessel Pressure Transmitters:\n",
    "#     2: (PRCS<0.25MPa & P_dw>0.2MPa) OR CEC>EQ ; 3:30min T_dw>422 ; 5:T_dw>1530\n",
    "PRCS = Presion_BombaRecir\n",
    "cond_A = (PRCS < 250_000.0) & (P_dw > 200_000.0)\n",
    "lv = levels_temp_steps(T_dw, [(2, cond_A | ((T_dw>EQ_TEMP)|(P_dw>EQ_PRESSURE))),\n",
    "                              (3, dur_T422>=1800.0),\n",
    "                              (5, T_dw>1530.0)])\n",
    "apply_and_save(\"VesselPressureTransmitters\", lv, 1800.0)\n",
    "\n",
    "# 12) Feedwater Flow Transmitters: CEC mults 1.0/1.5/2.0\n",
    "lv = levels_cec(T_dw, P_dw, mults=((2,1.0),(3,1.5),(5,2.0)))\n",
    "apply_and_save(\"FeedwaterFlowTransmitters\", lv, 1800.0)\n",
    "\n",
    "# 13) Drywell Thermocouples: 2:CEC>EQ; 3:T>673; 5:T>1530\n",
    "lv = levels_temp_steps(T_dw, [(2, (T_dw>EQ_TEMP)|(P_dw>EQ_PRESSURE)),\n",
    "                              (3, T_dw>673.0),\n",
    "                              (5, T_dw>1530.0)])\n",
    "apply_and_save(\"DrywellThermocouples\", lv, 1800.0)\n",
    "\n",
    "# 14) Radiation Detectors in Drywell: CEC mults 1.0/1.5/2.0\n",
    "lv = levels_cec(T_dw, P_dw, mults=((2,1.0),(3,1.5),(5,2.0)))\n",
    "apply_and_save(\"RadiationDetectorsDrywell\", lv, 1800.0)\n",
    "\n",
    "# 15) Control Rods Position: 2:CEC>EQ; 5:Vessel Failure\n",
    "lv = levels_temp_steps(T_dw, [(2, (T_dw>EQ_TEMP)|(P_dw>EQ_PRESSURE)),\n",
    "                              (5, VESSEL_FAILURE)])\n",
    "apply_and_save(\"ControlRodsPosition\", lv, 1800.0)\n",
    "\n",
    "# 16) Recirculation Pressure Transmitters (P106/T106): 2/3/4 por umbrales; 5 por VF\n",
    "P106, T106 = Presion_BombaRecir, TempVapor_BombaRecir\n",
    "lv = niveles_base(len(tiempo_s))\n",
    "for L, p_thr, t_thr in [(2, 8_000_000.0,  573.0),\n",
    "                        (3,12_000_000.0,1100.0),\n",
    "                        (4,17_200_000.0,1530.0)]:\n",
    "    set_or(lv, (P106>p_thr)|(T106>t_thr), L)\n",
    "set_or(lv, VESSEL_FAILURE, 5)\n",
    "apply_and_save(\"RecirculationPressureTransmitters\", lv, 10000.0)\n",
    "\n",
    "# 17) Recirculation Flow Transmitters (P106/T106): idéntico a (16)\n",
    "lv = niveles_base(len(tiempo_s))\n",
    "for L, p_thr, t_thr in [(2, 8_000_000.0,  573.0),\n",
    "                        (3,12_000_000.0,1100.0),\n",
    "                        (4,17_200_000.0,1530.0)]:\n",
    "    set_or(lv, (P106>p_thr)|(T106>t_thr), L)\n",
    "set_or(lv, VESSEL_FAILURE, 5)\n",
    "apply_and_save(\"RecirculationFlowTransmitters\", lv, 10000.0)\n",
    "\n",
    "# 18) Average Reactor Power Monitors: 2:CEC>EQ; 5:Vessel Failure\n",
    "lv = levels_temp_steps(T_dw, [(2, (T_dw>EQ_TEMP)|(P_dw>EQ_PRESSURE)),\n",
    "                              (5, VESSEL_FAILURE)])\n",
    "apply_and_save(\"AverageReactorPowerMonitors\", lv, 1800.0)\n",
    "\n",
    "# 19) Vessel Thermocouples Upper Head (rangos)\n",
    "T_uh = TempVapor_CabezaSuperior\n",
    "lv = niveles_base(len(tiempo_s))\n",
    "for L, cond in [(2, (T_uh>645.0) & (T_uh<873.0)),\n",
    "                (3, (T_uh>923.0) & (T_uh<1173.0)),\n",
    "                (4, (T_uh>1173.0)& (T_uh<1530.0)),\n",
    "                (5,  T_uh>1570.0)]:\n",
    "    set_or(lv, cond, L)\n",
    "apply_and_save(\"VesselThermocouplesUpperHead\", lv, 1800.0)\n",
    "\n",
    "# 20) Vessel Thermocouples Lower Head (rangos; 5 por VF)\n",
    "T_lh = TempVapor_CabezaInferior\n",
    "lv = niveles_base(len(tiempo_s))\n",
    "for L, cond in [(2, (T_lh>645.0) & (T_lh<873.0)),\n",
    "                (3, (T_lh>923.0) & (T_lh<1173.0)),\n",
    "                (4, (T_lh>1173.0)& (T_lh<1530.0))]:\n",
    "    set_or(lv, cond, L)\n",
    "set_or(lv, VESSEL_FAILURE, 5)\n",
    "apply_and_save(\"VesselThermocouplesLowerHead\", lv, 20000.0)\n",
    "\n",
    "# 21) FW Thermocouples (Tcore = Cabeza Inferior): 2:[645,873), 4:[873,1530), 5:>1570\n",
    "Tcore = TempVapor_CabezaInferior\n",
    "lv = niveles_base(len(tiempo_s))\n",
    "for L, cond in [(2, (Tcore>645.0) & (Tcore<873.0)),\n",
    "                (4, (Tcore>873.0) & (Tcore<1530.0)),\n",
    "                (5,  Tcore>1570.0)]:\n",
    "    set_or(lv, cond, L)\n",
    "apply_and_save(\"FWThermocouples\", lv, 25000.0)\n",
    "\n",
    "# 22) Suction Pipes Thermocouples (T106): 2/3/4 por rangos; 5:>1570\n",
    "lv = niveles_base(len(tiempo_s))\n",
    "for L, cond in [(2, (T106>645.0)  & (T106<873.0)),\n",
    "                (3, (T106>923.0)  & (T106<1173.0)),\n",
    "                (4, (T106>1173.0) & (T106<1530.0)),\n",
    "                (5,  T106>1570.0)]:\n",
    "    set_or(lv, cond, L)\n",
    "apply_and_save(\"SuctionPipesThermocouples\", lv, 100000.0)\n",
    "\n",
    "# =========================\n",
    "# EXPORTACIÓN (idéntica a la tuya)\n",
    "# =========================\n",
    "def exportar_niveles_y_graficas(niveles_instrumentos: dict, tiempo_s: np.ndarray,\n",
    "                                carpeta_csv: str = \"csv_niveles\",\n",
    "                                carpeta_figs: str = \"graficas_niveles\"):\n",
    "    os.makedirs(carpeta_csv, exist_ok=True)\n",
    "    os.makedirs(carpeta_figs, exist_ok=True)\n",
    "    for nombre, niveles in niveles_instrumentos.items():\n",
    "        if niveles.shape != tiempo_s.shape:\n",
    "            print(f\"[ADVERTENCIA] Longitud diferente en '{nombre}': tiempo={tiempo_s.shape}, niveles={niveles.shape}. Se omite.\")\n",
    "            continue\n",
    "        safe = \"\".join(c if c.isalnum() or c in (\"_\", \"-\") else \"_\" for c in nombre)\n",
    "        # CSV\n",
    "        pd.DataFrame({\"tiempo_s\": tiempo_s, \"nivel\": niveles.astype(int)}).to_csv(\n",
    "            os.path.join(carpeta_csv, f\"{safe}_niveles.csv\"), index=False\n",
    "        )\n",
    "        # Gráfica\n",
    "        plt.figure()\n",
    "        plt.step(tiempo_s, niveles, where=\"post\")\n",
    "        plt.xlabel(\"Tiempo [s]\"); plt.ylabel(\"Nivel de daño (1–5)\")\n",
    "        plt.title(f\"{nombre} – Nivel (1–5)\")\n",
    "        plt.yticks([1, 2, 3, 4, 5]); plt.ylim(0.8, 5.2); plt.grid(True); plt.tight_layout()\n",
    "        ruta_png = os.path.join(carpeta_figs, f\"{safe}_niveles.png\")\n",
    "        plt.savefig(ruta_png, dpi=200); plt.close()\n",
    "        print(f\"Guardado CSV: {os.path.join(carpeta_csv, f'{safe}_niveles.csv')}\")\n",
    "        print(f\"Guardada gráfica: {ruta_png}\")\n",
    "\n",
    "exportar_niveles_y_graficas(niveles_instrumentos, tiempo_s)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7fd9ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ No encontrado: FeedwaterPressureTransmitters_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: SuppressionPoolLevelTransmitters_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: HPCSFlowTransmitter_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: ContainmentHydrogenAnalyzer_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: DrywellHydrogenAnalyzer_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: ContainmentPressureTransmitterAux_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n",
      "⚠ No encontrado: DrywellPressureTransmitterAux_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ============================================================\n",
    "# CONFIGURACIÓN\n",
    "# ============================================================\n",
    "carpeta = Path(\"csv_niveles\")\n",
    "\n",
    "state_order = {'Good':0, 'Careful':1, 'Warning':2, 'Blind':3}\n",
    "\n",
    "ACTIONS_PyT_DIR = \"ACTIONS_CSV_PyT\"\n",
    "os.makedirs(ACTIONS_PyT_DIR, exist_ok=True)\n",
    "ACTIONS_PyT_SAVED = set()  # para evitar duplicados entre SAMG1_PyT y SAMG2_PyT\n",
    "\n",
    "# ============================================================\n",
    "# MAPEO CSV POR INSTRUMENTO\n",
    "# ============================================================\n",
    "instrument_to_csv = {\n",
    "    \"Average Reactor Power Monitors\": \"AverageReactorPowerMonitors\",\n",
    "    \"Boron Injection Pressure Transmitters\": \"BoronInjectionPressureTransmitters\",\n",
    "    \"Boron Tank Level Transmitter\": \"BoronTankLevelTransmitter\",\n",
    "    \"Containment Pressure Transmitters\": \"ContainmentPressureTransmitters\",\n",
    "    \"Containment Thermocouples\": \"ContainmentThermocouples\",\n",
    "    \"Control Rods Position\": \"ControlRodsPosition\",\n",
    "    \"Drywell Pressure Transmitters\": \"DrywellPressureTransmitters\",\n",
    "    \"Drywell Thermocouples\": \"DrywellThermocouples\",\n",
    "    \"Feedwater Flow Transmitters\": \"FeedwaterFlowTransmitters\",\n",
    "    \"Feedwater Pressure Transmitters\": \"FeedwaterPressureTransmitters\",\n",
    "    \"FW Thermocouples\": \"FWThermocouples\",\n",
    "    \"Radiation Detectors in Containment\": \"RadiationDetectorsContainment\",\n",
    "    \"Radiation Detectors in Drywell\": \"RadiationDetectorsDrywell\",\n",
    "    \"Recirculation Flow Transmitters\": \"RecirculationFlowTransmitters\",\n",
    "    \"Recirculation Pressure Transmitters\": \"RecirculationPressureTransmitters\",\n",
    "    \"SRV Position Indicators\": \"SRVPositionIndicators\",\n",
    "    \"Suction Pipes Thermocouples\": \"SuctionPipesThermocouples\",\n",
    "    \"Suppression Pool Thermocouples\": \"SuppressionPoolThermocouples\",  # base 'pp'\n",
    "    \"Suppression Pool Level Transmitters\": \"SuppressionPoolLevelTransmitters\",\n",
    "    \"Vessel Level (Fuel Range)\": \"VesselLevelFuelRange\",\n",
    "    \"Vessel Level (Wide Range)\": \"VesselLevelWideRange\",\n",
    "    \"Vessel Pressure Transmitters\": \"VesselPressureTransmitters\",\n",
    "    \"Vessel Thermocouples (Lower Head)\": \"VesselThermocouplesLowerHead\",\n",
    "    \"Vessel Thermocouples (Upper Head)\": \"VesselThermocouplesUpperHead\",\n",
    "    \"HPCS Flow Transmitter\": \"HPCSFlowTransmitter\",\n",
    "    \"Containment Hydrogen Concentration Analyzer\": \"ContainmentHydrogenAnalyzer\",\n",
    "    \"Drywell Hydrogen Concentration Analyzer\": \"DrywellHydrogenAnalyzer\",\n",
    "    # Opcionales si existen CSV:\n",
    "    \"Containment Pressure Transmitter (Auxiliary Building)\": \"ContainmentPressureTransmitterAux\",\n",
    "    \"Drywell Pressure Transmitter (Auxiliary Building)\": \"DrywellPressureTransmitterAux\",\n",
    "}\n",
    "\n",
    "# Alias (por si aparecen variantes de escritura)\n",
    "name_aliases = {\n",
    "    \"Suppression Pool Thermocouples\": \"Supression Pool Thermocouples\",\n",
    "    \"Suppression Pool Level Transmitters\": \"Suppresion Pool Level Transmitters\",\n",
    "}\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# UTILIDADES\n",
    "# ============================================================\n",
    "def _canon(s: str) -> str:\n",
    "    return \"\".join(ch.lower() for ch in s if ch.isalnum())\n",
    "\n",
    "def resolve_instrument_name(name: str, available: dict) -> str | None:\n",
    "    name = name_aliases.get(name, name)\n",
    "    if name in available:\n",
    "        return name\n",
    "    idx = { _canon(k): k for k in available.keys() }\n",
    "    return idx.get(_canon(name))\n",
    "\n",
    "def leer_csv_flexible(path: Path) -> pd.DataFrame:\n",
    "    \"\"\"Lee CSV con separador auto (, ; \\t) y devuelve DF con columnas 'tiempo_s','nivel'.\"\"\"\n",
    "    seps = [\",\",\";\",\"\\t\",\"|\"]\n",
    "    last_err = None\n",
    "    for sep in seps:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=sep)\n",
    "            if df.shape[1] < 1:\n",
    "                continue\n",
    "            # limpiar columnas unnamed\n",
    "            df = df.loc[:, ~df.columns.astype(str).str.startswith(\"Unnamed\")]\n",
    "            cols = [c.lower().strip() for c in df.columns.astype(str)]\n",
    "\n",
    "            # Caso NUEVO (ancho): columnas tiempo_s, nivel\n",
    "            if \"tiempo_s\" in cols and \"nivel\" in cols:\n",
    "                tcol = df.columns[cols.index(\"tiempo_s\")]\n",
    "                ncol = df.columns[cols.index(\"nivel\")]\n",
    "                out = df[[tcol,ncol]].rename(columns={tcol:\"tiempo_s\", ncol:\"nivel\"}).copy()\n",
    "                out[\"tiempo_s\"] = pd.to_numeric(out[\"tiempo_s\"], errors=\"coerce\")\n",
    "                out[\"nivel\"]    = pd.to_numeric(out[\"nivel\"], errors=\"coerce\")\n",
    "                out = out.dropna(subset=[\"tiempo_s\",\"nivel\"])\n",
    "                out[\"nivel\"] = out[\"nivel\"].round().clip(1,5).astype(int)\n",
    "                out = out.sort_values(\"tiempo_s\").reset_index(drop=True)\n",
    "                return out\n",
    "\n",
    "            # Caso ANTIGUO (largo): Intervalo / Nivel de Daño\n",
    "            if \"intervalo\" in cols and \"nivel de daño\" in cols:\n",
    "                icol = df.columns[cols.index(\"intervalo\")]\n",
    "                lcol = df.columns[cols.index(\"nivel de daño\")]\n",
    "                tmp = df[[icol,lcol]].rename(columns={icol:\"Intervalo\", lcol:\"Nivel de Daño\"}).copy()\n",
    "                tmp[\"Intervalo\"] = tmp[\"Intervalo\"].astype(str)\n",
    "                tmp[\"Nivel de Daño\"] = pd.to_numeric(tmp[\"Nivel de Daño\"], errors=\"coerce\").fillna(1).astype(int).clip(1,5)\n",
    "                # inventamos tiempo_s como 0,1,2,... (pasos)\n",
    "                out = pd.DataFrame({\n",
    "                    \"tiempo_s\": np.arange(len(tmp), dtype=float),\n",
    "                    \"nivel\": tmp[\"Nivel de Daño\"].to_numpy(int)\n",
    "                })\n",
    "                return out\n",
    "\n",
    "            # Si tiene dos columnas cualesquiera, intentamos mapear a tiempo,nivel por posición\n",
    "            if df.shape[1] >= 2:\n",
    "                out = df.iloc[:, :2].copy()\n",
    "                out.columns = [\"tiempo_s\",\"nivel\"]\n",
    "                out[\"tiempo_s\"] = pd.to_numeric(out[\"tiempo_s\"], errors=\"coerce\")\n",
    "                out[\"nivel\"]    = pd.to_numeric(out[\"nivel\"], errors=\"coerce\")\n",
    "                out = out.dropna(subset=[\"tiempo_s\",\"nivel\"])\n",
    "                out[\"nivel\"] = out[\"nivel\"].round().clip(1,5).astype(int)\n",
    "                out = out.sort_values(\"tiempo_s\").reset_index(drop=True)\n",
    "                return out\n",
    "\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            continue\n",
    "    # Si no pudimos leer, relanza último error\n",
    "    raise last_err if last_err else RuntimeError(f\"No se pudo leer {path}\")\n",
    "\n",
    "# ====== NUEVO: utilidades para construir y guardar CSV ======\n",
    "def _levels_dataframe(instrs):\n",
    "    \"\"\"\n",
    "    Devuelve (t_ref, df) donde df contiene 'tiempo_s' y,\n",
    "    por cada instrumento, una columna con su nivel remuestreado (1..5).\n",
    "    \"\"\"\n",
    "    t_ref = _reference_time(instrs)\n",
    "    data = {\"tiempo_s\": t_ref}\n",
    "    for i_name in instrs:\n",
    "        resolved = resolve_instrument_name(i_name, damage_by_instrument) or i_name\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        y = _resample_to_reference(df, t_ref)\n",
    "        data[resolved] = y.astype(int)\n",
    "    out = pd.DataFrame(data)\n",
    "    return t_ref, out\n",
    "\n",
    "def _availability_dataframe(instrs):\n",
    "    \"\"\"\n",
    "    Calcula availability y devuelve (t_ref, df) con columnas:\n",
    "    'tiempo_s', 'state', 'state_code' (0..3).\n",
    "    \"\"\"\n",
    "    t_ref = _reference_time(instrs)\n",
    "    levels = []\n",
    "    for i_name in instrs:\n",
    "        resolved = resolve_instrument_name(i_name, damage_by_instrument) or i_name\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        y = _resample_to_reference(df, t_ref)\n",
    "        levels.append(y.astype(int))\n",
    "\n",
    "    states, codes = [], []\n",
    "    for i in range(len(t_ref)):\n",
    "        lvls_t = [int(arr[i]) for arr in levels]\n",
    "        st = determine_state_from_levels(lvls_t)\n",
    "        states.append(st)\n",
    "        codes.append(state_order[st])\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        \"tiempo_s\": t_ref,\n",
    "        \"state\": states,\n",
    "        \"state_code\": np.array(codes, dtype=int)\n",
    "    })\n",
    "    return t_ref, df\n",
    "# ============================================================\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# CARGA TODOS LOS INSTRUMENTOS + TIEMPO DE REFERENCIA\n",
    "# ============================================================\n",
    "raw_data = {}\n",
    "ref_time = None\n",
    "\n",
    "for visible_name, base in instrument_to_csv.items():\n",
    "    ruta = carpeta / f\"{base}_niveles.csv\"\n",
    "    if ruta.exists():\n",
    "        df = leer_csv_flexible(ruta)\n",
    "        raw_data[visible_name] = df\n",
    "        if ref_time is None and not df.empty:\n",
    "            ref_time = df[\"tiempo_s\"].to_numpy()\n",
    "    else:\n",
    "        # se rellena luego con fallback\n",
    "        pass\n",
    "\n",
    "# Si no hay ningún CSV real, inventamos ref_time\n",
    "if ref_time is None:\n",
    "    ref_time = np.arange(100, dtype=float)  # 100 puntos por defecto\n",
    "\n",
    "# Completar faltantes con nivel=1 y mismo eje temporal\n",
    "for visible_name, base in instrument_to_csv.items():\n",
    "    if visible_name not in raw_data:\n",
    "        print(f\"⚠ No encontrado: {base}_niveles.csv → se asigna nivel=1 con la malla temporal de referencia\")\n",
    "        raw_data[visible_name] = pd.DataFrame({\n",
    "            \"tiempo_s\": ref_time,\n",
    "            \"nivel\": np.ones_like(ref_time, dtype=int)\n",
    "        })\n",
    "\n",
    "# ============================================================\n",
    "# PREPARACIÓN DE ESTRUCTURAS\n",
    "# ============================================================\n",
    "damage_by_instrument = {name: df for name, df in raw_data.items()}\n",
    "\n",
    "# ============================================================\n",
    "# LÓGICA AVAILABILITY (tu regla)\n",
    "# ============================================================\n",
    "def determine_state_from_levels(lvls: list[int]) -> str:\n",
    "    if all(l == 1 for l in lvls):\n",
    "        return 'Good'\n",
    "    if any(l == 2 for l in lvls) and all(l <= 2 for l in lvls):\n",
    "        return 'Careful'\n",
    "    if all(l == 5 for l in lvls):\n",
    "        return 'Blind'\n",
    "    if any(l in (3,4) for l in lvls):\n",
    "        return 'Warning'\n",
    "    return 'Warning'\n",
    "\n",
    "# ============================================================\n",
    "# PLOTS\n",
    "# ============================================================\n",
    "def create_directory(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def _reference_time(instruments):\n",
    "    \"\"\"Devuelve el vector tiempo_s de referencia (el del primer instrumento con datos).\"\"\"\n",
    "    for instr in instruments:\n",
    "        resolved = resolve_instrument_name(instr, damage_by_instrument) or instr\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        if df is not None and not df.empty:\n",
    "            return df[\"tiempo_s\"].to_numpy()\n",
    "    return ref_time\n",
    "\n",
    "def _resample_to_reference(df: pd.DataFrame, t_ref: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Ajusta la serie (tiempo_s, nivel) al eje temporal t_ref:\n",
    "    - si longitudes coinciden y tiempos iguales ≈: devuelve niveles tal cual\n",
    "    - si difiere, interpola 'nearest' por escalón (usamos pandas merge_asof).\n",
    "    \"\"\"\n",
    "    if df is None or df.empty:\n",
    "        return np.ones_like(t_ref, dtype=int)\n",
    "    src_t = df[\"tiempo_s\"].to_numpy()\n",
    "    src_y = df[\"nivel\"].to_numpy(int)\n",
    "\n",
    "    if len(src_t) == len(t_ref) and np.allclose(src_t, t_ref, rtol=0, atol=1e-9):\n",
    "        return src_y\n",
    "\n",
    "    # merge_asof para asignar al tiempo de referencia el nivel más cercano (look-up tipo nearest)\n",
    "    a = pd.DataFrame({\"t\": t_ref})\n",
    "    b = pd.DataFrame({\"t\": src_t, \"y\": src_y}).sort_values(\"t\")\n",
    "    out = pd.merge_asof(a.sort_values(\"t\"), b, on=\"t\", direction=\"nearest\")\n",
    "    y = out[\"y\"].fillna(1).round().clip(1,5).astype(int).to_numpy()\n",
    "    return y\n",
    "\n",
    "def plot_damage(instruments, save_path, title):\n",
    "    t_ref = _reference_time(instruments)\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), dpi=100)\n",
    "    fig.patch.set_facecolor('#001F3F')\n",
    "    ax.set_facecolor('#001F3F')\n",
    "\n",
    "    markers = ['o','s','D','^','v','P','X','*','<','>']\n",
    "    for idx, instr in enumerate(instruments):\n",
    "        resolved = resolve_instrument_name(instr, damage_by_instrument) or instr\n",
    "        df = damage_by_instrument.get(resolved)\n",
    "        y = _resample_to_reference(df, t_ref)\n",
    "        jitter = (idx - len(instruments)/2) * 0.05\n",
    "        ax.plot(\n",
    "            t_ref, y + jitter,\n",
    "            marker=markers[idx % len(markers)],\n",
    "            markersize=6,\n",
    "            linewidth=1.8,\n",
    "            label=resolved,\n",
    "            markevery=max(1, len(t_ref)//20)\n",
    "        )\n",
    "\n",
    "    ax.set_xlabel(\"Time (s)\", color='white', fontsize=20)\n",
    "    ax.set_ylabel(\"Damage Level\", color='white', fontsize=20)\n",
    "    ax.set_yticks([1,2,3,4,5])\n",
    "    ax.set_yticklabels([1,2,3,4,5], color='white', fontsize=18)\n",
    "    ax.tick_params(colors='white', labelsize=16)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('white')\n",
    "    ax.grid(color='white', linestyle='--', alpha=0.2, linewidth=1)\n",
    "    ax.set_title(title, color='white', fontsize=28, pad=24)\n",
    "\n",
    "    # leyenda abajo\n",
    "    leg_cols = len(instruments) if len(instruments) <= 2 else (len(instruments)+1)//2\n",
    "    leg = ax.legend(\n",
    "        loc='upper center', bbox_to_anchor=(0.5, -0.12),\n",
    "        ncol=max(1, leg_cols), frameon=False, fontsize=14\n",
    "    )\n",
    "    for txt in leg.get_texts():\n",
    "        txt.set_color('white')\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.25)\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "def plot_availability(measure, t_ref, states, save_path):\n",
    "    import numpy as np\n",
    "    values = np.array([state_order[s] for s in states], dtype=int)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, 8), dpi=100)\n",
    "    fig.patch.set_facecolor('#001F3F')\n",
    "    ax.set_facecolor('#001F3F')\n",
    "\n",
    "    # bandas por estado (Good/Careful/Warning/Blind)\n",
    "    bands = {0:'#2E7D32', 1:'#F9A825', 2:'#EF6C00', 3:'#B71C1C'}\n",
    "    for lvl, col in bands.items():\n",
    "        ax.axhspan(lvl, lvl+1, color=col, alpha=0.25)\n",
    "\n",
    "    # línea escalonada (mismo estilo que daño)\n",
    "    ax.plot(t_ref, values, drawstyle='steps-post', marker='o',\n",
    "            markersize=6, linewidth=1.8)\n",
    "\n",
    "    # === Igualamos estilo de ejes al de \"daño\" ===\n",
    "    ax.set_xlabel(\"Time (s)\", color='white', fontsize=20)\n",
    "    ax.set_ylabel(\"\", color='white', fontsize=20)  # sin etiqueta textual\n",
    "    ax.set_yticks([0,1,2,3])\n",
    "    ax.set_yticklabels(list(state_order.keys()), color='white', fontsize=18)\n",
    "\n",
    "    # ¡NO fijamos los xticks! (dejamos el auto-locator como en daño)\n",
    "    ax.tick_params(colors='white', labelsize=16)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor('white')\n",
    "    ax.grid(color='white', linestyle='--', alpha=0.2, linewidth=1)\n",
    "    ax.set_title(f\"{measure} Availability\", color='white', fontsize=28, pad=24)\n",
    "\n",
    "    fig.subplots_adjust(bottom=0.25)\n",
    "    plt.savefig(save_path, facecolor=fig.get_facecolor(), dpi=300)\n",
    "    plt.close(fig)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# GENERACIÓN DE SALIDAS\n",
    "# ============================================================\n",
    "def create_directory(path: str):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "def generate_graphs(samg_name, samg_dict, actions_map):\n",
    "    create_directory(samg_name)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(samg_name, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                base = measure.replace(' ', '_').replace('/', '_')\n",
    "\n",
    "                # --- CSV de niveles por instrumento (remuestreados) ---\n",
    "                _, df_levels = _levels_dataframe(instrs)\n",
    "                out_csv = os.path.join(path_code, base + \".csv\")\n",
    "                df_levels.to_csv(out_csv, index=False, encoding=\"utf-8\")\n",
    "\n",
    "                # --- gráfico como antes ---\n",
    "                plot_damage(instrs, os.path.join(path_code, base + \".png\"), measure)\n",
    "\n",
    "                # --- NUEVO: copia única por ACTION a carpeta global ACTIONS_CSV_PyT ---\n",
    "                #     Mismo contenido del CSV anterior, nombre con sufijo _PyT.csv\n",
    "                if base not in ACTIONS_PyT_SAVED:\n",
    "                    df_levels.to_csv(\n",
    "                        os.path.join(ACTIONS_PyT_DIR, base + \"_PyT.csv\"),\n",
    "                        index=False, encoding=\"utf-8\"\n",
    "                    )\n",
    "                    ACTIONS_PyT_SAVED.add(base)\n",
    "\n",
    "\n",
    "\n",
    "def generate_availability(samg_name, samg_dict, actions_map):\n",
    "    base_dir = f\"Availability_{samg_name}\"\n",
    "    create_directory(base_dir)\n",
    "    for subguide, codes in samg_dict.items():\n",
    "        path_sub = os.path.join(base_dir, subguide)\n",
    "        create_directory(path_sub)\n",
    "        for code in codes:\n",
    "            if code not in actions_map:\n",
    "                continue\n",
    "            path_code = os.path.join(path_sub, code)\n",
    "            create_directory(path_code)\n",
    "            for measure, instrs in actions_map[code].items():\n",
    "                safe = measure.replace(' ', '_').replace('/', '_')\n",
    "                # --- nuevo: CSV de availability ---\n",
    "                t_ref, df_av = _availability_dataframe(instrs)\n",
    "                df_av.to_csv(os.path.join(path_code, safe + \"_availability.csv\"),\n",
    "                             index=False, encoding=\"utf-8\")\n",
    "                # --- gráfico como antes ---\n",
    "                states = df_av[\"state\"].tolist()\n",
    "                plot_availability(measure, t_ref, states,\n",
    "                                  os.path.join(path_code, safe + \"_availability.png\"))\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# EJECUCIÓN\n",
    "# ============================================================\n",
    "generate_graphs(\"SAMG1_PyT\", SAMG1, actions_short)\n",
    "generate_graphs(\"SAMG2_PyT\", SAMG2, actions_short)\n",
    "generate_availability(\"SAMG1_PyT\", SAMG1, actions_short)\n",
    "generate_availability(\"SAMG2_PyT\", SAMG2, actions_short)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b26458e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\TEMPERATURE_DRYWELL_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_DRYWELL_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_DRYWELL_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_DRYWELL_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\PRESSURE_DRYWELL_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_DRYWELL_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_DRYWELL_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_DRYWELL_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\RADIATION_CONTAINMENT_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\RADIATION_CONTAINMENT_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\RADIATION_CONTAINMENT_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\RADIATION_CONTAINMENT_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\HYDROGEN_CONTAINMENT_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\HYDROGEN_CONTAINMENT_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\HYDROGEN_CONTAINMENT_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\HYDROGEN_CONTAINMENT_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\LEVEL_BORON_TANK_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\LEVEL_BORON_TANK_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\LEVEL_BORON_TANK_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\LEVEL_BORON_TANK_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\INJECTED_FLOW_RPV_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\INJECTED_FLOW_RPV_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\INJECTED_FLOW_RPV_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\INJECTED_FLOW_RPV_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\LEVEL_RPV_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\LEVEL_RPV_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\LEVEL_RPV_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\LEVEL_RPV_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\PRESSURE_RPV_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_RPV_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_RPV_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_RPV_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\TEMPERATURE_RPV_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_RPV_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_RPV_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_RPV_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\PRESSURE_CONTAINMENT_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_CONTAINMENT_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_CONTAINMENT_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_CONTAINMENT_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\LEVEL_CONTAINMENT_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\LEVEL_CONTAINMENT_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\LEVEL_CONTAINMENT_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\LEVEL_CONTAINMENT_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\PRESSURE_SP_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_SP_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_SP_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\PRESSURE_SP_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\TEMPERATURE_SUPPRESSION_POOL_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_SUPPRESSION_POOL_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_SUPPRESSION_POOL_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_SUPPRESSION_POOL_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\SRV_POSITION_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\SRV_POSITION_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\SRV_POSITION_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\SRV_POSITION_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\REACTOR_POWER_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\REACTOR_POWER_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\REACTOR_POWER_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\REACTOR_POWER_availability.png\n",
      "✓ Guardado: GLOBAL_EVALUATION_CSV\\TEMPERATURE_CONTAINMENT_combined.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_CONTAINMENT_COMBINED.png\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_CONTAINMENT_availability.csv\n",
      "✓ Guardado: GLOBAL_EVALUATION\\TEMPERATURE_CONTAINMENT_availability.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ===========================\n",
    "# CONFIGURACIÓN\n",
    "# ===========================\n",
    "VARIABLES = [\n",
    "    \"TEMPERATURE_DRYWELL\",\n",
    "    \"PRESSURE_DRYWELL\",\n",
    "    \"RADIATION_CONTAINMENT\",\n",
    "    \"HYDROGEN_CONTAINMENT\",\n",
    "    \"LEVEL_BORON_TANK\",\n",
    "    \"INJECTED_FLOW_RPV\",\n",
    "    \"LEVEL_RPV\",\n",
    "    \"PRESSURE_RPV\",\n",
    "    \"TEMPERATURE_RPV\",\n",
    "    \"PRESSURE_CONTAINMENT\",\n",
    "    \"LEVEL_CONTAINMENT\",\n",
    "    \"PRESSURE_SP\",\n",
    "    \"TEMPERATURE_SUPPRESSION_POOL\",  # nombre canónico correcto\n",
    "    \"SRV_POSITION\",\n",
    "    \"REACTOR_POWER\",\n",
    "    \"TEMPERATURE_CONTAINMENT\",\n",
    "]\n",
    "\n",
    "# Alias para encontrar archivos si en disco todavía aparece TEMPERATURE_SP\n",
    "VAR_FILE_ALIASES = {\n",
    "    \"TEMPERATURE_SUPPRESSION_POOL\": [\"TEMPERATURE_SUPPRESSION_POOL\", \"TEMPERATURE_SP\"]\n",
    "}\n",
    "\n",
    "DIR_R   = \"ACTIONS_CSV_R\"\n",
    "DIR_PyT = \"ACTIONS_CSV_PyT\"\n",
    "\n",
    "OUT_DIR_IMG = \"GLOBAL_EVALUATION\"        # imágenes y availability CSV\n",
    "OUT_DIR_CSV = \"GLOBAL_EVALUATION_CSV\"    # CSV combinados (malla unida)\n",
    "os.makedirs(OUT_DIR_IMG, exist_ok=True)\n",
    "os.makedirs(OUT_DIR_CSV, exist_ok=True)\n",
    "\n",
    "MARKERS = [\"o\",\"s\",\"^\",\"D\",\"v\",\"P\",\"X\",\"<\",\">\",\"h\"]\n",
    "STATE_MAP   = {\"Good\":0, \"Careful\":1, \"Warning\":2, \"Blind\":3}\n",
    "ZONE_COLORS = {0:\"#006400\", 1:\"#CCCC00\", 2:\"#FF8C00\", 3:\"#8B0000\"}\n",
    "\n",
    "# ===========================\n",
    "# UTILIDADES DE FICHEROS\n",
    "# ===========================\n",
    "def resolve_paths_for_var(varname: str):\n",
    "    \"\"\"Devuelve (ruta_R, ruta_PyT) probando alias si hace falta.\"\"\"\n",
    "    bases = VAR_FILE_ALIASES.get(varname, [varname])\n",
    "    for base in bases:\n",
    "        rp = os.path.join(DIR_R,   f\"{base}_R.csv\")\n",
    "        pp = os.path.join(DIR_PyT, f\"{base}_PyT.csv\")\n",
    "        if os.path.exists(rp) and os.path.exists(pp):\n",
    "            return rp, pp\n",
    "    # por si el usuario ya renombró todo: intentamos la canónica\n",
    "    return os.path.join(DIR_R, f\"{varname}_R.csv\"), os.path.join(DIR_PyT, f\"{varname}_PyT.csv\")\n",
    "\n",
    "def load_timeseries_csv(path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Lee un CSV de serie temporal y normaliza a:\n",
    "      - 'tiempo_s' como columna de tiempo\n",
    "      - columnas por instrumento, enteras 1..5\n",
    "    \"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(path)\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    # Detecta la columna de tiempo (varias posibilidades)\n",
    "    time_candidates = [\"tiempo_s\", \"Time (s)\", \"time_s\", \"t\", \"time\", \"Time\"]\n",
    "    tcol = None\n",
    "    for c in df.columns:\n",
    "        if str(c).strip() in time_candidates:\n",
    "            tcol = c; break\n",
    "    if tcol is None:\n",
    "        low = {str(c).strip().lower(): c for c in df.columns}\n",
    "        for k in [\"tiempo_s\",\"time (s)\",\"time_s\",\"t\",\"time\"]:\n",
    "            if k in low:\n",
    "                tcol = low[k]; break\n",
    "    if tcol is None:\n",
    "        raise ValueError(f\"{path}: no encuentro columna de tiempo.\")\n",
    "\n",
    "    df = df.rename(columns={tcol: \"tiempo_s\"}).copy()\n",
    "    df[\"tiempo_s\"] = pd.to_numeric(df[\"tiempo_s\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"tiempo_s\"]).sort_values(\"tiempo_s\").reset_index(drop=True)\n",
    "\n",
    "    inst_cols = [c for c in df.columns if c != \"tiempo_s\"]\n",
    "    for c in inst_cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\").round().clip(1,5).astype(\"Int64\")\n",
    "    return df\n",
    "\n",
    "# ===========================\n",
    "# FUSIÓN R + PyT\n",
    "# ===========================\n",
    "def union_time_grid(df_r: pd.DataFrame | None, df_p: pd.DataFrame | None) -> np.ndarray:\n",
    "    times = set()\n",
    "    if df_r is not None: times.update(df_r[\"tiempo_s\"].dropna().tolist())\n",
    "    if df_p is not None: times.update(df_p[\"tiempo_s\"].dropna().tolist())\n",
    "    return np.array(sorted(times), dtype=float) if times else np.array([], dtype=float)\n",
    "\n",
    "def ffill_at_times(df: pd.DataFrame | None, inst: str, t_union: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Para cada t_union, asigna el último valor <= t (carry-forward).\n",
    "    Antes del primer dato: usa el primer valor. Si df no tiene la columna: NaN.\n",
    "    \"\"\"\n",
    "    if df is None or inst not in df.columns:\n",
    "        return np.full(len(t_union), np.nan, dtype=float)\n",
    "    src = df[[\"tiempo_s\", inst]].dropna(subset=[\"tiempo_s\"]).sort_values(\"tiempo_s\")\n",
    "    a = pd.DataFrame({\"t\": t_union})\n",
    "    b = src.rename(columns={\"tiempo_s\":\"t\"}).copy()\n",
    "    out = pd.merge_asof(a, b, on=\"t\", direction=\"backward\")\n",
    "    y = out[inst].to_numpy(dtype=float)\n",
    "\n",
    "    # Antes del primer dato → primer valor disponible\n",
    "    if len(src) > 0 and np.isnan(y).any():\n",
    "        first_val = float(src[inst].iloc[0]) if not pd.isna(src[inst].iloc[0]) else np.nan\n",
    "        y[np.isnan(y)] = first_val\n",
    "\n",
    "    # Si todo NaN (columna corrupta), usa 1\n",
    "    if np.all(np.isnan(y)):\n",
    "        y = np.ones_like(y)\n",
    "    return y\n",
    "\n",
    "def compress_steps(x: np.ndarray, y: np.ndarray):\n",
    "    \"\"\"Devuelve puntos de cambio (step-post) y garantiza incluir el último x.\"\"\"\n",
    "    if len(x) == 0:\n",
    "        return x, y\n",
    "    x_comp = [x[0]]\n",
    "    y_comp = [int(round(y[0]))]\n",
    "    for i in range(1, len(x)):\n",
    "        val = int(round(y[i]))\n",
    "        if val != y_comp[-1]:\n",
    "            x_comp.append(x[i]); y_comp.append(val)\n",
    "    if x_comp[-1] != x[-1]:\n",
    "        x_comp.append(x[-1]); y_comp.append(y_comp[-1])\n",
    "    return np.array(x_comp), np.array(y_comp)\n",
    "\n",
    "def build_combined_series(csv_r_path: str, csv_pyt_path: str):\n",
    "    \"\"\"\n",
    "    Carga R y PyT (ambas series), alinea en malla unida, carry-forward en cada fuente,\n",
    "    combina por máximo punto a punto. Devuelve:\n",
    "      - t_union (np.ndarray)\n",
    "      - df_combined (DataFrame): 'tiempo_s' + columnas por instrumento (1..5)\n",
    "      - series_plot: {inst: (x_comp, y_comp)} comprimido para step-plot\n",
    "      - insts (lista ordenada)\n",
    "    \"\"\"\n",
    "    df_r = load_timeseries_csv(csv_r_path) if os.path.exists(csv_r_path) else None\n",
    "    df_p = load_timeseries_csv(csv_pyt_path) if os.path.exists(csv_pyt_path) else None\n",
    "    if df_r is None and df_p is None:\n",
    "        raise FileNotFoundError(f\"No encuentro ni {csv_r_path} ni {csv_pyt_path}\")\n",
    "\n",
    "    t_union = union_time_grid(df_r, df_p)\n",
    "    if t_union.size == 0:\n",
    "        return t_union, pd.DataFrame(), {}, []\n",
    "\n",
    "    insts = set()\n",
    "    if df_r is not None: insts.update([c for c in df_r.columns if c != \"tiempo_s\"])\n",
    "    if df_p is not None: insts.update([c for c in df_p.columns if c != \"tiempo_s\"])\n",
    "    insts = sorted(insts)\n",
    "\n",
    "    data = {\"tiempo_s\": t_union}\n",
    "    series_plot = {}\n",
    "    for inst in insts:\n",
    "        yr = ffill_at_times(df_r, inst, t_union)\n",
    "        yp = ffill_at_times(df_p, inst, t_union)\n",
    "        # máximo conservador; si ambos NaN → 1\n",
    "        both_nan = np.isnan(yr) & np.isnan(yp)\n",
    "        comb = np.where(both_nan, 1.0, np.nanmax(np.vstack([\n",
    "            np.nan_to_num(yr, nan=-np.inf),\n",
    "            np.nan_to_num(yp, nan=-np.inf)\n",
    "        ]), axis=0))\n",
    "        comb = np.round(comb).clip(1,5).astype(int)\n",
    "        data[inst] = comb\n",
    "        x_c, y_c = compress_steps(t_union, comb)\n",
    "        series_plot[inst] = (x_c, y_c)\n",
    "\n",
    "    df_combined = pd.DataFrame(data)\n",
    "    return t_union, df_combined, series_plot, insts\n",
    "\n",
    "# ===========================\n",
    "# PLOTS\n",
    "# ===========================\n",
    "def auto_offsets(n: int, base=0.06):\n",
    "    if n <= 1: return [0.0]\n",
    "    idx = np.arange(n) - (n-1)/2.0\n",
    "    return (idx / max(1, (n-1)/2.0)) * base\n",
    "\n",
    "def plot_variable(name: str, series_plot: dict, insts: list):\n",
    "    if not series_plot:\n",
    "        return\n",
    "    xmins = [s[0][0] for s in series_plot.values() if len(s[0])>0]\n",
    "    xmaxs = [s[0][-1] for s in series_plot.values() if len(s[0])>0]\n",
    "    if not xmins or not xmaxs:\n",
    "        return\n",
    "    xmin, xmax = min(xmins), max(xmaxs)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(12, 6))\n",
    "    fig.patch.set_facecolor(\"#06243A\")\n",
    "    ax.set_facecolor(\"#06243A\")\n",
    "\n",
    "    offs = auto_offsets(len(insts), base=0.06)\n",
    "    markers = {insts[i]: MARKERS[i % len(MARKERS)] for i in range(len(insts))}\n",
    "    line_kwargs = dict(where=\"post\", linewidth=2.0, markersize=7,\n",
    "                       markeredgewidth=1.8, solid_capstyle=\"butt\",\n",
    "                       mfc=\"none\", markevery=None)\n",
    "    y_all = []\n",
    "    for i, inst in enumerate(insts):\n",
    "        x, y = series_plot[inst]\n",
    "        if len(x) == 0: continue\n",
    "        y_shift = y + offs[i]\n",
    "        y_all.extend(list(y_shift))\n",
    "        ln = ax.step(x, y_shift, marker=markers[inst], label=inst, **line_kwargs)[0]\n",
    "        ln.set_zorder(3)\n",
    "\n",
    "    ax.set_title(name.replace(\"_\", \" \"), fontsize=34, fontweight=\"bold\", color=\"white\", pad=20)\n",
    "    ax.set_xlabel(\"Time (s)\", fontsize=20, color=\"white\", labelpad=15)\n",
    "    ax.set_ylabel(\"Damage Level\", fontsize=24, color=\"white\", labelpad=15)\n",
    "    ax.set_xlim(xmin, xmax)\n",
    "    if y_all:\n",
    "        ymin = max(0.9, np.nanmin(y_all) - 0.1)\n",
    "        ymax = min(5.1, np.nanmax(y_all) + 0.1)\n",
    "        ax.set_ylim(ymin, ymax)\n",
    "    ax.tick_params(axis=\"both\", colors=\"white\", labelsize=14)\n",
    "    ax.grid(True, linestyle=\"--\", alpha=0.35)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_color(\"white\"); spine.set_alpha(0.6)\n",
    "    plt.subplots_adjust(bottom=0.24)\n",
    "    ncols = min(4, max(2, int(math.ceil(len(insts)/2))))\n",
    "    leg = ax.legend(loc=\"upper center\", bbox_to_anchor=(0.5, -0.18),\n",
    "                    ncol=ncols, frameon=False, fontsize=14,\n",
    "                    handlelength=2.6, handletextpad=0.8, columnspacing=1.8)\n",
    "    for txt in leg.get_texts():\n",
    "        txt.set_color(\"white\")\n",
    "\n",
    "    out_path = os.path.join(OUT_DIR_IMG, f\"{name}_COMBINED.png\")\n",
    "    plt.savefig(out_path, dpi=220, bbox_inches=\"tight\", facecolor=fig.get_facecolor())\n",
    "    plt.close(fig)\n",
    "    print(f\"✓ Guardado: {out_path}\")\n",
    "\n",
    "# ===========================\n",
    "# AVAILABILITY\n",
    "# ===========================\n",
    "def classify_state_from_levels(levels):\n",
    "    if not levels:\n",
    "        return \"Blind\"\n",
    "    lvls = [int(x) for x in levels if x is not None]\n",
    "    if all(l == 1 for l in lvls): return \"Good\"\n",
    "    if all(l == 5 for l in lvls): return \"Blind\"\n",
    "    if any(l in (3,4) for l in lvls): return \"Warning\"\n",
    "    if any(l == 2 for l in lvls) and all(l <= 2 for l in lvls): return \"Careful\"\n",
    "    return \"Warning\"\n",
    "\n",
    "def build_availability_from_combined(df_combined: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Calcula availability sobre la malla completa combinada.\"\"\"\n",
    "    times = df_combined[\"tiempo_s\"].to_numpy()\n",
    "    inst_cols = [c for c in df_combined.columns if c != \"tiempo_s\"]\n",
    "    states, codes = [], []\n",
    "    for i in range(len(times)):\n",
    "        lvls = [int(df_combined.iloc[i][c]) for c in inst_cols]\n",
    "        st = classify_state_from_levels(lvls)\n",
    "        states.append(st)\n",
    "        codes.append(STATE_MAP[st])\n",
    "    return pd.DataFrame({\"time_s\": times, \"state\": states, \"state_code\": codes})\n",
    "\n",
    "def plot_availability_timeseries(var_name: str, df_av: pd.DataFrame):\n",
    "    times = df_av[\"time_s\"].tolist()\n",
    "    values = df_av[\"state_code\"].tolist()\n",
    "    fig, ax = plt.subplots(figsize=(16, 9), dpi=120)\n",
    "    fig.patch.set_facecolor(\"#06243A\")\n",
    "    ax.set_facecolor(\"#06243A\")\n",
    "    for lvl, col in ZONE_COLORS.items():\n",
    "        ax.axhspan(lvl, lvl + 1, color=col, alpha=0.28)\n",
    "    ax.step(times, values, where=\"post\", marker=\"o\", mfc=\"none\",\n",
    "            markersize=6, linewidth=1.8, color=\"#00CED1\")\n",
    "    ax.set_xlim(min(times), max(times))\n",
    "    ax.set_xlabel(\"Time (s)\", fontsize=20, color=\"white\", labelpad=15)\n",
    "    ax.set_ylabel(\"Availability State\", fontsize=20, color=\"white\", labelpad=15)\n",
    "    ax.set_yticks(list(STATE_MAP.values()))\n",
    "    ax.set_yticklabels(list(STATE_MAP.keys()), color=\"white\", fontsize=16)\n",
    "    ax.set_title(f\"{var_name.replace('_',' ')} Availability\", color=\"white\", fontsize=28, pad=40)\n",
    "    ax.tick_params(colors=\"white\", labelsize=14)\n",
    "    ax.grid(color=\"white\", linestyle=\"--\", alpha=0.25, linewidth=1)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_edgecolor(\"white\")\n",
    "    fig.subplots_adjust(top=0.88, bottom=0.18)\n",
    "    out_png = os.path.join(OUT_DIR_IMG, f\"{var_name}_availability.png\")\n",
    "    plt.savefig(out_png, facecolor=fig.get_facecolor(), dpi=220)\n",
    "    plt.close(fig)\n",
    "    print(f\"✓ Guardado: {out_png}\")\n",
    "\n",
    "# ===========================\n",
    "# EJECUCIÓN\n",
    "# ===========================\n",
    "for var in VARIABLES:\n",
    "    # Corrige alias en disco: si existe TEMPERATURE_SP úsalo, pero el nombre lógico es TEMPERATURE_SUPPRESSION_POOL\n",
    "    r_path, p_path = resolve_paths_for_var(var)\n",
    "\n",
    "    if not (os.path.exists(r_path) and os.path.exists(p_path)):\n",
    "        print(f\"⚠️  Omito {var}: faltan {r_path} o {p_path}\")\n",
    "        continue\n",
    "\n",
    "    # 1) Combina R+PyT\n",
    "    t_union, df_combined, series_plot, insts = build_combined_series(r_path, p_path)\n",
    "    if df_combined.empty or not insts:\n",
    "        print(f\"⚠️  Omito {var}: no hay datos tras combinar.\")\n",
    "        continue\n",
    "\n",
    "    # 2) Guarda CSV combinado completo (malla unida)\n",
    "    out_csv = os.path.join(OUT_DIR_CSV, f\"{var}_combined.csv\")\n",
    "    df_combined.to_csv(out_csv, index=False)\n",
    "    print(f\"✓ Guardado: {out_csv}\")\n",
    "\n",
    "    # 3) Gráfica de niveles combinados por instrumento (step-post comprimido + offsets visuales)\n",
    "    plot_variable(var, series_plot, insts)\n",
    "\n",
    "    # 4) Availability sobre la malla completa\n",
    "    df_av = build_availability_from_combined(df_combined)\n",
    "    out_av_csv = os.path.join(OUT_DIR_IMG, f\"{var}_availability.csv\")\n",
    "    df_av.to_csv(out_av_csv, index=False)\n",
    "    print(f\"✓ Guardado: {out_av_csv}\")\n",
    "    plot_availability_timeseries(var, df_av)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
